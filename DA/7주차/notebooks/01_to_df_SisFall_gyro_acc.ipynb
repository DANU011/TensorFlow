{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'ax', 'ay', 'az', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D04': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing-sitting',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = '../data/SisFall_dataset'\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        # user_ID가 'SA' 또는 'SE'로 시작하고 뒤에 오는 숫자가 5의 배수인 경우 건너뛰기\n",
    "        if user_ID.startswith('SA') or user_ID.startswith('SE'):\n",
    "            numeric_part = user_ID[2:]\n",
    "            if numeric_part.isdigit() and int(numeric_part) % 5 == 0:\n",
    "                continue\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith('.txt'):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D04, D05, D07, F05, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D04', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    #Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    # 데이터 파싱 및 DataFrame에 추가\n",
    "                    for i, line in enumerate(lines):\n",
    "                        if i % 10 == 0:  # 10의 배수인 행만 처리\n",
    "                            # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                            fields = line.strip().split(',')\n",
    "\n",
    "                            if len(fields) >= 6:  # 필드 수 확인\n",
    "                                # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                gx_values.append(gx_value)\n",
    "                                gy_values.append(gy_value)\n",
    "                                gz_values.append(gz_value)\n",
    "\n",
    "                                if len(gx_values) == 1:\n",
    "                                    # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                    df.loc[len(df)] = {\n",
    "                                        'user_ID': user_ID,\n",
    "                                        'trial_ID': trial_ID,\n",
    "                                        'task_ID': task_ID,\n",
    "                                        'gx': gx_values[0],\n",
    "                                        'gy': gy_values[0],\n",
    "                                        'gz': gz_values[0],\n",
    "                                        'label': label\n",
    "                                    }\n",
    "                                    record_count += 1\n",
    "                                    gx_values = []\n",
    "                                    gy_values = []\n",
    "                                    gz_values = []\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-11T07:30:15.008747800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SA01' 'SA02' 'SA04' 'SA05' 'SA07' 'SA08' 'SA10' 'SA11' 'SA13' 'SA14'\n",
      " 'SA16' 'SA17' 'SA19' 'SA20' 'SA22' 'SA23' 'SE01' 'SE02' 'SE04' 'SE05'\n",
      " 'SE07' 'SE08' 'SE10' 'SE11' 'SE13' 'SE14']\n"
     ]
    }
   ],
   "source": [
    "print(df['user_ID'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T03:25:10.184010Z",
     "start_time": "2023-06-11T03:25:10.169050500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_train.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_train.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T03:25:18.076723300Z",
     "start_time": "2023-06-11T03:25:17.025445400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 74\u001B[0m\n\u001B[0;32m     70\u001B[0m gz_values\u001B[38;5;241m.\u001B[39mappend(gz_value)\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(gx_values) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;66;03m# 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\u001B[39;00m\n\u001B[1;32m---> 74\u001B[0m     \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     75\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: user_ID,\n\u001B[0;32m     76\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrial_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: trial_ID,\n\u001B[0;32m     77\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: task_ID,\n\u001B[0;32m     78\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgx\u001B[39m\u001B[38;5;124m'\u001B[39m: gx_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgy\u001B[39m\u001B[38;5;124m'\u001B[39m: gy_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m     80\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgz\u001B[39m\u001B[38;5;124m'\u001B[39m: gz_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m     81\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m: label\n\u001B[0;32m     82\u001B[0m     }\n\u001B[0;32m     83\u001B[0m     record_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     84\u001B[0m     gx_values \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:849\u001B[0m, in \u001B[0;36m_LocationIndexer.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m    846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_valid_setitem_indexer(key)\n\u001B[0;32m    848\u001B[0m iloc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39miloc\n\u001B[1;32m--> 849\u001B[0m \u001B[43miloc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setitem_with_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1818\u001B[0m, in \u001B[0;36m_iLocIndexer._setitem_with_indexer\u001B[1;34m(self, indexer, value, name)\u001B[0m\n\u001B[0;32m   1815\u001B[0m     indexer, missing \u001B[38;5;241m=\u001B[39m convert_missing_indexer(indexer)\n\u001B[0;32m   1817\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m missing:\n\u001B[1;32m-> 1818\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setitem_with_indexer_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1819\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   1821\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloc\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1822\u001B[0m     \u001B[38;5;66;03m# must come after setting of missing\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:2173\u001B[0m, in \u001B[0;36m_iLocIndexer._setitem_with_indexer_missing\u001B[1;34m(self, indexer, value)\u001B[0m\n\u001B[0;32m   2171\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_mgr \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39m_mgr\n\u001B[0;32m   2172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2173\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_append\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m_mgr\n\u001B[0;32m   2174\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_maybe_update_cacher(clear\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9563\u001B[0m, in \u001B[0;36mDataFrame._append\u001B[1;34m(self, other, ignore_index, verify_integrity, sort)\u001B[0m\n\u001B[0;32m   9560\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   9561\u001B[0m     to_concat \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m, other]\n\u001B[1;32m-> 9563\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   9564\u001B[0m \u001B[43m    \u001B[49m\u001B[43mto_concat\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9566\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverify_integrity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9567\u001B[0m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9568\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   9569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mappend\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:385\u001B[0m, in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    370\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    372\u001B[0m op \u001B[38;5;241m=\u001B[39m _Concatenator(\n\u001B[0;32m    373\u001B[0m     objs,\n\u001B[0;32m    374\u001B[0m     axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    382\u001B[0m     sort\u001B[38;5;241m=\u001B[39msort,\n\u001B[0;32m    383\u001B[0m )\n\u001B[1;32m--> 385\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001B[0m, in \u001B[0;36m_Concatenator.get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    612\u001B[0m             indexers[ax] \u001B[38;5;241m=\u001B[39m obj_labels\u001B[38;5;241m.\u001B[39mget_indexer(new_labels)\n\u001B[0;32m    614\u001B[0m     mgrs_indexers\u001B[38;5;241m.\u001B[39mappend((obj\u001B[38;5;241m.\u001B[39m_mgr, indexers))\n\u001B[1;32m--> 616\u001B[0m new_data \u001B[38;5;241m=\u001B[39m \u001B[43mconcatenate_managers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmgrs_indexers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_axes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconcat_axis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbm_axis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    619\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    620\u001B[0m     new_data\u001B[38;5;241m.\u001B[39m_consolidate_inplace()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\concat.py:231\u001B[0m, in \u001B[0;36mconcatenate_managers\u001B[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001B[0m\n\u001B[0;32m    225\u001B[0m vals \u001B[38;5;241m=\u001B[39m [ju\u001B[38;5;241m.\u001B[39mblock\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;28;01mfor\u001B[39;00m ju \u001B[38;5;129;01min\u001B[39;00m join_units]\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m blk\u001B[38;5;241m.\u001B[39mis_extension:\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001B[39;00m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;66;03m#  we can use np.concatenate, which is more performant\u001B[39;00m\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;66;03m#  than concat_compat\u001B[39;00m\n\u001B[1;32m--> 231\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001B[39;00m\n\u001B[0;32m    234\u001B[0m     values \u001B[38;5;241m=\u001B[39m concat_compat(vals, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mconcatenate\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D04': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing-sitting',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = '../data/SisFall_dataset'\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        # user_ID가 'SA' 또는 'SE'로 시작하고 뒤에 오는 숫자가 5의 배수인 경우에만 처리\n",
    "        if (user_ID.startswith('SA') or user_ID.startswith('SE')) and user_ID[2:].isdigit() and int(user_ID[2:]) % 5 == 0:\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                if file_name.endswith('.txt'):\n",
    "                    # 파일 경로\n",
    "                    file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                    # 파일 이름에 대한 정보\n",
    "                    activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                    trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                    # task_id가 D01, D04, D05, D07, F05, F06인 경우에만 처리\n",
    "                    if activity in ['D01', 'D04', 'D05', 'D07', 'F06']:\n",
    "                        # task_id에 해당하는 label 정보\n",
    "                        task_ID = activity\n",
    "                        label = label_mapping[task_ID]\n",
    "\n",
    "                        # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                        Range = 2000  # 예시 값을 사용\n",
    "                        Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                        # 파일에서 데이터를 읽어와서 처리\n",
    "                        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                            lines = file.readlines()\n",
    "\n",
    "                        # 데이터 파싱 및 계산\n",
    "                        gx_values = []\n",
    "                        gy_values = []\n",
    "                        gz_values = []\n",
    "\n",
    "                        # 데이터 파싱 및 DataFrame에 추가\n",
    "                        for i, line in enumerate(lines):\n",
    "                            if i % 10 == 0:  # 10의 배수인 행만 처리\n",
    "                                # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                                fields = line.strip().split(',')\n",
    "\n",
    "                                if len(fields) >= 6:  # 필드 수 확인\n",
    "                                    # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                    gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                    gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                    gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                    gx_values.append(gx_value)\n",
    "                                    gy_values.append(gy_value)\n",
    "                                    gz_values.append(gz_value)\n",
    "\n",
    "                                    if len(gx_values) == 1:\n",
    "                                        # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                        df.loc[len(df)] = {\n",
    "                                            'user_ID': user_ID,\n",
    "                                            'trial_ID': trial_ID,\n",
    "                                            'task_ID': task_ID,\n",
    "                                            'gx': gx_values[0],\n",
    "                                            'gy': gy_values[0],\n",
    "                                            'gz': gz_values[0],\n",
    "                                            'label': label\n",
    "                                        }\n",
    "                                        record_count += 1\n",
    "                                        gx_values = []\n",
    "                                        gy_values = []\n",
    "                                        gz_values = []\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T07:29:43.355084500Z",
     "start_time": "2023-06-11T07:28:10.795297200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df['user_ID'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_test.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_test.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T03:30:05.423659100Z",
     "start_time": "2023-06-11T03:30:05.200512900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_ID trial_ID task_ID         gx         gy         gz     label\n",
      "0         SA01      R01     D01  -1.098633 -30.761719 -21.484375   walking\n",
      "1         SA01      R01     D01 -10.864258 -46.752930  -3.173828   walking\n",
      "2         SA01      R01     D01  31.860352 -22.216797   8.056641   walking\n",
      "3         SA01      R01     D01   2.624512 -11.352539  29.052734   walking\n",
      "4         SA01      R01     D01   7.263184  15.869141  26.184082   walking\n",
      "...        ...      ...     ...        ...        ...        ...       ...\n",
      "331797    SE15      R05     D07  -1.281738   3.601074  -0.366211  standing\n",
      "331798    SE15      R05     D07  -1.586914   3.295898  -0.610352  standing\n",
      "331799    SE15      R05     D07  -1.586914   3.173828  -0.915527  standing\n",
      "331800    SE15      R05     D07  -1.525879   2.868652  -0.976562  standing\n",
      "331801    SE15      R05     D07  -1.281738   3.051758  -0.915527  standing\n",
      "\n",
      "[331802 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = \"../data/SisFall_dataset\"\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D03, D05, D07, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D03', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    #Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    # 데이터 파싱 및 DataFrame에 추가\n",
    "                    for i, line in enumerate(lines):\n",
    "                        if i % 10 == 0:  # 1, 11, 21, 31번째 행만 처리\n",
    "                            # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                            fields = line.strip().split(',')\n",
    "\n",
    "                            if len(fields) >= 6:  # 필드 수 확인\n",
    "                                # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                gx_values.append(gx_value)\n",
    "                                gy_values.append(gy_value)\n",
    "                                gz_values.append(gz_value)\n",
    "\n",
    "                                if len(gx_values) == 1:\n",
    "                                    # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                    df.loc[len(df)] = {\n",
    "                                        'user_ID': user_ID,\n",
    "                                        'trial_ID': trial_ID,\n",
    "                                        'task_ID': task_ID,\n",
    "                                        'gx': gx_values[0],\n",
    "                                        'gy': gy_values[0],\n",
    "                                        'gz': gz_values[0],\n",
    "                                        'label': label\n",
    "                                    }\n",
    "                                    record_count += 1\n",
    "                                    gx_values = []\n",
    "                                    gy_values = []\n",
    "                                    gz_values = []\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-10T07:13:45.832325300Z",
     "start_time": "2023-06-10T06:27:33.678589900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_ID trial_ID task_ID         gx         gy         gz    label   \n",
      "0    SA01      R01     D01  -1.098633 -30.761719 -21.484375  walking  \\\n",
      "1    SA01      R01     D01 -10.864258 -46.752930  -3.173828  walking   \n",
      "2    SA01      R01     D01  31.860352 -22.216797   8.056641  walking   \n",
      "3    SA01      R01     D01   2.624512 -11.352539  29.052734  walking   \n",
      "4    SA01      R01     D01   7.263184  15.869141  26.184082  walking   \n",
      "\n",
      "   scaled_gx  scaled_gy  scaled_gz  \n",
      "0   0.015592   0.010843   0.042287  \n",
      "1   0.001771  -0.010123   0.066825  \n",
      "2   0.062238   0.022046   0.081875  \n",
      "3   0.020861   0.036290   0.110011  \n",
      "4   0.027426   0.071980   0.106167  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz' 열의 데이터 추출\n",
    "data = df[['gx', 'gy', 'gz']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df['scaled_gx'] = scaled_data[:, 0]\n",
    "df['scaled_gy'] = scaled_data[:, 1]\n",
    "df['scaled_gz'] = scaled_data[:, 2]\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-10T07:14:51.893004100Z",
     "start_time": "2023-06-10T07:14:51.862061500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_train.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_train.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-10T07:15:17.721845Z",
     "start_time": "2023-06-10T07:15:15.492526700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = \"../data/SisFall_dataset\"\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D03, D05, D07, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D03', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    #Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    # 데이터 파싱 및 DataFrame에 추가\n",
    "                    for i, line in enumerate(lines):\n",
    "                        if i % 10 == 3:\n",
    "                            # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                            fields = line.strip().split(',')\n",
    "\n",
    "                            if len(fields) >= 6:  # 필드 수 확인\n",
    "                                # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                gx_values.append(gx_value)\n",
    "                                gy_values.append(gy_value)\n",
    "                                gz_values.append(gz_value)\n",
    "\n",
    "                                if len(gx_values) == 1:\n",
    "                                    # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                    df.loc[len(df)] = {\n",
    "                                        'user_ID': user_ID,\n",
    "                                        'trial_ID': trial_ID,\n",
    "                                        'task_ID': task_ID,\n",
    "                                        'gx': gx_values[0],\n",
    "                                        'gy': gy_values[0],\n",
    "                                        'gz': gz_values[0],\n",
    "                                        'label': label\n",
    "                                    }\n",
    "                                    record_count += 1\n",
    "                                    gx_values = []\n",
    "                                    gy_values = []\n",
    "                                    gz_values = []\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-10T07:16:32.977722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz' 열의 데이터 추출\n",
    "data = df[['gx', 'gy', 'gz']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df['scaled_gx'] = scaled_data[:, 0]\n",
    "df['scaled_gy'] = scaled_data[:, 1]\n",
    "df['scaled_gz'] = scaled_data[:, 2]\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
