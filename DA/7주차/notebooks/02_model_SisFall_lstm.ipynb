{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "427/427 [==============================] - 3s 3ms/step - loss: 1.0303 - accuracy: 0.5756 - val_loss: 0.8544 - val_accuracy: 0.6692\n",
      "Epoch 2/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.7200 - val_loss: 0.8169 - val_accuracy: 0.6768\n",
      "Epoch 3/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.5777 - accuracy: 0.7743 - val_loss: 0.8080 - val_accuracy: 0.6873\n",
      "Epoch 4/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.4955 - accuracy: 0.8065 - val_loss: 0.7934 - val_accuracy: 0.7037\n",
      "Epoch 5/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.8359 - val_loss: 0.8235 - val_accuracy: 0.7049\n",
      "Epoch 6/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.3685 - accuracy: 0.8627 - val_loss: 0.8355 - val_accuracy: 0.7066\n",
      "Epoch 7/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8858 - val_loss: 0.9002 - val_accuracy: 0.6920\n",
      "Epoch 8/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9023 - val_loss: 0.9498 - val_accuracy: 0.6920\n",
      "Epoch 9/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9157 - val_loss: 0.9910 - val_accuracy: 0.6821\n",
      "Epoch 10/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2212 - accuracy: 0.9273 - val_loss: 1.0259 - val_accuracy: 0.6826\n",
      "Epoch 11/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1980 - accuracy: 0.9359 - val_loss: 1.0748 - val_accuracy: 0.6750\n",
      "Epoch 12/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1846 - accuracy: 0.9395 - val_loss: 1.0878 - val_accuracy: 0.6780\n",
      "Epoch 13/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1698 - accuracy: 0.9455 - val_loss: 1.1066 - val_accuracy: 0.6897\n",
      "Epoch 14/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9487 - val_loss: 1.1826 - val_accuracy: 0.6739\n",
      "Epoch 15/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1480 - accuracy: 0.9516 - val_loss: 1.2180 - val_accuracy: 0.6815\n",
      "Epoch 16/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1320 - accuracy: 0.9567 - val_loss: 1.2474 - val_accuracy: 0.6791\n",
      "Epoch 17/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1209 - accuracy: 0.9603 - val_loss: 1.2642 - val_accuracy: 0.6879\n",
      "Epoch 18/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1084 - accuracy: 0.9647 - val_loss: 1.3229 - val_accuracy: 0.6826\n",
      "Epoch 19/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9693 - val_loss: 1.3420 - val_accuracy: 0.6797\n",
      "Epoch 20/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9705 - val_loss: 1.3517 - val_accuracy: 0.6914\n",
      "Epoch 21/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9698 - val_loss: 1.3840 - val_accuracy: 0.6809\n",
      "Epoch 22/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1123 - accuracy: 0.9612 - val_loss: 1.4526 - val_accuracy: 0.6786\n",
      "Epoch 23/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.9550 - val_loss: 1.4392 - val_accuracy: 0.6710\n",
      "Epoch 24/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1036 - accuracy: 0.9647 - val_loss: 1.4559 - val_accuracy: 0.6727\n",
      "Epoch 25/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9771 - val_loss: 1.4652 - val_accuracy: 0.6727\n",
      "Epoch 26/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 1.4852 - val_accuracy: 0.6786\n",
      "Epoch 27/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.9843 - val_loss: 1.4904 - val_accuracy: 0.6762\n",
      "Epoch 28/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 1.5364 - val_accuracy: 0.6826\n",
      "Epoch 29/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0412 - accuracy: 0.9889 - val_loss: 1.5850 - val_accuracy: 0.6750\n",
      "Epoch 30/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 1.5639 - val_accuracy: 0.6861\n",
      "Epoch 31/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0439 - accuracy: 0.9863 - val_loss: 1.5870 - val_accuracy: 0.6844\n",
      "Epoch 32/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.9707 - val_loss: 1.6396 - val_accuracy: 0.6657\n",
      "Epoch 33/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9544 - val_loss: 1.6465 - val_accuracy: 0.6651\n",
      "Epoch 34/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9672 - val_loss: 1.6960 - val_accuracy: 0.6739\n",
      "Epoch 35/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9856 - val_loss: 1.6618 - val_accuracy: 0.6733\n",
      "Epoch 36/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0401 - accuracy: 0.9894 - val_loss: 1.6477 - val_accuracy: 0.6797\n",
      "Epoch 37/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9930 - val_loss: 1.6407 - val_accuracy: 0.6908\n",
      "Epoch 38/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9952 - val_loss: 1.6963 - val_accuracy: 0.6850\n",
      "Epoch 39/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 1.7518 - val_accuracy: 0.6780\n",
      "Epoch 40/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 1.7610 - val_accuracy: 0.6803\n",
      "Epoch 41/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 1.7869 - val_accuracy: 0.6786\n",
      "Epoch 42/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 1.8466 - val_accuracy: 0.6768\n",
      "Epoch 43/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.9765 - val_loss: 1.8837 - val_accuracy: 0.6774\n",
      "Epoch 44/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1165 - accuracy: 0.9589 - val_loss: 1.8654 - val_accuracy: 0.6715\n",
      "Epoch 45/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0844 - accuracy: 0.9694 - val_loss: 1.8700 - val_accuracy: 0.6645\n",
      "Epoch 46/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 1.8638 - val_accuracy: 0.6739\n",
      "Epoch 47/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0300 - accuracy: 0.9927 - val_loss: 1.9160 - val_accuracy: 0.6733\n",
      "Epoch 48/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.9970 - val_loss: 1.9568 - val_accuracy: 0.6674\n",
      "Epoch 49/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 1.9259 - val_accuracy: 0.6780\n",
      "Epoch 50/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 1.9693 - val_accuracy: 0.6727\n",
      "Epoch 51/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 1.9755 - val_accuracy: 0.6780\n",
      "Epoch 52/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 1.9849 - val_accuracy: 0.6739\n",
      "Epoch 53/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 2.0355 - val_accuracy: 0.6727\n",
      "Epoch 54/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9685 - val_loss: 2.0027 - val_accuracy: 0.6704\n",
      "Epoch 55/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.9688 - val_loss: 2.0551 - val_accuracy: 0.6628\n",
      "Epoch 56/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0508 - accuracy: 0.9829 - val_loss: 2.0347 - val_accuracy: 0.6745\n",
      "Epoch 57/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 2.0493 - val_accuracy: 0.6786\n",
      "Epoch 58/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 2.0279 - val_accuracy: 0.6809\n",
      "Epoch 59/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 2.1062 - val_accuracy: 0.6739\n",
      "Epoch 60/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 2.0820 - val_accuracy: 0.6774\n",
      "Epoch 61/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 2.1105 - val_accuracy: 0.6791\n",
      "Epoch 62/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 2.0820 - val_accuracy: 0.6745\n",
      "Epoch 63/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9888 - val_loss: 2.0587 - val_accuracy: 0.6721\n",
      "Epoch 64/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9677 - val_loss: 2.0400 - val_accuracy: 0.6610\n",
      "Epoch 65/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9735 - val_loss: 2.0700 - val_accuracy: 0.6791\n",
      "Epoch 66/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0398 - accuracy: 0.9888 - val_loss: 2.0525 - val_accuracy: 0.6774\n",
      "Epoch 67/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 2.0505 - val_accuracy: 0.6750\n",
      "Epoch 68/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 2.0625 - val_accuracy: 0.6745\n",
      "Epoch 69/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 2.1145 - val_accuracy: 0.6750\n",
      "Epoch 70/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 2.1335 - val_accuracy: 0.6745\n",
      "Epoch 71/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 2.0967 - val_accuracy: 0.6780\n",
      "Epoch 72/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 2.1415 - val_accuracy: 0.6844\n",
      "Epoch 73/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 2.1751 - val_accuracy: 0.6838\n",
      "Epoch 74/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.9654 - val_loss: 2.0792 - val_accuracy: 0.6686\n",
      "Epoch 75/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9671 - val_loss: 2.0582 - val_accuracy: 0.6821\n",
      "Epoch 76/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9797 - val_loss: 2.0973 - val_accuracy: 0.6774\n",
      "Epoch 77/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 2.1085 - val_accuracy: 0.6844\n",
      "Epoch 78/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 2.1297 - val_accuracy: 0.6821\n",
      "Epoch 79/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 2.1282 - val_accuracy: 0.6832\n",
      "Epoch 80/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1415 - val_accuracy: 0.6809\n",
      "Epoch 81/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.1417 - val_accuracy: 0.6838\n",
      "Epoch 82/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1533 - val_accuracy: 0.6791\n",
      "Epoch 83/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1668 - val_accuracy: 0.6780\n",
      "Epoch 84/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1705 - val_accuracy: 0.6815\n",
      "Epoch 85/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 9.7761e-04 - accuracy: 1.0000 - val_loss: 2.1786 - val_accuracy: 0.6821\n",
      "Epoch 86/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 7.8717e-04 - accuracy: 1.0000 - val_loss: 2.2052 - val_accuracy: 0.6803\n",
      "Epoch 87/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 6.7338e-04 - accuracy: 1.0000 - val_loss: 2.2138 - val_accuracy: 0.6803\n",
      "Epoch 88/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 5.9347e-04 - accuracy: 1.0000 - val_loss: 2.2254 - val_accuracy: 0.6832\n",
      "Epoch 89/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9953 - val_loss: 2.2264 - val_accuracy: 0.6698\n",
      "Epoch 90/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8861 - val_loss: 2.0001 - val_accuracy: 0.6710\n",
      "Epoch 91/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1394 - accuracy: 0.9515 - val_loss: 1.9946 - val_accuracy: 0.6780\n",
      "Epoch 92/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 2.0341 - val_accuracy: 0.6774\n",
      "Epoch 93/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0290 - accuracy: 0.9940 - val_loss: 2.0328 - val_accuracy: 0.6721\n",
      "Epoch 94/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0152 - accuracy: 0.9985 - val_loss: 2.0491 - val_accuracy: 0.6745\n",
      "Epoch 95/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 2.0791 - val_accuracy: 0.6692\n",
      "Epoch 96/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9999 - val_loss: 2.1078 - val_accuracy: 0.6721\n",
      "Epoch 97/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 2.1177 - val_accuracy: 0.6680\n",
      "Epoch 98/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1188 - val_accuracy: 0.6686\n",
      "Epoch 99/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 2.1501 - val_accuracy: 0.6680\n",
      "Epoch 100/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 2.1900 - val_accuracy: 0.6704\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df = pd.read_csv('../data/SisFall_train_L.csv')  # 훈련 파일\n",
    "test_df = pd.read_csv('../data/SisFall_val_L.csv')  # 테스트 파일\n",
    "\n",
    "X_train = []  # 훈련 입력 데이터\n",
    "y_train = []  # 훈련 출력 데이터\n",
    "\n",
    "X_test = []  # 테스트 입력 데이터\n",
    "y_test = []  # 테스트 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(train_df) - 39, 40):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = train_df.loc[i:i+39, 'gx'].values\n",
    "    gy_values = train_df.loc[i:i+39, 'gy'].values\n",
    "    gz_values = train_df.loc[i:i+39, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = train_df.loc[i:i+39, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_train.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_train.append(labels[0])\n",
    "\n",
    "for i in range(0, len(test_df) - 39, 40):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = test_df.loc[i:i+39, 'gx'].values\n",
    "    gy_values = test_df.loc[i:i+39, 'gy'].values\n",
    "    gz_values = test_df.loc[i:i+39, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = test_df.loc[i:i+39, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_test.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_test.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = label_encoder.transform(y_test)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "y_test = onehot_encoder.transform(integer_encoded_test)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(3, 40)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = history.model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_lstm.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_lstm.npy', label_encoder.classes_)\n",
    "\n",
    "# 가중치를 로드하기 위해 모델 구성\n",
    "loaded_model = keras.models.Sequential()\n",
    "loaded_model.add(keras.layers.LSTM(128, input_shape=(3, 40)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "loaded_model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 피클 파일에서 가중치 로드\n",
    "loaded_model_weights = pickle.load(open('../model/best_model_weights_lstm.pkl', 'rb'))\n",
    "\n",
    "# 모델에 로드된 가중치 설정\n",
    "loaded_model.set_weights(loaded_model_weights)\n",
    "\n",
    "# 모델 컴파일\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장\n",
    "loaded_model.save('../model/loaded_model_lstm.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T08:49:45.865602Z",
     "start_time": "2023-06-13T08:48:05.072634100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the training history\n",
    "train_loss = history.history['loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
