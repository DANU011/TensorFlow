{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "user_ID가 6,7로 끝나는 경우 검증 데이터 / 8,9로 끝나는 경우 테스트 데이터"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 103\u001B[0m\n\u001B[0;32m     99\u001B[0m az_values\u001B[38;5;241m.\u001B[39mappend(az_value)\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(gx_values) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;66;03m# 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\u001B[39;00m\n\u001B[1;32m--> 103\u001B[0m     \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    104\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: user_ID,\n\u001B[0;32m    105\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrial_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: trial_ID,\n\u001B[0;32m    106\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: task_ID,\n\u001B[0;32m    107\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgx\u001B[39m\u001B[38;5;124m'\u001B[39m: gx_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    108\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgy\u001B[39m\u001B[38;5;124m'\u001B[39m: gy_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    109\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgz\u001B[39m\u001B[38;5;124m'\u001B[39m: gz_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124max\u001B[39m\u001B[38;5;124m'\u001B[39m: ax_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    111\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124may\u001B[39m\u001B[38;5;124m'\u001B[39m: ay_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    112\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maz\u001B[39m\u001B[38;5;124m'\u001B[39m: az_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    113\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m: label\n\u001B[0;32m    114\u001B[0m     }\n\u001B[0;32m    115\u001B[0m     record_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    117\u001B[0m     gx_values \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:849\u001B[0m, in \u001B[0;36m_LocationIndexer.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m    846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_valid_setitem_indexer(key)\n\u001B[0;32m    848\u001B[0m iloc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39miloc\n\u001B[1;32m--> 849\u001B[0m \u001B[43miloc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setitem_with_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1818\u001B[0m, in \u001B[0;36m_iLocIndexer._setitem_with_indexer\u001B[1;34m(self, indexer, value, name)\u001B[0m\n\u001B[0;32m   1815\u001B[0m     indexer, missing \u001B[38;5;241m=\u001B[39m convert_missing_indexer(indexer)\n\u001B[0;32m   1817\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m missing:\n\u001B[1;32m-> 1818\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setitem_with_indexer_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1819\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   1821\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloc\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1822\u001B[0m     \u001B[38;5;66;03m# must come after setting of missing\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:2173\u001B[0m, in \u001B[0;36m_iLocIndexer._setitem_with_indexer_missing\u001B[1;34m(self, indexer, value)\u001B[0m\n\u001B[0;32m   2171\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_mgr \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39m_mgr\n\u001B[0;32m   2172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2173\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_append\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m_mgr\n\u001B[0;32m   2174\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_maybe_update_cacher(clear\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9563\u001B[0m, in \u001B[0;36mDataFrame._append\u001B[1;34m(self, other, ignore_index, verify_integrity, sort)\u001B[0m\n\u001B[0;32m   9560\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   9561\u001B[0m     to_concat \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m, other]\n\u001B[1;32m-> 9563\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   9564\u001B[0m \u001B[43m    \u001B[49m\u001B[43mto_concat\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9566\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverify_integrity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9567\u001B[0m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9568\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   9569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mappend\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:385\u001B[0m, in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    370\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    372\u001B[0m op \u001B[38;5;241m=\u001B[39m _Concatenator(\n\u001B[0;32m    373\u001B[0m     objs,\n\u001B[0;32m    374\u001B[0m     axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    382\u001B[0m     sort\u001B[38;5;241m=\u001B[39msort,\n\u001B[0;32m    383\u001B[0m )\n\u001B[1;32m--> 385\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001B[0m, in \u001B[0;36m_Concatenator.get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    612\u001B[0m             indexers[ax] \u001B[38;5;241m=\u001B[39m obj_labels\u001B[38;5;241m.\u001B[39mget_indexer(new_labels)\n\u001B[0;32m    614\u001B[0m     mgrs_indexers\u001B[38;5;241m.\u001B[39mappend((obj\u001B[38;5;241m.\u001B[39m_mgr, indexers))\n\u001B[1;32m--> 616\u001B[0m new_data \u001B[38;5;241m=\u001B[39m \u001B[43mconcatenate_managers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmgrs_indexers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_axes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconcat_axis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbm_axis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    619\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    620\u001B[0m     new_data\u001B[38;5;241m.\u001B[39m_consolidate_inplace()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\concat.py:231\u001B[0m, in \u001B[0;36mconcatenate_managers\u001B[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001B[0m\n\u001B[0;32m    225\u001B[0m vals \u001B[38;5;241m=\u001B[39m [ju\u001B[38;5;241m.\u001B[39mblock\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;28;01mfor\u001B[39;00m ju \u001B[38;5;129;01min\u001B[39;00m join_units]\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m blk\u001B[38;5;241m.\u001B[39mis_extension:\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001B[39;00m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;66;03m#  we can use np.concatenate, which is more performant\u001B[39;00m\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;66;03m#  than concat_compat\u001B[39;00m\n\u001B[1;32m--> 231\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001B[39;00m\n\u001B[0;32m    234\u001B[0m     values \u001B[38;5;241m=\u001B[39m concat_compat(vals, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mconcatenate\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'ax', 'ay', 'az', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D02': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D04': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D06': 'stairs_walking',\n",
    "    'D07': 'standing-sitting',\n",
    "    'D08': 'standing-sitting',\n",
    "    'F01': 'fall',\n",
    "    'F02': 'fall',\n",
    "    'F06': 'fall',\n",
    "    'F05': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = '../data/SisFall_dataset'\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        # user_ID가 'SA' 또는 'SE'로 시작하고 뒤에 오는 숫자가 7이거나 8인 경우 건너뛰기\n",
    "        if user_ID.startswith('SA') or user_ID.startswith('SE'):\n",
    "            numeric_part = user_ID[2:]\n",
    "            if user_ID.startswith('SA') or user_ID.startswith('SE'):\n",
    "                numeric_part = user_ID[2:]\n",
    "                if numeric_part.isdigit() and int(numeric_part) >= 6 and int(numeric_part) <= 9:\n",
    "                    continue\n",
    "\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith('.txt'):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                if activity in ['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'F01', 'F02', 'F05', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    #Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    range_g = 16  # range for ADXL345 when set to ±16g\n",
    "                    resolution_bits = 13  # resolution for ADXL345\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    ax_values = []\n",
    "                    ay_values = []\n",
    "                    az_values = []\n",
    "\n",
    "                    # 데이터 파싱 및 DataFrame에 추가\n",
    "                    for i, line in enumerate(lines):\n",
    "                        if i % 20 == 0:  # 20의 배수인 행만 처리\n",
    "                            # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                            fields = line.strip().split(',')\n",
    "\n",
    "                            if len(fields) >= 6:  # 필드 수 확인\n",
    "                                # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                ax_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[0])\n",
    "                                ay_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[1])\n",
    "                                az_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[2])\n",
    "\n",
    "\n",
    "                                gx_values.append(gx_value)\n",
    "                                gy_values.append(gy_value)\n",
    "                                gz_values.append(gz_value)\n",
    "\n",
    "                                ax_values.append(ax_value)\n",
    "                                ay_values.append(ay_value)\n",
    "                                az_values.append(az_value)\n",
    "\n",
    "                                if len(gx_values) == 1:\n",
    "                                    # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                    df.loc[len(df)] = {\n",
    "                                        'user_ID': user_ID,\n",
    "                                        'trial_ID': trial_ID,\n",
    "                                        'task_ID': task_ID,\n",
    "                                        'gx': gx_values[0],\n",
    "                                        'gy': gy_values[0],\n",
    "                                        'gz': gz_values[0],\n",
    "                                        'ax': ax_values[0],\n",
    "                                        'ay': ay_values[0],\n",
    "                                        'az': az_values[0],\n",
    "                                        'label': label\n",
    "                                    }\n",
    "                                    record_count += 1\n",
    "\n",
    "                                    gx_values = []\n",
    "                                    gy_values = []\n",
    "                                    gz_values = []\n",
    "\n",
    "                                    ax_values = []\n",
    "                                    ay_values = []\n",
    "                                    az_values = []\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz' 열의 데이터 추출\n",
    "data = df[['gx', 'gy', 'gz','ax', 'ay', 'az']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df['scaled_gx'] = scaled_data[:, 0]\n",
    "df['scaled_gy'] = scaled_data[:, 1]\n",
    "df['scaled_gz'] = scaled_data[:, 2]\n",
    "df['scaled_ax'] = scaled_data[:, 3]\n",
    "df['scaled_ay'] = scaled_data[:, 4]\n",
    "df['scaled_az'] = scaled_data[:, 5]\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_train_L_20.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T06:31:18.678624500Z",
     "start_time": "2023-06-14T00:37:28.791649700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m scaler \u001B[38;5;241m=\u001B[39m MinMaxScaler(feature_range\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# 'gx', 'gy', 'gz' 열의 데이터 추출\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgx\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgy\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgz\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# 데이터 스케일링\u001B[39;00m\n\u001B[0;32m     10\u001B[0m scaled_data \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mfit_transform(data)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz' 열의 데이터 추출\n",
    "data = df[['gx', 'gy', 'gz']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df['scaled_gx'] = scaled_data[:, 0]\n",
    "df['scaled_gy'] = scaled_data[:, 1]\n",
    "df['scaled_gz'] = scaled_data[:, 2]\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T08:19:21.131966400Z",
     "start_time": "2023-06-13T08:19:20.042353300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "print(df['user_ID'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_train_L.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_val_L_20.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# DataFrame 초기화\n",
    "df_val = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'ax', 'ay', 'az', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D02': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D04': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D06': 'stairs_walking',\n",
    "    'D07': 'standing-sitting',\n",
    "    'D08': 'standing-sitting',\n",
    "    'F01': 'fall',\n",
    "    'F02': 'fall',\n",
    "    'F06': 'fall',\n",
    "    'F05': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = '../data/SisFall_dataset'\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        # user_ID가 'SA' 또는 'SE'로 시작하고 뒤에 오는 숫자가 7이나 8인 경우 처리\n",
    "        if user_ID.startswith('SA') or user_ID.startswith('SE'):\n",
    "            numeric_part = user_ID[2:]\n",
    "            if numeric_part.isdigit() and int(numeric_part) in [7, 8]:\n",
    "                for file_name in os.listdir(dir_path):\n",
    "                    if file_name.endswith('.txt'):\n",
    "                        # 파일 경로\n",
    "                        file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                        # 파일 이름에 대한 정보\n",
    "                        activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                        trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                        if activity in ['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'F01', 'F02', 'F05', 'F06']:\n",
    "                            # task_id에 해당하는 label 정보\n",
    "                            task_ID = activity\n",
    "                            label = label_mapping[task_ID]\n",
    "\n",
    "                            # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                            Range = 2000  # 예시 값을 사용\n",
    "                            Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                            range_g = 16  # range for ADXL345 when set to ±16g\n",
    "                            resolution_bits = 13  # resolution for ADXL345\n",
    "\n",
    "                            # 파일에서 데이터를 읽어와서 처리\n",
    "                            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                                lines = file.readlines()\n",
    "\n",
    "                            # 데이터 파싱 및 계산\n",
    "                            gx_values = []\n",
    "                            gy_values = []\n",
    "                            gz_values = []\n",
    "\n",
    "                            ax_values = []\n",
    "                            ay_values = []\n",
    "                            az_values = []\n",
    "\n",
    "                            # 데이터 파싱 및 DataFrame에 추가\n",
    "                            for i, line in enumerate(lines):\n",
    "                                if i % 20 == 0:  # 10의 배수인 행만 처리\n",
    "                                    # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                                    fields = line.strip().split(',')\n",
    "\n",
    "                                    if len(fields) >= 6:  # 필드 수 확인\n",
    "                                        # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                        gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                        gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                        gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                        ax_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[0])\n",
    "                                        ay_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[1])\n",
    "                                        az_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[2])\n",
    "\n",
    "                                        gx_values.append(gx_value)\n",
    "                                        gy_values.append(gy_value)\n",
    "                                        gz_values.append(gz_value)\n",
    "\n",
    "                                        ax_values.append(ax_value)\n",
    "                                        ay_values.append(ay_value)\n",
    "                                        az_values.append(az_value)\n",
    "\n",
    "                                        if len(gx_values) == 1:\n",
    "                                            # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                            df_val.loc[len(df_val)] = {\n",
    "                                                'user_ID': user_ID,\n",
    "                                                'trial_ID': trial_ID,\n",
    "                                                'task_ID': task_ID,\n",
    "                                                'gx': gx_values[0],\n",
    "                                                'gy': gy_values[0],\n",
    "                                                'gz': gz_values[0],\n",
    "                                                'ax': ax_values[0],\n",
    "                                                'ay': ay_values[0],\n",
    "                                                'az': az_values[0],\n",
    "                                                'label': label\n",
    "                                            }\n",
    "                                            record_count += 1\n",
    "\n",
    "                                            gx_values = []\n",
    "                                            gy_values = []\n",
    "                                            gz_values = []\n",
    "\n",
    "                                            ax_values = []\n",
    "                                            ay_values = []\n",
    "                                            az_values = []\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz', 'ax', 'ay', 'az' 열의 데이터 추출\n",
    "data = df_val[['gx', 'gy', 'gz', 'ax', 'ay', 'az']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df_val['scaled_gx'] = scaled_data[:, 0]\n",
    "df_val['scaled_gy'] = scaled_data[:, 1]\n",
    "df_val['scaled_gz'] = scaled_data[:, 2]\n",
    "df_val['scaled_ax'] = scaled_data[:, 3]\n",
    "df_val['scaled_ay'] = scaled_data[:, 4]\n",
    "df_val['scaled_az'] = scaled_data[:, 5]\n",
    "\n",
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_val_L_20.csv'\n",
    "df_val.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T00:02:11.030284200Z",
     "start_time": "2023-06-14T00:01:18.531069100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_ID trial_ID task_ID        gx         gy         gz   \n",
      "0        SA06      R01     D01 -0.061035  54.199219  19.470215  \\\n",
      "1        SA06      R01     D01 -5.981445  52.062988  27.465820   \n",
      "2        SA06      R01     D01  0.366211  59.143066  20.141602   \n",
      "3        SA06      R01     D01  7.080078  45.654297  26.916504   \n",
      "4        SA06      R01     D01 -0.427246  40.832520  26.367188   \n",
      "...       ...      ...     ...       ...        ...        ...   \n",
      "77095    SE07      R05     D08 -0.549316   4.089355  -0.732422   \n",
      "77096    SE07      R05     D08 -1.037598   4.211426  -0.427246   \n",
      "77097    SE07      R05     D08 -0.427246   4.516602  -0.366211   \n",
      "77098    SE07      R05     D08 -0.854492   5.004883  -0.244141   \n",
      "77099    SE07      R05     D08 -1.098633   4.943848   0.183105   \n",
      "\n",
      "                  label  \n",
      "0               walking  \n",
      "1               walking  \n",
      "2               walking  \n",
      "3               walking  \n",
      "4               walking  \n",
      "...                 ...  \n",
      "77095  standing-sitting  \n",
      "77096  standing-sitting  \n",
      "77097  standing-sitting  \n",
      "77098  standing-sitting  \n",
      "77099  standing-sitting  \n",
      "\n",
      "[77100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df_val = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D02': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D04': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D06': 'stairs_walking',\n",
    "    'D07': 'standing-sitting',\n",
    "    'D08': 'standing-sitting',\n",
    "    'F01': 'fall',\n",
    "    'F02': 'fall',\n",
    "    'F06': 'fall',\n",
    "    'F05': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = '../data/SisFall_dataset'\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        # user_ID가 'SA' 또는 'SE'로 시작하고 뒤에 오는 숫자가 6이거나 7인 경우에만 처리\n",
    "        if (user_ID.startswith('SA') or user_ID.startswith('SE')) and user_ID[2:].isdigit() and int(user_ID[2:]) in [6, 7]:\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                if file_name.endswith('.txt'):\n",
    "                    # 파일 경로\n",
    "                    file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                    # 파일 이름에 대한 정보\n",
    "                    activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                    trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                    # task_id가 D01, D04, D05, D07, F05, F06인 경우에만 처리\n",
    "                    if activity in ['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'F01', 'F02', 'F05', 'F06']:\n",
    "                        # task_id에 해당하는 label 정보\n",
    "                        task_ID = activity\n",
    "                        label = label_mapping[task_ID]\n",
    "\n",
    "                        # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                        Range = 2000  # 예시 값을 사용\n",
    "                        Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                        # 파일에서 데이터를 읽어와서 처리\n",
    "                        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                            lines = file.readlines()\n",
    "\n",
    "                        # 데이터 파싱 및 계산\n",
    "                        gx_values = []\n",
    "                        gy_values = []\n",
    "                        gz_values = []\n",
    "\n",
    "                        # 데이터 파싱 및 DataFrame에 추가\n",
    "                        for i, line in enumerate(lines):\n",
    "                            if i % 10 == 0:  # 10의 배수인 행만 처리\n",
    "                                # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                                fields = line.strip().split(',')\n",
    "\n",
    "                                if len(fields) >= 6:  # 필드 수 확인\n",
    "                                    # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                    gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                    gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                    gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                    gx_values.append(gx_value)\n",
    "                                    gy_values.append(gy_value)\n",
    "                                    gz_values.append(gz_value)\n",
    "\n",
    "                                    if len(gx_values) == 1:\n",
    "                                        # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                        df_val.loc[len(df_val)] = {\n",
    "                                            'user_ID': user_ID,\n",
    "                                            'trial_ID': trial_ID,\n",
    "                                            'task_ID': task_ID,\n",
    "                                            'gx': gx_values[0],\n",
    "                                            'gy': gy_values[0],\n",
    "                                            'gz': gz_values[0],\n",
    "                                            'label': label\n",
    "                                        }\n",
    "                                        record_count += 1\n",
    "                                        gx_values = []\n",
    "                                        gy_values = []\n",
    "                                        gz_values = []\n",
    "\n",
    "print(df_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T08:22:57.586369300Z",
     "start_time": "2023-06-13T08:20:05.989711600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_ID trial_ID task_ID        gx         gy         gz    label   \n",
      "0    SA06      R01     D01 -0.061035  54.199219  19.470215  walking  \\\n",
      "1    SA06      R01     D01 -5.981445  52.062988  27.465820  walking   \n",
      "2    SA06      R01     D01  0.366211  59.143066  20.141602  walking   \n",
      "3    SA06      R01     D01  7.080078  45.654297  26.916504  walking   \n",
      "4    SA06      R01     D01 -0.427246  40.832520  26.367188  walking   \n",
      "\n",
      "   scaled_gx  scaled_gy  scaled_gz  \n",
      "0   0.153615   0.122234   0.097170  \n",
      "1   0.145180   0.119433   0.107885  \n",
      "2   0.154224   0.128716   0.098070  \n",
      "3   0.163790   0.111031   0.107149  \n",
      "4   0.153094   0.104709   0.106413  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz' 열의 데이터 추출\n",
    "data = df_val[['gx', 'gy', 'gz']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df_val['scaled_gx'] = scaled_data[:, 0]\n",
    "df_val['scaled_gy'] = scaled_data[:, 1]\n",
    "df_val['scaled_gz'] = scaled_data[:, 2]\n",
    "\n",
    "print(df_val.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T08:23:53.150889100Z",
     "start_time": "2023-06-13T08:23:53.077159800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df_val['user_ID'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_test.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_val_L.csv'\n",
    "df_val.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T03:30:05.423659100Z",
     "start_time": "2023-06-11T03:30:05.200512900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_ID trial_ID task_ID         gx         gy         gz     label\n",
      "0         SA01      R01     D01  -1.098633 -30.761719 -21.484375   walking\n",
      "1         SA01      R01     D01 -10.864258 -46.752930  -3.173828   walking\n",
      "2         SA01      R01     D01  31.860352 -22.216797   8.056641   walking\n",
      "3         SA01      R01     D01   2.624512 -11.352539  29.052734   walking\n",
      "4         SA01      R01     D01   7.263184  15.869141  26.184082   walking\n",
      "...        ...      ...     ...        ...        ...        ...       ...\n",
      "331797    SE15      R05     D07  -1.281738   3.601074  -0.366211  standing\n",
      "331798    SE15      R05     D07  -1.586914   3.295898  -0.610352  standing\n",
      "331799    SE15      R05     D07  -1.586914   3.173828  -0.915527  standing\n",
      "331800    SE15      R05     D07  -1.525879   2.868652  -0.976562  standing\n",
      "331801    SE15      R05     D07  -1.281738   3.051758  -0.915527  standing\n",
      "\n",
      "[331802 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df_test = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D02': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D04': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D06': 'stairs_walking',\n",
    "    'D07': 'standing-sitting',\n",
    "    'D08': 'standing-sitting',\n",
    "    'F01': 'fall',\n",
    "    'F02': 'fall',\n",
    "    'F06': 'fall',\n",
    "    'F05': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = '../data/SisFall_dataset'\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        # user_ID가 'SA' 또는 'SE'로 시작하고 뒤에 오는 숫자가 6이거나 7인 경우에만 처리\n",
    "        if (user_ID.startswith('SA') or user_ID.startswith('SE')) and user_ID[2:].isdigit() and int(user_ID[2:]) in [8, 9]:\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                if file_name.endswith('.txt'):\n",
    "                    # 파일 경로\n",
    "                    file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                    # 파일 이름에 대한 정보\n",
    "                    activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                    trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                    # task_id가 D01, D04, D05, D07, F05, F06인 경우에만 처리\n",
    "                    if activity in ['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'F01', 'F02', 'F05', 'F06']:\n",
    "                        # task_id에 해당하는 label 정보\n",
    "                        task_ID = activity\n",
    "                        label = label_mapping[task_ID]\n",
    "\n",
    "                        # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                        Range = 2000  # 예시 값을 사용\n",
    "                        Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                        # 파일에서 데이터를 읽어와서 처리\n",
    "                        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                            lines = file.readlines()\n",
    "\n",
    "                        # 데이터 파싱 및 계산\n",
    "                        gx_values = []\n",
    "                        gy_values = []\n",
    "                        gz_values = []\n",
    "\n",
    "                        # 데이터 파싱 및 DataFrame에 추가\n",
    "                        for i, line in enumerate(lines):\n",
    "                            if i % 10 == 0:  # 10의 배수인 행만 처리\n",
    "                                # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                                fields = line.strip().split(',')\n",
    "\n",
    "                                if len(fields) >= 6:  # 필드 수 확인\n",
    "                                    # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                    gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                    gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                    gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                    gx_values.append(gx_value)\n",
    "                                    gy_values.append(gy_value)\n",
    "                                    gz_values.append(gz_value)\n",
    "\n",
    "                                    if len(gx_values) == 1:\n",
    "                                        # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                        df_test.loc[len(df_test)] = {\n",
    "                                            'user_ID': user_ID,\n",
    "                                            'trial_ID': trial_ID,\n",
    "                                            'task_ID': task_ID,\n",
    "                                            'gx': gx_values[0],\n",
    "                                            'gy': gy_values[0],\n",
    "                                            'gz': gz_values[0],\n",
    "                                            'label': label\n",
    "                                        }\n",
    "                                        record_count += 1\n",
    "                                        gx_values = []\n",
    "                                        gy_values = []\n",
    "                                        gz_values = []\n",
    "\n",
    "print(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-10T07:13:45.832325300Z",
     "start_time": "2023-06-10T06:27:33.678589900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz' 열의 데이터 추출\n",
    "data = df_test[['gx', 'gy', 'gz']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df_test['scaled_gx'] = scaled_data[:, 0]\n",
    "df_test['scaled_gy'] = scaled_data[:, 1]\n",
    "df_test['scaled_gz'] = scaled_data[:, 2]\n",
    "\n",
    "print(df_test.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_train.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_test_L.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-10T07:15:17.721845Z",
     "start_time": "2023-06-10T07:15:15.492526700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_test_L_20.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# DataFrame 초기화\n",
    "df_val = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'ax', 'ay', 'az', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D02': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D04': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D06': 'stairs_walking',\n",
    "    'D07': 'standing-sitting',\n",
    "    'D08': 'standing-sitting',\n",
    "    'F01': 'fall',\n",
    "    'F02': 'fall',\n",
    "    'F06': 'fall',\n",
    "    'F05': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = '../data/SisFall_dataset'\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        # user_ID가 'SA' 또는 'SE'로 시작하고 뒤에 오는 숫자가 7이나 8인 경우 처리\n",
    "        if user_ID.startswith('SA') or user_ID.startswith('SE'):\n",
    "            numeric_part = user_ID[2:]\n",
    "            if numeric_part.isdigit() and int(numeric_part) in [6, 9]:\n",
    "                for file_name in os.listdir(dir_path):\n",
    "                    if file_name.endswith('.txt'):\n",
    "                        # 파일 경로\n",
    "                        file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                        # 파일 이름에 대한 정보\n",
    "                        activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                        trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                        if activity in ['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'F01', 'F02', 'F05', 'F06']:\n",
    "                            # task_id에 해당하는 label 정보\n",
    "                            task_ID = activity\n",
    "                            label = label_mapping[task_ID]\n",
    "\n",
    "                            # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                            Range = 2000  # 예시 값을 사용\n",
    "                            Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                            range_g = 16  # range for ADXL345 when set to ±16g\n",
    "                            resolution_bits = 13  # resolution for ADXL345\n",
    "\n",
    "                            # 파일에서 데이터를 읽어와서 처리\n",
    "                            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                                lines = file.readlines()\n",
    "\n",
    "                            # 데이터 파싱 및 계산\n",
    "                            gx_values = []\n",
    "                            gy_values = []\n",
    "                            gz_values = []\n",
    "\n",
    "                            ax_values = []\n",
    "                            ay_values = []\n",
    "                            az_values = []\n",
    "\n",
    "                            # 데이터 파싱 및 DataFrame에 추가\n",
    "                            for i, line in enumerate(lines):\n",
    "                                if i % 20 == 0:  # 10의 배수인 행만 처리\n",
    "                                    # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                                    fields = line.strip().split(',')\n",
    "\n",
    "                                    if len(fields) >= 6:  # 필드 수 확인\n",
    "                                        # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                        gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                        gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                        gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                        ax_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[0])\n",
    "                                        ay_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[1])\n",
    "                                        az_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[2])\n",
    "\n",
    "                                        gx_values.append(gx_value)\n",
    "                                        gy_values.append(gy_value)\n",
    "                                        gz_values.append(gz_value)\n",
    "\n",
    "                                        ax_values.append(ax_value)\n",
    "                                        ay_values.append(ay_value)\n",
    "                                        az_values.append(az_value)\n",
    "\n",
    "                                        if len(gx_values) == 1:\n",
    "                                            # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                            df_val.loc[len(df_val)] = {\n",
    "                                                'user_ID': user_ID,\n",
    "                                                'trial_ID': trial_ID,\n",
    "                                                'task_ID': task_ID,\n",
    "                                                'gx': gx_values[0],\n",
    "                                                'gy': gy_values[0],\n",
    "                                                'gz': gz_values[0],\n",
    "                                                'ax': ax_values[0],\n",
    "                                                'ay': ay_values[0],\n",
    "                                                'az': az_values[0],\n",
    "                                                'label': label\n",
    "                                            }\n",
    "                                            record_count += 1\n",
    "\n",
    "                                            gx_values = []\n",
    "                                            gy_values = []\n",
    "                                            gz_values = []\n",
    "\n",
    "                                            ax_values = []\n",
    "                                            ay_values = []\n",
    "                                            az_values = []\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz', 'ax', 'ay', 'az' 열의 데이터 추출\n",
    "data = df_val[['gx', 'gy', 'gz', 'ax', 'ay', 'az']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df_val['scaled_gx'] = scaled_data[:, 0]\n",
    "df_val['scaled_gy'] = scaled_data[:, 1]\n",
    "df_val['scaled_gz'] = scaled_data[:, 2]\n",
    "df_val['scaled_ax'] = scaled_data[:, 3]\n",
    "df_val['scaled_ay'] = scaled_data[:, 4]\n",
    "df_val['scaled_az'] = scaled_data[:, 5]\n",
    "\n",
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_test_L_20.csv'\n",
    "df_val.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T06:38:00.401703400Z",
     "start_time": "2023-06-14T06:37:02.090284500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_test_L_19.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# DataFrame 초기화\n",
    "df_val = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'ax', 'ay', 'az', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D02': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D04': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D06': 'stairs_walking',\n",
    "    'D07': 'standing-sitting',\n",
    "    'D08': 'standing-sitting',\n",
    "    'F01': 'fall',\n",
    "    'F02': 'fall',\n",
    "    'F06': 'fall',\n",
    "    'F05': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = '../data/SisFall_dataset'\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        # user_ID가 'SA' 또는 'SE'로 시작하고 뒤에 오는 숫자가 7이나 8인 경우 처리\n",
    "        if user_ID.startswith('SA') or user_ID.startswith('SE'):\n",
    "            numeric_part = user_ID[2:]\n",
    "            if numeric_part.isdigit() and int(numeric_part) in [6,4,9]:\n",
    "                for file_name in os.listdir(dir_path):\n",
    "                    if file_name.endswith('.txt'):\n",
    "                        # 파일 경로\n",
    "                        file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                        # 파일 이름에 대한 정보\n",
    "                        activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                        trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                        if activity in ['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'F01', 'F02', 'F05', 'F06']:\n",
    "                            # task_id에 해당하는 label 정보\n",
    "                            task_ID = activity\n",
    "                            label = label_mapping[task_ID]\n",
    "\n",
    "                            # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                            Range = 2000  # 예시 값을 사용\n",
    "                            Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                            range_g = 16  # range for ADXL345 when set to ±16g\n",
    "                            resolution_bits = 13  # resolution for ADXL345\n",
    "\n",
    "                            # 파일에서 데이터를 읽어와서 처리\n",
    "                            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                                lines = file.readlines()\n",
    "\n",
    "                            # 데이터 파싱 및 계산\n",
    "                            gx_values = []\n",
    "                            gy_values = []\n",
    "                            gz_values = []\n",
    "\n",
    "                            ax_values = []\n",
    "                            ay_values = []\n",
    "                            az_values = []\n",
    "\n",
    "                            # 데이터 파싱 및 DataFrame에 추가\n",
    "                            for i, line in enumerate(lines):\n",
    "                                if i % 19 == 0:  # 10의 배수인 행만 처리\n",
    "                                    # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                                    fields = line.strip().split(',')\n",
    "\n",
    "                                    if len(fields) >= 6:  # 필드 수 확인\n",
    "                                        # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                        gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                        gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                        gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                        ax_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[0])\n",
    "                                        ay_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[1])\n",
    "                                        az_value = (2 * range_g / (2 ** resolution_bits)) * float(fields[2])\n",
    "\n",
    "                                        gx_values.append(gx_value)\n",
    "                                        gy_values.append(gy_value)\n",
    "                                        gz_values.append(gz_value)\n",
    "\n",
    "                                        ax_values.append(ax_value)\n",
    "                                        ay_values.append(ay_value)\n",
    "                                        az_values.append(az_value)\n",
    "\n",
    "                                        if len(gx_values) == 1:\n",
    "                                            # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                            df_val.loc[len(df_val)] = {\n",
    "                                                'user_ID': user_ID,\n",
    "                                                'trial_ID': trial_ID,\n",
    "                                                'task_ID': task_ID,\n",
    "                                                'gx': gx_values[0],\n",
    "                                                'gy': gy_values[0],\n",
    "                                                'gz': gz_values[0],\n",
    "                                                'ax': ax_values[0],\n",
    "                                                'ay': ay_values[0],\n",
    "                                                'az': az_values[0],\n",
    "                                                'label': label\n",
    "                                            }\n",
    "                                            record_count += 1\n",
    "\n",
    "                                            gx_values = []\n",
    "                                            gy_values = []\n",
    "                                            gz_values = []\n",
    "\n",
    "                                            ax_values = []\n",
    "                                            ay_values = []\n",
    "                                            az_values = []\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz', 'ax', 'ay', 'az' 열의 데이터 추출\n",
    "data = df_val[['gx', 'gy', 'gz', 'ax', 'ay', 'az']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df_val['scaled_gx'] = scaled_data[:, 0]\n",
    "df_val['scaled_gy'] = scaled_data[:, 1]\n",
    "df_val['scaled_gz'] = scaled_data[:, 2]\n",
    "df_val['scaled_ax'] = scaled_data[:, 3]\n",
    "df_val['scaled_ay'] = scaled_data[:, 4]\n",
    "df_val['scaled_az'] = scaled_data[:, 5]\n",
    "\n",
    "# CSV 파일로 저장\n",
    "csv_path = '../data/SisFall_test_L_19.csv'\n",
    "df_val.to_csv(csv_path, index=False)\n",
    "print('CSV 파일이 저장되었습니다:', csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T07:15:04.229844400Z",
     "start_time": "2023-06-14T07:13:16.061038200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
