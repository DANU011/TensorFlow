{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_ID trial_ID task_ID        gx         gy         gz     label\n",
      "0        SA01      R01     D01 -1.098633 -30.761719 -21.484375   walking\n",
      "1        SA01      R01     D01 -3.234863 -34.667969 -18.676758   walking\n",
      "2        SA01      R01     D01 -5.126953 -37.414551 -16.540527   walking\n",
      "3        SA01      R01     D01 -6.347656 -39.489746 -13.854980   walking\n",
      "4        SA01      R01     D01 -7.812500 -41.198730 -11.657715   walking\n",
      "...       ...      ...     ...       ...        ...        ...       ...\n",
      "23035    SE15      R05     D07 -2.380371   5.981445   0.305176  standing\n",
      "23036    SE15      R05     D07 -2.197266   6.408691   0.366211  standing\n",
      "23037    SE15      R05     D07 -1.892090   6.835938   0.427246  standing\n",
      "23038    SE15      R05     D07 -1.647949   7.263184   0.427246  standing\n",
      "23039    SE15      R05     D07 -1.525879   7.568359   0.427246  standing\n",
      "\n",
      "[23040 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = \"../data/SisFall_dataset\"\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D03, D05, D07, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D03', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    for line in lines:\n",
    "                        # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                        fields = line.strip().split(',')\n",
    "\n",
    "                        # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                        gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                        gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                        gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                        gx_values.append(gx_value)\n",
    "                        gy_values.append(gy_value)\n",
    "                        gz_values.append(gz_value)\n",
    "\n",
    "                        if len(gx_values) == 1:\n",
    "                            # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                            df.loc[len(df)] = {\n",
    "                                'user_ID': user_ID,\n",
    "                                'trial_ID': trial_ID,\n",
    "                                'task_ID': task_ID,\n",
    "                                'gx': gx_values[0],\n",
    "                                'gy': gy_values[0],\n",
    "                                'gz': gz_values[0],\n",
    "                                'label': label\n",
    "                            }\n",
    "                            record_count += 1\n",
    "                            gx_values = []\n",
    "                            gy_values = []\n",
    "                            gz_values = []\n",
    "\n",
    "                            if record_count == 40:\n",
    "                                # 40개의 레코드 처리가 완료되었으므로 다음 파일 처리\n",
    "                                record_count = 0\n",
    "                                break\n",
    "\n",
    "                if record_count == 40:\n",
    "                    # 40개의 레코드 처리가 완료되었으므로 다음 파일 처리\n",
    "                    break\n",
    "\n",
    "        if record_count == 40:\n",
    "            # 40개의 레코드 처리가 완료되었으므로 다음 파일 처리\n",
    "            break\n",
    "\n",
    "    if record_count == 40:\n",
    "        # 40개의 레코드 처리가 완료되었으므로 다음 파일 처리\n",
    "        break\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T03:58:23.574284300Z",
     "start_time": "2023-06-07T03:57:56.094297500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_df.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = \"../data/SisFall_df.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"CSV 파일이 저장되었습니다:\", csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T03:58:40.608111900Z",
     "start_time": "2023-06-07T03:58:40.514389700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_shuffled = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Split data into input features (X) and target variable (y)\n",
    "X = df_shuffled[['gx', 'gy', 'gz']].values\n",
    "y = df_shuffled['label'].values\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert encoded labels to one-hot encoding\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T03:58:50.783009700Z",
     "start_time": "2023-06-07T03:58:45.149642600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(3, 1), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T03:59:04.566365600Z",
     "start_time": "2023-06-07T03:59:02.455628500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "576/576 [==============================] - 4s 2ms/step - loss: 1.3098 - accuracy: 0.4277\n",
      "Epoch 2/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2512 - accuracy: 0.4579\n",
      "Epoch 3/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2297 - accuracy: 0.4692\n",
      "Epoch 4/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2099 - accuracy: 0.4870\n",
      "Epoch 5/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1905 - accuracy: 0.4980\n",
      "Epoch 6/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1740 - accuracy: 0.5023\n",
      "Epoch 7/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1611 - accuracy: 0.5092\n",
      "Epoch 8/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1487 - accuracy: 0.5104\n",
      "Epoch 9/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1387 - accuracy: 0.5157\n",
      "Epoch 10/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1278 - accuracy: 0.5250\n",
      "144/144 [==============================] - 1s 1ms/step - loss: 1.0814 - accuracy: 0.5384\n",
      "Test Loss: 1.0814\n",
      "Test Accuracy: 0.5384\n"
     ]
    }
   ],
   "source": [
    "# Reshape input features to match the expected shape of the LSTM model\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Train the LSTM model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T03:59:27.555190200Z",
     "start_time": "2023-06-07T03:59:12.124271400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "576/576 [==============================] - 4s 2ms/step - loss: 1.3078 - accuracy: 0.4255\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2490 - accuracy: 0.4590\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2243 - accuracy: 0.4773\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2021 - accuracy: 0.4868\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1889 - accuracy: 0.4962\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1726 - accuracy: 0.5046\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1559 - accuracy: 0.5133\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1451 - accuracy: 0.5188\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1311 - accuracy: 0.5258\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1257 - accuracy: 0.5270\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1182 - accuracy: 0.5280\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1062 - accuracy: 0.5360\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1012 - accuracy: 0.5353\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0941 - accuracy: 0.5397\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0911 - accuracy: 0.5434\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0864 - accuracy: 0.5438\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0818 - accuracy: 0.5442\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0744 - accuracy: 0.5503\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0696 - accuracy: 0.5526\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0670 - accuracy: 0.5520\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0631 - accuracy: 0.5532\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0600 - accuracy: 0.5557\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0550 - accuracy: 0.5574\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0555 - accuracy: 0.5609\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0502 - accuracy: 0.5628\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0456 - accuracy: 0.5637\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0446 - accuracy: 0.5635\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0427 - accuracy: 0.5654\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0393 - accuracy: 0.5683\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0346 - accuracy: 0.5671\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0297 - accuracy: 0.5696\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0230 - accuracy: 0.5769\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0277 - accuracy: 0.5733\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0207 - accuracy: 0.5751\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0148 - accuracy: 0.5810\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0133 - accuracy: 0.5802\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0154 - accuracy: 0.5792\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0110 - accuracy: 0.5794\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0091 - accuracy: 0.5803\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0078 - accuracy: 0.5836\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0007 - accuracy: 0.5830\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9996 - accuracy: 0.5859\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9990 - accuracy: 0.5845\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9969 - accuracy: 0.5856\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9960 - accuracy: 0.5864\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9929 - accuracy: 0.5915\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9899 - accuracy: 0.5915\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9908 - accuracy: 0.5867\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9881 - accuracy: 0.5911\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9873 - accuracy: 0.5934\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9838 - accuracy: 0.5945\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9840 - accuracy: 0.5924\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9768 - accuracy: 0.5961\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9813 - accuracy: 0.5975\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9800 - accuracy: 0.5956\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9721 - accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9731 - accuracy: 0.6012\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9706 - accuracy: 0.6021\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9703 - accuracy: 0.5971\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9681 - accuracy: 0.6015\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9646 - accuracy: 0.6004\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9693 - accuracy: 0.5996\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9594 - accuracy: 0.6022\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9668 - accuracy: 0.6016\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9618 - accuracy: 0.5988\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9548 - accuracy: 0.6063\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9568 - accuracy: 0.6042\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9519 - accuracy: 0.6081\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9555 - accuracy: 0.6061\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9520 - accuracy: 0.6074\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9498 - accuracy: 0.6085\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9559 - accuracy: 0.6066\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9508 - accuracy: 0.6092\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9465 - accuracy: 0.6074\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9481 - accuracy: 0.6054\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9451 - accuracy: 0.6074\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9405 - accuracy: 0.6130\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9387 - accuracy: 0.6104\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9412 - accuracy: 0.6131\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9387 - accuracy: 0.6136\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9405 - accuracy: 0.6125\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9362 - accuracy: 0.6113\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9301 - accuracy: 0.6156\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9374 - accuracy: 0.6132\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9335 - accuracy: 0.6137\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9319 - accuracy: 0.6155\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9300 - accuracy: 0.6119\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9314 - accuracy: 0.6158\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9321 - accuracy: 0.6118\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9232 - accuracy: 0.6168\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9339 - accuracy: 0.6158\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9256 - accuracy: 0.6205\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9292 - accuracy: 0.6117\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9234 - accuracy: 0.6188\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9246 - accuracy: 0.6199\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9177 - accuracy: 0.6225\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9178 - accuracy: 0.6236\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9187 - accuracy: 0.6206\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9213 - accuracy: 0.6197\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9179 - accuracy: 0.6260\n",
      "576/576 [==============================] - 2s 1ms/step - loss: 0.8109 - accuracy: 0.6672\n",
      "Train Loss: 0.8109\n",
      "Train Accuracy: 0.6672\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.8799 - accuracy: 0.6439\n",
      "Test Loss: 0.8799\n",
      "Test Accuracy: 0.6439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# DataFrame을 무작위로 섞기\n",
    "df_shuffled = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# 데이터를 입력 특성 (X)과 타겟 변수 (y)로 분할하기\n",
    "X = df_shuffled[['gx', 'gy', 'gz']].values\n",
    "y = df_shuffled['label'].values\n",
    "\n",
    "# 레이블을 인코딩하기 위해 LabelEncoder 사용\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 인코딩된 레이블을 원-핫 인코딩으로 변환하기\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# 입력 특성을 LSTM 모델의 예상 형태로 재구성\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(3, 1), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# LSTM 모델 훈련\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# 훈련 데이터에서 모델 평가\n",
    "train_loss, train_accuracy = model.evaluate(X_train_reshaped, y_train)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# 테스트 데이터에서 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T04:05:11.866573700Z",
     "start_time": "2023-06-07T04:03:07.678757500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "576/576 [==============================] - 4s 2ms/step - loss: 1.3131 - accuracy: 0.4223\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2505 - accuracy: 0.4562\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2280 - accuracy: 0.4720\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2093 - accuracy: 0.4856\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1935 - accuracy: 0.4913\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1761 - accuracy: 0.4988\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1578 - accuracy: 0.5086\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1481 - accuracy: 0.5124\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1369 - accuracy: 0.5184\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1291 - accuracy: 0.5236\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1169 - accuracy: 0.5295\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1098 - accuracy: 0.5339\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1069 - accuracy: 0.5334\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1005 - accuracy: 0.5347\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0883 - accuracy: 0.5414\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0896 - accuracy: 0.5432\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0835 - accuracy: 0.5416\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0767 - accuracy: 0.5492\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0708 - accuracy: 0.5489\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0700 - accuracy: 0.5533\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0657 - accuracy: 0.5546\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0619 - accuracy: 0.5530\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0595 - accuracy: 0.5576\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0520 - accuracy: 0.5584\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0497 - accuracy: 0.5607\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0463 - accuracy: 0.5610\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0454 - accuracy: 0.5639\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0403 - accuracy: 0.5656\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0365 - accuracy: 0.5694\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0340 - accuracy: 0.5666\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0287 - accuracy: 0.5693\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0280 - accuracy: 0.5697\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0236 - accuracy: 0.5710\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0233 - accuracy: 0.5738\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0216 - accuracy: 0.5752\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0165 - accuracy: 0.5754\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0145 - accuracy: 0.5778\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0118 - accuracy: 0.5775\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0072 - accuracy: 0.5798\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0075 - accuracy: 0.5782\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0017 - accuracy: 0.5854\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0034 - accuracy: 0.5840\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0003 - accuracy: 0.5822\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0006 - accuracy: 0.5828\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9978 - accuracy: 0.5839\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9931 - accuracy: 0.5871\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9902 - accuracy: 0.5859\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9922 - accuracy: 0.5866\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9882 - accuracy: 0.5901\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9849 - accuracy: 0.5900\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9842 - accuracy: 0.5924\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9862 - accuracy: 0.5913\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9840 - accuracy: 0.5924\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9792 - accuracy: 0.5942\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9768 - accuracy: 0.5951\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9770 - accuracy: 0.5957\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9720 - accuracy: 0.5971\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9785 - accuracy: 0.5944\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9672 - accuracy: 0.6004\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9709 - accuracy: 0.5968\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9666 - accuracy: 0.6003\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9655 - accuracy: 0.5991\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9625 - accuracy: 0.5977\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9653 - accuracy: 0.6027\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9598 - accuracy: 0.6042\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9639 - accuracy: 0.6010\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9579 - accuracy: 0.6040\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9575 - accuracy: 0.6057\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9584 - accuracy: 0.6054\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9568 - accuracy: 0.6038\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9538 - accuracy: 0.6035\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9510 - accuracy: 0.6057\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9461 - accuracy: 0.6084\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9501 - accuracy: 0.6051\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9460 - accuracy: 0.6066\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9471 - accuracy: 0.6092\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9451 - accuracy: 0.6073\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9424 - accuracy: 0.6079\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9409 - accuracy: 0.6158\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9377 - accuracy: 0.6127\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9357 - accuracy: 0.6140\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9396 - accuracy: 0.6126\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9342 - accuracy: 0.6097\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9366 - accuracy: 0.6143\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9357 - accuracy: 0.6135\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9333 - accuracy: 0.6145\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9274 - accuracy: 0.6184\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9331 - accuracy: 0.6151\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9319 - accuracy: 0.6100\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9274 - accuracy: 0.6136\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9265 - accuracy: 0.6204\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9273 - accuracy: 0.6177\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9235 - accuracy: 0.6176\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9250 - accuracy: 0.6184\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9275 - accuracy: 0.6142\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9255 - accuracy: 0.6143\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9219 - accuracy: 0.6178\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9206 - accuracy: 0.6164\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9219 - accuracy: 0.6174\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9191 - accuracy: 0.6207\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9146 - accuracy: 0.6197\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9198 - accuracy: 0.6202\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9142 - accuracy: 0.6230\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9168 - accuracy: 0.6233\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9143 - accuracy: 0.6223\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9107 - accuracy: 0.6228\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9158 - accuracy: 0.6247\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9162 - accuracy: 0.6221\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9081 - accuracy: 0.6261\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9101 - accuracy: 0.6221\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9117 - accuracy: 0.6242\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9095 - accuracy: 0.6242\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9091 - accuracy: 0.6230\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9068 - accuracy: 0.6268\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9066 - accuracy: 0.6267\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9050 - accuracy: 0.6276\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9068 - accuracy: 0.6267\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9093 - accuracy: 0.6240\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9053 - accuracy: 0.6279\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9033 - accuracy: 0.6277\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9009 - accuracy: 0.6280\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9027 - accuracy: 0.6265\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8993 - accuracy: 0.6305\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8993 - accuracy: 0.6280\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8999 - accuracy: 0.6325\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8957 - accuracy: 0.6328\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9013 - accuracy: 0.6286\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8965 - accuracy: 0.6302\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8996 - accuracy: 0.6297\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9013 - accuracy: 0.6308\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8944 - accuracy: 0.6299\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8981 - accuracy: 0.6281\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8969 - accuracy: 0.6351\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8912 - accuracy: 0.6332\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8996 - accuracy: 0.6322\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8898 - accuracy: 0.6340\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8876 - accuracy: 0.6385\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8910 - accuracy: 0.6325\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8901 - accuracy: 0.6324\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8936 - accuracy: 0.6361\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8890 - accuracy: 0.6325\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8894 - accuracy: 0.6357\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8926 - accuracy: 0.6341\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8864 - accuracy: 0.6336\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8853 - accuracy: 0.6362\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8866 - accuracy: 0.6368\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8880 - accuracy: 0.6351\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8813 - accuracy: 0.6361\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8882 - accuracy: 0.6359\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8853 - accuracy: 0.6345\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8863 - accuracy: 0.6373\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8871 - accuracy: 0.6388\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8804 - accuracy: 0.6384\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8810 - accuracy: 0.6359\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8837 - accuracy: 0.6394\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8771 - accuracy: 0.6394\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8834 - accuracy: 0.6385\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8785 - accuracy: 0.6381\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8780 - accuracy: 0.6388\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8814 - accuracy: 0.6381\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8769 - accuracy: 0.6419\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8799 - accuracy: 0.6408\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8737 - accuracy: 0.6415\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8710 - accuracy: 0.6456\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8759 - accuracy: 0.6428\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8793 - accuracy: 0.6382\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8756 - accuracy: 0.6379\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8745 - accuracy: 0.6424\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8766 - accuracy: 0.6435\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8736 - accuracy: 0.6438\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8745 - accuracy: 0.6389\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8758 - accuracy: 0.6401\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8690 - accuracy: 0.6429\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8755 - accuracy: 0.6437\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8687 - accuracy: 0.6440\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8731 - accuracy: 0.6438\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8747 - accuracy: 0.6428\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8711 - accuracy: 0.6408\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8631 - accuracy: 0.6458\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8652 - accuracy: 0.6444\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8664 - accuracy: 0.6424\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8674 - accuracy: 0.6433\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8687 - accuracy: 0.6413\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8704 - accuracy: 0.6414\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8671 - accuracy: 0.6417\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8613 - accuracy: 0.6477\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8694 - accuracy: 0.6430\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8627 - accuracy: 0.6481\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8558 - accuracy: 0.6495\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8651 - accuracy: 0.6483\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8662 - accuracy: 0.6449\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8600 - accuracy: 0.6468\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8607 - accuracy: 0.6473\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8531 - accuracy: 0.6495\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8603 - accuracy: 0.6462\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8610 - accuracy: 0.6465\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8671 - accuracy: 0.6456\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8622 - accuracy: 0.6464\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8618 - accuracy: 0.6466\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8622 - accuracy: 0.6445\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8575 - accuracy: 0.6463\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8587 - accuracy: 0.6475\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8623 - accuracy: 0.6456\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8604 - accuracy: 0.6471\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8547 - accuracy: 0.6494\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8655 - accuracy: 0.6439\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8599 - accuracy: 0.6474\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8517 - accuracy: 0.6515\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8595 - accuracy: 0.6456\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8540 - accuracy: 0.6487\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8521 - accuracy: 0.6490\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8529 - accuracy: 0.6485\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8592 - accuracy: 0.6475\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8509 - accuracy: 0.6479\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8570 - accuracy: 0.6506\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8462 - accuracy: 0.6530\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8525 - accuracy: 0.6524\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8515 - accuracy: 0.6495\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8525 - accuracy: 0.6500\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8545 - accuracy: 0.6478\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8478 - accuracy: 0.6527\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8540 - accuracy: 0.6500\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8489 - accuracy: 0.6521\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8489 - accuracy: 0.6514\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8500 - accuracy: 0.6502\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8499 - accuracy: 0.6512\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8439 - accuracy: 0.6549\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8527 - accuracy: 0.6492\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8559 - accuracy: 0.6469\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8530 - accuracy: 0.6517\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8547 - accuracy: 0.6535\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8539 - accuracy: 0.6517\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8522 - accuracy: 0.6494\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8437 - accuracy: 0.6542\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8512 - accuracy: 0.6516\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8488 - accuracy: 0.6492\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8447 - accuracy: 0.6515\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8465 - accuracy: 0.6522\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8422 - accuracy: 0.6553\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8449 - accuracy: 0.6521\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8419 - accuracy: 0.6562\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8474 - accuracy: 0.6515\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8475 - accuracy: 0.6539\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8494 - accuracy: 0.6570\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8428 - accuracy: 0.6558\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8419 - accuracy: 0.6566\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8489 - accuracy: 0.6532\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8492 - accuracy: 0.6491\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8412 - accuracy: 0.6555\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.6555\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8454 - accuracy: 0.6540\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8388 - accuracy: 0.6567\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8439 - accuracy: 0.6541\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.6525\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8358 - accuracy: 0.6573\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8368 - accuracy: 0.6580\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8367 - accuracy: 0.6555\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8411 - accuracy: 0.6536\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8423 - accuracy: 0.6561\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8381 - accuracy: 0.6585\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8364 - accuracy: 0.6566\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8380 - accuracy: 0.6555\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8413 - accuracy: 0.6537\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8314 - accuracy: 0.6602\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8363 - accuracy: 0.6581\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8350 - accuracy: 0.6615\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8322 - accuracy: 0.6626\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8388 - accuracy: 0.6549\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8366 - accuracy: 0.6617\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8392 - accuracy: 0.6535\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8365 - accuracy: 0.6576\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8403 - accuracy: 0.6549\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8344 - accuracy: 0.6573\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8311 - accuracy: 0.6602\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8380 - accuracy: 0.6560\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8351 - accuracy: 0.6575\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8340 - accuracy: 0.6621\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8294 - accuracy: 0.6616\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8337 - accuracy: 0.6600\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8310 - accuracy: 0.6593\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8305 - accuracy: 0.6640\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8263 - accuracy: 0.6643\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8383 - accuracy: 0.6588\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8329 - accuracy: 0.6581\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8284 - accuracy: 0.6584\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8366 - accuracy: 0.6611\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8311 - accuracy: 0.6574\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8298 - accuracy: 0.6561\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8270 - accuracy: 0.6597\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8261 - accuracy: 0.6608\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8358 - accuracy: 0.6554\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8281 - accuracy: 0.6611\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8265 - accuracy: 0.6648\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8292 - accuracy: 0.6644\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8263 - accuracy: 0.6642\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8286 - accuracy: 0.6613\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8330 - accuracy: 0.6611\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8303 - accuracy: 0.6632\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8204 - accuracy: 0.6630\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8270 - accuracy: 0.6625\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8276 - accuracy: 0.6595\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8276 - accuracy: 0.6613\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8213 - accuracy: 0.6666\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8212 - accuracy: 0.6636\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8234 - accuracy: 0.6653\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8300 - accuracy: 0.6607\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8297 - accuracy: 0.6642\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8253 - accuracy: 0.6653\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8259 - accuracy: 0.6622\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8250 - accuracy: 0.6677\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8240 - accuracy: 0.6641\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8338 - accuracy: 0.6588\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8254 - accuracy: 0.6634\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8139 - accuracy: 0.6664\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8196 - accuracy: 0.6644\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8239 - accuracy: 0.6638\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8284 - accuracy: 0.6655\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8250 - accuracy: 0.6664\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8246 - accuracy: 0.6625\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8197 - accuracy: 0.6641\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8223 - accuracy: 0.6624\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8294 - accuracy: 0.6604\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8210 - accuracy: 0.6625\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8205 - accuracy: 0.6663\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8177 - accuracy: 0.6644\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8152 - accuracy: 0.6699\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8217 - accuracy: 0.6636\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8258 - accuracy: 0.6657\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8205 - accuracy: 0.6659\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8227 - accuracy: 0.6644\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8152 - accuracy: 0.6686\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8213 - accuracy: 0.6669\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8214 - accuracy: 0.6638\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8189 - accuracy: 0.6655\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8248 - accuracy: 0.6635\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8212 - accuracy: 0.6646\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8126 - accuracy: 0.6683\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8154 - accuracy: 0.6683\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8145 - accuracy: 0.6680\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8197 - accuracy: 0.6648\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8170 - accuracy: 0.6698\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8180 - accuracy: 0.6682\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8186 - accuracy: 0.6686\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8175 - accuracy: 0.6662\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8181 - accuracy: 0.6656\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8168 - accuracy: 0.6648\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8147 - accuracy: 0.6670\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8192 - accuracy: 0.6672\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8151 - accuracy: 0.6660\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8137 - accuracy: 0.6692\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8094 - accuracy: 0.6682\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8135 - accuracy: 0.6669\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8200 - accuracy: 0.6683\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8201 - accuracy: 0.6659\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8111 - accuracy: 0.6697\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8144 - accuracy: 0.6717\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8156 - accuracy: 0.6698\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8132 - accuracy: 0.6686\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8123 - accuracy: 0.6681\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8146 - accuracy: 0.6685\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8110 - accuracy: 0.6702\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8134 - accuracy: 0.6655\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8141 - accuracy: 0.6675\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8105 - accuracy: 0.6720\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8098 - accuracy: 0.6705\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8136 - accuracy: 0.6693\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8104 - accuracy: 0.6699\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8106 - accuracy: 0.6692\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8115 - accuracy: 0.6711\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8092 - accuracy: 0.6705\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8133 - accuracy: 0.6682\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8104 - accuracy: 0.6713\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8105 - accuracy: 0.6701\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8181 - accuracy: 0.6633\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8119 - accuracy: 0.6668\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8103 - accuracy: 0.6724\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8058 - accuracy: 0.6701\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8116 - accuracy: 0.6731\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8051 - accuracy: 0.6731\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8062 - accuracy: 0.6697\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8174 - accuracy: 0.6707\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8086 - accuracy: 0.6680\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8053 - accuracy: 0.6742\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8030 - accuracy: 0.6758\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8085 - accuracy: 0.6691\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8113 - accuracy: 0.6715\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8062 - accuracy: 0.6729\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8123 - accuracy: 0.6738\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8057 - accuracy: 0.6734\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8060 - accuracy: 0.6732\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8114 - accuracy: 0.6722\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8018 - accuracy: 0.6717\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8063 - accuracy: 0.6689\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8020 - accuracy: 0.6717\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8127 - accuracy: 0.6700\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8048 - accuracy: 0.6738\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8088 - accuracy: 0.6742\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8086 - accuracy: 0.6702\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8133 - accuracy: 0.6693\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8059 - accuracy: 0.6725\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8071 - accuracy: 0.6731\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8011 - accuracy: 0.6718\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8028 - accuracy: 0.6716\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8044 - accuracy: 0.6718\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8000 - accuracy: 0.6732\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8081 - accuracy: 0.6685\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8045 - accuracy: 0.6755\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8035 - accuracy: 0.6716\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7994 - accuracy: 0.6765\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7996 - accuracy: 0.6742\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8000 - accuracy: 0.6759\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8006 - accuracy: 0.6730\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8012 - accuracy: 0.6769\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8026 - accuracy: 0.6725\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8017 - accuracy: 0.6720\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8044 - accuracy: 0.6717\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8033 - accuracy: 0.6724\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7939 - accuracy: 0.6787\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8038 - accuracy: 0.6721\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8003 - accuracy: 0.6752\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8041 - accuracy: 0.6755\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8014 - accuracy: 0.6789\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8035 - accuracy: 0.6731\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7948 - accuracy: 0.6730\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7994 - accuracy: 0.6737\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8068 - accuracy: 0.6693\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8059 - accuracy: 0.6748\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8061 - accuracy: 0.6724\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7935 - accuracy: 0.6789\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8015 - accuracy: 0.6773\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7958 - accuracy: 0.6754\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7973 - accuracy: 0.6760\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8008 - accuracy: 0.6751\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8006 - accuracy: 0.6762\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8007 - accuracy: 0.6762\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7994 - accuracy: 0.6750\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7992 - accuracy: 0.6785\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7985 - accuracy: 0.6748\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8028 - accuracy: 0.6744\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7910 - accuracy: 0.6802\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7977 - accuracy: 0.6757\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8075 - accuracy: 0.6752\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7968 - accuracy: 0.6773\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7958 - accuracy: 0.6755\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7986 - accuracy: 0.6760\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7977 - accuracy: 0.6773\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7967 - accuracy: 0.6771\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7944 - accuracy: 0.6797\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7980 - accuracy: 0.6783\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7932 - accuracy: 0.6806\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7935 - accuracy: 0.6788\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7959 - accuracy: 0.6761\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7924 - accuracy: 0.6747\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7913 - accuracy: 0.6792\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7996 - accuracy: 0.6743\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7937 - accuracy: 0.6793\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7962 - accuracy: 0.6765\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7977 - accuracy: 0.6774\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7951 - accuracy: 0.6761\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7931 - accuracy: 0.6817\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7922 - accuracy: 0.6759\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7941 - accuracy: 0.6767\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7939 - accuracy: 0.6797\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7976 - accuracy: 0.6755\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7920 - accuracy: 0.6795\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7889 - accuracy: 0.6812\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7889 - accuracy: 0.6781\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7932 - accuracy: 0.6777\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7956 - accuracy: 0.6751\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7889 - accuracy: 0.6787\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7896 - accuracy: 0.6812\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.8007 - accuracy: 0.6755\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7919 - accuracy: 0.6779\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7902 - accuracy: 0.6811\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7914 - accuracy: 0.6764\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7853 - accuracy: 0.6796\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7946 - accuracy: 0.6780\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7903 - accuracy: 0.6816\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7882 - accuracy: 0.6792\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7925 - accuracy: 0.6787\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7868 - accuracy: 0.6794\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7897 - accuracy: 0.6781\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7894 - accuracy: 0.6782\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7919 - accuracy: 0.6765\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7911 - accuracy: 0.6843\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7907 - accuracy: 0.6785\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7862 - accuracy: 0.6819\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7823 - accuracy: 0.6819\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7930 - accuracy: 0.6797\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7843 - accuracy: 0.6813\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7908 - accuracy: 0.6801\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7895 - accuracy: 0.6800\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7955 - accuracy: 0.6800\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7882 - accuracy: 0.6802\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7913 - accuracy: 0.6806\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7816 - accuracy: 0.6837\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7885 - accuracy: 0.6777\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7854 - accuracy: 0.6782\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7937 - accuracy: 0.6785\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7990 - accuracy: 0.6733\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7829 - accuracy: 0.6844\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7868 - accuracy: 0.6799\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7924 - accuracy: 0.6821\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7874 - accuracy: 0.6804\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7814 - accuracy: 0.6846\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7909 - accuracy: 0.6755\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7896 - accuracy: 0.6791\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7866 - accuracy: 0.6820\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7840 - accuracy: 0.6844\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7874 - accuracy: 0.6830\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7882 - accuracy: 0.6793\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7909 - accuracy: 0.6754\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7870 - accuracy: 0.6810\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7836 - accuracy: 0.6832\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7871 - accuracy: 0.6807\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7802 - accuracy: 0.6846\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7846 - accuracy: 0.6813\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7883 - accuracy: 0.6874\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7837 - accuracy: 0.6832\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7885 - accuracy: 0.6805\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7847 - accuracy: 0.6800\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7820 - accuracy: 0.6799\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7821 - accuracy: 0.6818\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7833 - accuracy: 0.6851\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7880 - accuracy: 0.6778\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7798 - accuracy: 0.6816\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7783 - accuracy: 0.6845\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7910 - accuracy: 0.6805\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7856 - accuracy: 0.6823\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7851 - accuracy: 0.6781\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7759 - accuracy: 0.6848\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7883 - accuracy: 0.6844\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7786 - accuracy: 0.6838\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7773 - accuracy: 0.6892\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7799 - accuracy: 0.6827\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7820 - accuracy: 0.6810\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7821 - accuracy: 0.6849\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7849 - accuracy: 0.6825\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7845 - accuracy: 0.6829\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7869 - accuracy: 0.6813\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7819 - accuracy: 0.6822\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7885 - accuracy: 0.6763\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7834 - accuracy: 0.6793\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7830 - accuracy: 0.6829\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7794 - accuracy: 0.6845\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7759 - accuracy: 0.6852\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7728 - accuracy: 0.6881\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7810 - accuracy: 0.6833\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7789 - accuracy: 0.6866\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7796 - accuracy: 0.6814\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7818 - accuracy: 0.6851\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7807 - accuracy: 0.6803\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7803 - accuracy: 0.6839\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7786 - accuracy: 0.6816\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7767 - accuracy: 0.6870\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7796 - accuracy: 0.6843\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7809 - accuracy: 0.6819\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7767 - accuracy: 0.6841\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7775 - accuracy: 0.6848\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7719 - accuracy: 0.6858\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7781 - accuracy: 0.6850\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7835 - accuracy: 0.6848\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7760 - accuracy: 0.6848\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7780 - accuracy: 0.6837\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7817 - accuracy: 0.6835\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7796 - accuracy: 0.6857\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7771 - accuracy: 0.6865\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7805 - accuracy: 0.6857\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7813 - accuracy: 0.6859\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7761 - accuracy: 0.6848\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7751 - accuracy: 0.6878\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7783 - accuracy: 0.6858\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7811 - accuracy: 0.6868\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7748 - accuracy: 0.6848\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7759 - accuracy: 0.6837\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7750 - accuracy: 0.6825\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7749 - accuracy: 0.6874\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7772 - accuracy: 0.6843\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7784 - accuracy: 0.6831\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7714 - accuracy: 0.6892\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7756 - accuracy: 0.6854\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7749 - accuracy: 0.6876\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7793 - accuracy: 0.6857\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7748 - accuracy: 0.6887\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7787 - accuracy: 0.6829\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7733 - accuracy: 0.6855\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7772 - accuracy: 0.6839\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7752 - accuracy: 0.6872\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7781 - accuracy: 0.6852\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7725 - accuracy: 0.6866\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7708 - accuracy: 0.6866\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7722 - accuracy: 0.6883\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7772 - accuracy: 0.6879\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7650 - accuracy: 0.6884\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7760 - accuracy: 0.6847\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7791 - accuracy: 0.6827\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7837 - accuracy: 0.6816\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7738 - accuracy: 0.6899\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7730 - accuracy: 0.6848\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7782 - accuracy: 0.6835\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7757 - accuracy: 0.6852\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7687 - accuracy: 0.6889\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7738 - accuracy: 0.6859\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7715 - accuracy: 0.6866\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7674 - accuracy: 0.6896\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7732 - accuracy: 0.6848\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7687 - accuracy: 0.6899\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7787 - accuracy: 0.6797\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7723 - accuracy: 0.6889\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7661 - accuracy: 0.6908\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7715 - accuracy: 0.6916\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7714 - accuracy: 0.6861\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7733 - accuracy: 0.6838\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7763 - accuracy: 0.6848\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7703 - accuracy: 0.6884\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7673 - accuracy: 0.6874\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7713 - accuracy: 0.6870\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7696 - accuracy: 0.6872\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7698 - accuracy: 0.6875\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7731 - accuracy: 0.6866\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7706 - accuracy: 0.6888\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7771 - accuracy: 0.6859\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7734 - accuracy: 0.6840\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7685 - accuracy: 0.6897\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7644 - accuracy: 0.6888\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7741 - accuracy: 0.6892\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7701 - accuracy: 0.6848\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7718 - accuracy: 0.6932\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7727 - accuracy: 0.6872\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7718 - accuracy: 0.6901\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7681 - accuracy: 0.6923\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7707 - accuracy: 0.6899\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7757 - accuracy: 0.6876\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7676 - accuracy: 0.6891\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7738 - accuracy: 0.6867\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7691 - accuracy: 0.6893\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7669 - accuracy: 0.6930\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7660 - accuracy: 0.6929\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7692 - accuracy: 0.6909\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.6900\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7682 - accuracy: 0.6886\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7702 - accuracy: 0.6921\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7725 - accuracy: 0.6882\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7666 - accuracy: 0.6879\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7660 - accuracy: 0.6909\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7707 - accuracy: 0.6872\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7684 - accuracy: 0.6887\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7692 - accuracy: 0.6872\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7697 - accuracy: 0.6896\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7643 - accuracy: 0.6909\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7669 - accuracy: 0.6871\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7678 - accuracy: 0.6880\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7679 - accuracy: 0.6940\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7658 - accuracy: 0.6908\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.6940\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7661 - accuracy: 0.6906\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7706 - accuracy: 0.6862\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7651 - accuracy: 0.6912\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7642 - accuracy: 0.6911\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7730 - accuracy: 0.6878\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.6905\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7638 - accuracy: 0.6879\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7739 - accuracy: 0.6869\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.6913\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7737 - accuracy: 0.6879\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7640 - accuracy: 0.6923\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7626 - accuracy: 0.6898\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7676 - accuracy: 0.6889\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7648 - accuracy: 0.6895\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7639 - accuracy: 0.6893\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7655 - accuracy: 0.6883\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7626 - accuracy: 0.6927\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.6903\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7694 - accuracy: 0.6895\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7653 - accuracy: 0.6927\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7673 - accuracy: 0.6903\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7725 - accuracy: 0.6888\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7629 - accuracy: 0.6904\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7693 - accuracy: 0.6877\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7647 - accuracy: 0.6912\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7648 - accuracy: 0.6894\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.6935\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7673 - accuracy: 0.6901\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7648 - accuracy: 0.6887\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7632 - accuracy: 0.6915\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7668 - accuracy: 0.6913\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7696 - accuracy: 0.6891\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.6913\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7679 - accuracy: 0.6877\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7581 - accuracy: 0.6908\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7595 - accuracy: 0.6925\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7651 - accuracy: 0.6890\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7609 - accuracy: 0.6904\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7601 - accuracy: 0.6915\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7606 - accuracy: 0.6941\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7690 - accuracy: 0.6931\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7670 - accuracy: 0.6916\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7713 - accuracy: 0.6881\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7597 - accuracy: 0.6886\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7616 - accuracy: 0.6925\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7622 - accuracy: 0.6908\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7580 - accuracy: 0.6915\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7629 - accuracy: 0.6906\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7566 - accuracy: 0.6946\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7561 - accuracy: 0.6929\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7624 - accuracy: 0.6924\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7661 - accuracy: 0.6873\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7630 - accuracy: 0.6924\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7614 - accuracy: 0.6946\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7616 - accuracy: 0.6940\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7604 - accuracy: 0.6963\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7568 - accuracy: 0.6956\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7578 - accuracy: 0.6966\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7612 - accuracy: 0.6960\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7545 - accuracy: 0.6961\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7608 - accuracy: 0.6944\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7636 - accuracy: 0.6909\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7628 - accuracy: 0.6883\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7615 - accuracy: 0.6908\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7616 - accuracy: 0.6938\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7592 - accuracy: 0.6927\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7681 - accuracy: 0.6886\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7641 - accuracy: 0.6915\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7603 - accuracy: 0.6933\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7510 - accuracy: 0.6965\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7559 - accuracy: 0.6930\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7604 - accuracy: 0.6930\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7618 - accuracy: 0.6947\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7480 - accuracy: 0.6961\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7559 - accuracy: 0.6943\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7594 - accuracy: 0.6918\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7575 - accuracy: 0.6917\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7546 - accuracy: 0.6960\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7635 - accuracy: 0.6915\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7544 - accuracy: 0.6950\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7614 - accuracy: 0.6883\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7589 - accuracy: 0.6935\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7639 - accuracy: 0.6900\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7626 - accuracy: 0.6913\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7577 - accuracy: 0.6909\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7573 - accuracy: 0.6946\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7624 - accuracy: 0.6912\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7586 - accuracy: 0.6933\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7526 - accuracy: 0.6962\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7492 - accuracy: 0.6997\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7568 - accuracy: 0.6922\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7560 - accuracy: 0.6937\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7537 - accuracy: 0.6962\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7527 - accuracy: 0.6966\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7472 - accuracy: 0.6993\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7515 - accuracy: 0.6979\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7538 - accuracy: 0.6948\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7593 - accuracy: 0.6928\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7530 - accuracy: 0.6954\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7583 - accuracy: 0.6988\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7537 - accuracy: 0.6958\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7545 - accuracy: 0.6995\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7556 - accuracy: 0.6976\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7552 - accuracy: 0.6970\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7591 - accuracy: 0.6948\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7588 - accuracy: 0.6954\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7548 - accuracy: 0.6974\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7569 - accuracy: 0.6924\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7519 - accuracy: 0.6937\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7556 - accuracy: 0.6962\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7564 - accuracy: 0.6954\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7480 - accuracy: 0.6992\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7565 - accuracy: 0.6953\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7564 - accuracy: 0.6906\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7498 - accuracy: 0.6965\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7532 - accuracy: 0.6978\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7553 - accuracy: 0.6997\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7506 - accuracy: 0.6981\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7531 - accuracy: 0.6949\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7573 - accuracy: 0.6918\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7572 - accuracy: 0.6938\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7568 - accuracy: 0.6961\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7502 - accuracy: 0.7006\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7508 - accuracy: 0.6968\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7506 - accuracy: 0.6969\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7571 - accuracy: 0.6989\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7466 - accuracy: 0.6978\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7429 - accuracy: 0.7004\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7542 - accuracy: 0.6942\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7526 - accuracy: 0.6953\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7543 - accuracy: 0.6985\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7504 - accuracy: 0.6960\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7553 - accuracy: 0.6949\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7548 - accuracy: 0.6917\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7527 - accuracy: 0.7005\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7456 - accuracy: 0.7002\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7509 - accuracy: 0.6971\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7531 - accuracy: 0.6976\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7486 - accuracy: 0.6995\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7499 - accuracy: 0.6972\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7476 - accuracy: 0.6981\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7519 - accuracy: 0.6974\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7494 - accuracy: 0.6978\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7562 - accuracy: 0.6941\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7547 - accuracy: 0.6948\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7498 - accuracy: 0.6963\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7512 - accuracy: 0.6985\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7457 - accuracy: 0.7021\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7487 - accuracy: 0.6975\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7469 - accuracy: 0.6997\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7501 - accuracy: 0.6966\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7468 - accuracy: 0.7003\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7493 - accuracy: 0.6992\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7567 - accuracy: 0.6956\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7505 - accuracy: 0.6934\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7499 - accuracy: 0.6969\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7437 - accuracy: 0.6990\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7564 - accuracy: 0.6943\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7479 - accuracy: 0.6986\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7440 - accuracy: 0.7011\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7460 - accuracy: 0.6957\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7568 - accuracy: 0.6933\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7501 - accuracy: 0.6985\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7455 - accuracy: 0.6959\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7495 - accuracy: 0.6979\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7458 - accuracy: 0.7000\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7493 - accuracy: 0.6965\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7473 - accuracy: 0.6977\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7445 - accuracy: 0.6970\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7488 - accuracy: 0.6963\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7461 - accuracy: 0.6992\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7479 - accuracy: 0.6987\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7550 - accuracy: 0.6982\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7486 - accuracy: 0.6965\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7411 - accuracy: 0.7005\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7435 - accuracy: 0.7014\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7510 - accuracy: 0.6978\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7495 - accuracy: 0.6976\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7465 - accuracy: 0.6996\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7471 - accuracy: 0.6970\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7425 - accuracy: 0.7008\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7436 - accuracy: 0.7016\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7474 - accuracy: 0.6999\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7502 - accuracy: 0.7000\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7486 - accuracy: 0.6966\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7507 - accuracy: 0.6940\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7502 - accuracy: 0.6972\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7481 - accuracy: 0.7010\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7475 - accuracy: 0.6982\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7486 - accuracy: 0.6986\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7451 - accuracy: 0.6997\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7443 - accuracy: 0.6980\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7471 - accuracy: 0.7004\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7457 - accuracy: 0.6984\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7440 - accuracy: 0.6993\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7420 - accuracy: 0.7004\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7493 - accuracy: 0.6956\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7389 - accuracy: 0.7015\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7473 - accuracy: 0.6966\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7456 - accuracy: 0.7029\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7381 - accuracy: 0.7021\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7481 - accuracy: 0.6990\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7490 - accuracy: 0.6968\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7457 - accuracy: 0.7007\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7471 - accuracy: 0.6979\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7477 - accuracy: 0.6969\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7462 - accuracy: 0.6995\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7437 - accuracy: 0.7010\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7483 - accuracy: 0.6998\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7551 - accuracy: 0.6982\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7450 - accuracy: 0.7020\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7403 - accuracy: 0.6979\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7361 - accuracy: 0.7051\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7394 - accuracy: 0.7014\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7417 - accuracy: 0.6998\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7471 - accuracy: 0.7016\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7370 - accuracy: 0.7035\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7429 - accuracy: 0.7025\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7473 - accuracy: 0.6993\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7415 - accuracy: 0.7020\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7412 - accuracy: 0.7020\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7360 - accuracy: 0.7021\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7464 - accuracy: 0.6986\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7390 - accuracy: 0.7022\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7442 - accuracy: 0.6960\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7430 - accuracy: 0.7017\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7433 - accuracy: 0.7000\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7427 - accuracy: 0.6996\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7465 - accuracy: 0.6987\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7419 - accuracy: 0.7009\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7438 - accuracy: 0.7007\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7361 - accuracy: 0.6996\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7449 - accuracy: 0.6962\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7476 - accuracy: 0.6991\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7380 - accuracy: 0.7004\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7413 - accuracy: 0.7023\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7468 - accuracy: 0.6984\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7403 - accuracy: 0.7004\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7425 - accuracy: 0.7022\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7411 - accuracy: 0.6992\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7455 - accuracy: 0.7027\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7366 - accuracy: 0.7061\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7447 - accuracy: 0.6993\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7476 - accuracy: 0.6973\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7444 - accuracy: 0.7037\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7412 - accuracy: 0.7012\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7439 - accuracy: 0.6975\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7396 - accuracy: 0.7016\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7422 - accuracy: 0.7016\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7422 - accuracy: 0.6993\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7424 - accuracy: 0.6999\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7381 - accuracy: 0.7025\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7416 - accuracy: 0.7020\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7399 - accuracy: 0.7033\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7401 - accuracy: 0.7036\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7428 - accuracy: 0.6993\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7390 - accuracy: 0.6998\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7392 - accuracy: 0.7010\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7387 - accuracy: 0.7007\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7390 - accuracy: 0.7052\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7361 - accuracy: 0.7024\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7414 - accuracy: 0.6979\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7373 - accuracy: 0.7064\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7377 - accuracy: 0.6993\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7367 - accuracy: 0.7043\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7383 - accuracy: 0.7020\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7377 - accuracy: 0.7046\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7428 - accuracy: 0.7041\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7314 - accuracy: 0.7071\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7416 - accuracy: 0.7019\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7352 - accuracy: 0.7046\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7495 - accuracy: 0.6986\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7329 - accuracy: 0.7077\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7377 - accuracy: 0.7029\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7404 - accuracy: 0.7030\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7343 - accuracy: 0.7076\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7413 - accuracy: 0.6984\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7351 - accuracy: 0.7041\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7486 - accuracy: 0.7024\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7356 - accuracy: 0.7037\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7403 - accuracy: 0.6994\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7386 - accuracy: 0.6996\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7396 - accuracy: 0.7029\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7428 - accuracy: 0.6991\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7381 - accuracy: 0.7037\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7366 - accuracy: 0.7029\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7376 - accuracy: 0.7030\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7407 - accuracy: 0.7013\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7374 - accuracy: 0.7014\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7418 - accuracy: 0.7018\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7377 - accuracy: 0.7068\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7343 - accuracy: 0.7047\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7378 - accuracy: 0.7068\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7347 - accuracy: 0.7046\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7369 - accuracy: 0.7037\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7383 - accuracy: 0.7094\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7363 - accuracy: 0.7049\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7407 - accuracy: 0.7036\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7394 - accuracy: 0.7028\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7341 - accuracy: 0.7065\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7380 - accuracy: 0.7031\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7358 - accuracy: 0.7025\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7387 - accuracy: 0.7019\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7385 - accuracy: 0.7013\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7383 - accuracy: 0.7025\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7412 - accuracy: 0.7023\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7370 - accuracy: 0.7010\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7391 - accuracy: 0.7040\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7382 - accuracy: 0.7053\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7381 - accuracy: 0.7014\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7408 - accuracy: 0.7021\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7343 - accuracy: 0.7015\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7356 - accuracy: 0.7019\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7402 - accuracy: 0.7021\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7339 - accuracy: 0.7053\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7371 - accuracy: 0.7058\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7333 - accuracy: 0.7054\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7299 - accuracy: 0.7077\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7368 - accuracy: 0.7021\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7339 - accuracy: 0.7046\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7363 - accuracy: 0.7018\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7341 - accuracy: 0.7038\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7331 - accuracy: 0.7059\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7354 - accuracy: 0.7010\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7319 - accuracy: 0.7072\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7363 - accuracy: 0.7036\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7253 - accuracy: 0.7090\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7341 - accuracy: 0.7020\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7421 - accuracy: 0.7032\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7367 - accuracy: 0.7045\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7316 - accuracy: 0.7051\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7297 - accuracy: 0.7050\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7317 - accuracy: 0.7052\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7368 - accuracy: 0.7032\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7331 - accuracy: 0.7053\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7306 - accuracy: 0.7026\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7387 - accuracy: 0.7075\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7321 - accuracy: 0.7064\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7328 - accuracy: 0.7056\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7330 - accuracy: 0.7038\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7359 - accuracy: 0.7034\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7331 - accuracy: 0.7073\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7323 - accuracy: 0.7030\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7394 - accuracy: 0.7014\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.7312 - accuracy: 0.7067\n",
      "576/576 [==============================] - 2s 1ms/step - loss: 0.5626 - accuracy: 0.7765\n",
      "Train Loss: 0.5626\n",
      "Train Accuracy: 0.7765\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.7860 - accuracy: 0.7051\n",
      "Test Loss: 0.7860\n",
      "Test Accuracy: 0.7051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# DataFrame을 무작위로 섞기\n",
    "df_shuffled = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# 데이터를 입력 특성 (X)과 타겟 변수 (y)로 분할하기\n",
    "X = df_shuffled[['gx', 'gy', 'gz']].values\n",
    "y = df_shuffled['label'].values\n",
    "\n",
    "# 레이블을 인코딩하기 위해 LabelEncoder 사용\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 인코딩된 레이블을 원-핫 인코딩으로 변환하기\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# 입력 특성을 LSTM 모델의 예상 형태로 재구성\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(3, 1), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# LSTM 모델 훈련\n",
    "model.fit(X_train_reshaped, y_train, epochs=1000, batch_size=32)\n",
    "\n",
    "# 훈련 데이터에서 모델 평가\n",
    "train_loss, train_accuracy = model.evaluate(X_train_reshaped, y_train)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# 테스트 데이터에서 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T04:26:00.297277300Z",
     "start_time": "2023-06-07T04:05:34.935219800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# DataFrame을 무작위로 섞기\n",
    "df_shuffled = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# 데이터를 입력 특성 (X)과 타겟 변수 (y)로 분할하기\n",
    "X = df_shuffled[['gx', 'gy', 'gz']].values\n",
    "y = df_shuffled['label'].values\n",
    "\n",
    "# 레이블을 인코딩하기 위해 LabelEncoder 사용\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 인코딩된 레이블을 원-핫 인코딩으로 변환하기\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# 입력 특성을 LSTM 모델의 예상 형태로 재구성\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(3, 1), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# LSTM 모델 훈련\n",
    "model.fit(X_train_reshaped, y_train, epochs=3000, batch_size=32)\n",
    "\n",
    "# 훈련 데이터에서 모델 평가\n",
    "train_loss, train_accuracy = model.evaluate(X_train_reshaped, y_train)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# 테스트 데이터에서 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "288/288 [==============================] - 3s 3ms/step - loss: 1.3403 - accuracy: 0.4214\n",
      "Epoch 2/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.2622 - accuracy: 0.4517\n",
      "Epoch 3/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.2399 - accuracy: 0.4628\n",
      "Epoch 4/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.2204 - accuracy: 0.4755\n",
      "Epoch 5/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.2061 - accuracy: 0.4877\n",
      "Epoch 6/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1927 - accuracy: 0.4906\n",
      "Epoch 7/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1784 - accuracy: 0.5034\n",
      "Epoch 8/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1698 - accuracy: 0.5055\n",
      "Epoch 9/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1567 - accuracy: 0.5148\n",
      "Epoch 10/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1500 - accuracy: 0.5114\n",
      "Epoch 11/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1401 - accuracy: 0.5220\n",
      "Epoch 12/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1307 - accuracy: 0.5259\n",
      "Epoch 13/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1266 - accuracy: 0.5216\n",
      "Epoch 14/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1172 - accuracy: 0.5333\n",
      "Epoch 15/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1122 - accuracy: 0.5317\n",
      "Epoch 16/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.1063 - accuracy: 0.5367\n",
      "Epoch 17/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0987 - accuracy: 0.5348\n",
      "Epoch 18/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0973 - accuracy: 0.5396\n",
      "Epoch 19/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0935 - accuracy: 0.5417\n",
      "Epoch 20/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0858 - accuracy: 0.5433\n",
      "Epoch 21/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0805 - accuracy: 0.5490\n",
      "Epoch 22/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0834 - accuracy: 0.5461\n",
      "Epoch 23/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0756 - accuracy: 0.5530\n",
      "Epoch 24/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0701 - accuracy: 0.5504\n",
      "Epoch 25/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0692 - accuracy: 0.5524\n",
      "Epoch 26/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0694 - accuracy: 0.5533\n",
      "Epoch 27/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0660 - accuracy: 0.5549\n",
      "Epoch 28/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0574 - accuracy: 0.5554\n",
      "Epoch 29/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0559 - accuracy: 0.5570\n",
      "Epoch 30/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0491 - accuracy: 0.5626\n",
      "Epoch 31/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0525 - accuracy: 0.5608\n",
      "Epoch 32/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0515 - accuracy: 0.5622\n",
      "Epoch 33/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0483 - accuracy: 0.5621\n",
      "Epoch 34/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0452 - accuracy: 0.5640\n",
      "Epoch 35/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0448 - accuracy: 0.5635\n",
      "Epoch 36/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0403 - accuracy: 0.5668\n",
      "Epoch 37/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0378 - accuracy: 0.5678\n",
      "Epoch 38/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0328 - accuracy: 0.5698\n",
      "Epoch 39/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0314 - accuracy: 0.5751\n",
      "Epoch 40/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0334 - accuracy: 0.5683\n",
      "Epoch 41/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0265 - accuracy: 0.5701\n",
      "Epoch 42/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0325 - accuracy: 0.5705\n",
      "Epoch 43/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0285 - accuracy: 0.5734\n",
      "Epoch 44/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0234 - accuracy: 0.5757\n",
      "Epoch 45/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0245 - accuracy: 0.5754\n",
      "Epoch 46/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0176 - accuracy: 0.5795\n",
      "Epoch 47/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0146 - accuracy: 0.5807\n",
      "Epoch 48/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0156 - accuracy: 0.5789\n",
      "Epoch 49/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0141 - accuracy: 0.5764\n",
      "Epoch 50/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0108 - accuracy: 0.5769\n",
      "Epoch 51/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0120 - accuracy: 0.5807\n",
      "Epoch 52/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0023 - accuracy: 0.5842\n",
      "Epoch 53/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0060 - accuracy: 0.5815\n",
      "Epoch 54/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0025 - accuracy: 0.5839\n",
      "Epoch 55/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0008 - accuracy: 0.5852\n",
      "Epoch 56/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 1.0002 - accuracy: 0.5859\n",
      "Epoch 57/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9985 - accuracy: 0.5866\n",
      "Epoch 58/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9982 - accuracy: 0.5876\n",
      "Epoch 59/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9988 - accuracy: 0.5878\n",
      "Epoch 60/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9958 - accuracy: 0.5839\n",
      "Epoch 61/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9955 - accuracy: 0.5875\n",
      "Epoch 62/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9948 - accuracy: 0.5898\n",
      "Epoch 63/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9898 - accuracy: 0.5907\n",
      "Epoch 64/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9928 - accuracy: 0.5872\n",
      "Epoch 65/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9897 - accuracy: 0.5922\n",
      "Epoch 66/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9819 - accuracy: 0.5951\n",
      "Epoch 67/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9859 - accuracy: 0.5911\n",
      "Epoch 68/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9844 - accuracy: 0.5905\n",
      "Epoch 69/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9784 - accuracy: 0.5908\n",
      "Epoch 70/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9825 - accuracy: 0.5928\n",
      "Epoch 71/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9800 - accuracy: 0.5933\n",
      "Epoch 72/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9787 - accuracy: 0.5929\n",
      "Epoch 73/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9755 - accuracy: 0.5967\n",
      "Epoch 74/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9766 - accuracy: 0.5933\n",
      "Epoch 75/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9766 - accuracy: 0.5964\n",
      "Epoch 76/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9717 - accuracy: 0.5953\n",
      "Epoch 77/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9676 - accuracy: 0.5980\n",
      "Epoch 78/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9697 - accuracy: 0.5978\n",
      "Epoch 79/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9723 - accuracy: 0.5961\n",
      "Epoch 80/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9661 - accuracy: 0.5954\n",
      "Epoch 81/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9664 - accuracy: 0.6015\n",
      "Epoch 82/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9623 - accuracy: 0.6032\n",
      "Epoch 83/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9567 - accuracy: 0.6027\n",
      "Epoch 84/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9637 - accuracy: 0.5989\n",
      "Epoch 85/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9635 - accuracy: 0.6007\n",
      "Epoch 86/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9567 - accuracy: 0.6018\n",
      "Epoch 87/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9608 - accuracy: 0.6028\n",
      "Epoch 88/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9589 - accuracy: 0.6022\n",
      "Epoch 89/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9599 - accuracy: 0.6021\n",
      "Epoch 90/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9522 - accuracy: 0.6075\n",
      "Epoch 91/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9534 - accuracy: 0.6048\n",
      "Epoch 92/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9532 - accuracy: 0.6035\n",
      "Epoch 93/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9548 - accuracy: 0.6048\n",
      "Epoch 94/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9494 - accuracy: 0.6057\n",
      "Epoch 95/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9459 - accuracy: 0.6069\n",
      "Epoch 96/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9518 - accuracy: 0.6074\n",
      "Epoch 97/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9459 - accuracy: 0.6037\n",
      "Epoch 98/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9495 - accuracy: 0.6064\n",
      "Epoch 99/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9485 - accuracy: 0.6058\n",
      "Epoch 100/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9449 - accuracy: 0.6053\n",
      "Epoch 101/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9433 - accuracy: 0.6070\n",
      "Epoch 102/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9435 - accuracy: 0.6076\n",
      "Epoch 103/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9432 - accuracy: 0.6037\n",
      "Epoch 104/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9456 - accuracy: 0.6044\n",
      "Epoch 105/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9414 - accuracy: 0.6099\n",
      "Epoch 106/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9351 - accuracy: 0.6119\n",
      "Epoch 107/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9397 - accuracy: 0.6101\n",
      "Epoch 108/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9363 - accuracy: 0.6109\n",
      "Epoch 109/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9424 - accuracy: 0.6106\n",
      "Epoch 110/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9428 - accuracy: 0.6103\n",
      "Epoch 111/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9356 - accuracy: 0.6115\n",
      "Epoch 112/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9364 - accuracy: 0.6126\n",
      "Epoch 113/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9327 - accuracy: 0.6156\n",
      "Epoch 114/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9292 - accuracy: 0.6157\n",
      "Epoch 115/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9336 - accuracy: 0.6111\n",
      "Epoch 116/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9326 - accuracy: 0.6119\n",
      "Epoch 117/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9328 - accuracy: 0.6135\n",
      "Epoch 118/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9285 - accuracy: 0.6140\n",
      "Epoch 119/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9261 - accuracy: 0.6151\n",
      "Epoch 120/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9271 - accuracy: 0.6156\n",
      "Epoch 121/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9226 - accuracy: 0.6160\n",
      "Epoch 122/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9298 - accuracy: 0.6166\n",
      "Epoch 123/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9284 - accuracy: 0.6152\n",
      "Epoch 124/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9234 - accuracy: 0.6173\n",
      "Epoch 125/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9219 - accuracy: 0.6191\n",
      "Epoch 126/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9299 - accuracy: 0.6146\n",
      "Epoch 127/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9254 - accuracy: 0.6190\n",
      "Epoch 128/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9206 - accuracy: 0.6202\n",
      "Epoch 129/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9203 - accuracy: 0.6148\n",
      "Epoch 130/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9181 - accuracy: 0.6197\n",
      "Epoch 131/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9147 - accuracy: 0.6185\n",
      "Epoch 132/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9191 - accuracy: 0.6201\n",
      "Epoch 133/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9160 - accuracy: 0.6226\n",
      "Epoch 134/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9111 - accuracy: 0.6227\n",
      "Epoch 135/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9163 - accuracy: 0.6184\n",
      "Epoch 136/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9174 - accuracy: 0.6195\n",
      "Epoch 137/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9164 - accuracy: 0.6197\n",
      "Epoch 138/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9163 - accuracy: 0.6235\n",
      "Epoch 139/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9137 - accuracy: 0.6181\n",
      "Epoch 140/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9144 - accuracy: 0.6225\n",
      "Epoch 141/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9164 - accuracy: 0.6215\n",
      "Epoch 142/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9133 - accuracy: 0.6213\n",
      "Epoch 143/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.9094 - accuracy: 0.6251\n",
      "Epoch 144/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9077 - accuracy: 0.6250\n",
      "Epoch 145/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9085 - accuracy: 0.6241\n",
      "Epoch 146/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9119 - accuracy: 0.6221\n",
      "Epoch 147/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9102 - accuracy: 0.6235\n",
      "Epoch 148/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9094 - accuracy: 0.6229\n",
      "Epoch 149/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9115 - accuracy: 0.6210\n",
      "Epoch 150/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9085 - accuracy: 0.6267\n",
      "Epoch 151/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9075 - accuracy: 0.6246\n",
      "Epoch 152/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9036 - accuracy: 0.6255\n",
      "Epoch 153/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9099 - accuracy: 0.6216\n",
      "Epoch 154/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9064 - accuracy: 0.6239\n",
      "Epoch 155/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9044 - accuracy: 0.6231\n",
      "Epoch 156/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9033 - accuracy: 0.6243\n",
      "Epoch 157/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9036 - accuracy: 0.6257\n",
      "Epoch 158/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9020 - accuracy: 0.6228\n",
      "Epoch 159/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9034 - accuracy: 0.6249\n",
      "Epoch 160/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9016 - accuracy: 0.6275\n",
      "Epoch 161/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9015 - accuracy: 0.6292\n",
      "Epoch 162/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9004 - accuracy: 0.6275\n",
      "Epoch 163/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8980 - accuracy: 0.6302\n",
      "Epoch 164/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9010 - accuracy: 0.6233\n",
      "Epoch 165/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9002 - accuracy: 0.6287\n",
      "Epoch 166/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.9055 - accuracy: 0.6248\n",
      "Epoch 167/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8959 - accuracy: 0.6330\n",
      "Epoch 168/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8995 - accuracy: 0.6253\n",
      "Epoch 169/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8983 - accuracy: 0.6303\n",
      "Epoch 170/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8985 - accuracy: 0.6303\n",
      "Epoch 171/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8946 - accuracy: 0.6302\n",
      "Epoch 172/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8936 - accuracy: 0.6341\n",
      "Epoch 173/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8974 - accuracy: 0.6327\n",
      "Epoch 174/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8999 - accuracy: 0.6257\n",
      "Epoch 175/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8955 - accuracy: 0.6308\n",
      "Epoch 176/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8915 - accuracy: 0.6344\n",
      "Epoch 177/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8959 - accuracy: 0.6304\n",
      "Epoch 178/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8977 - accuracy: 0.6263\n",
      "Epoch 179/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8977 - accuracy: 0.6243\n",
      "Epoch 180/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8849 - accuracy: 0.6340\n",
      "Epoch 181/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8879 - accuracy: 0.6337\n",
      "Epoch 182/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8915 - accuracy: 0.6300\n",
      "Epoch 183/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8885 - accuracy: 0.6308\n",
      "Epoch 184/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8913 - accuracy: 0.6306\n",
      "Epoch 185/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8927 - accuracy: 0.6322\n",
      "Epoch 186/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8847 - accuracy: 0.6339\n",
      "Epoch 187/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8890 - accuracy: 0.6321\n",
      "Epoch 188/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8929 - accuracy: 0.6286\n",
      "Epoch 189/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8922 - accuracy: 0.6321\n",
      "Epoch 190/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8859 - accuracy: 0.6354\n",
      "Epoch 191/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8858 - accuracy: 0.6353\n",
      "Epoch 192/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8901 - accuracy: 0.6311\n",
      "Epoch 193/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8832 - accuracy: 0.6367\n",
      "Epoch 194/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8897 - accuracy: 0.6331\n",
      "Epoch 195/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8892 - accuracy: 0.6317\n",
      "Epoch 196/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8892 - accuracy: 0.6332\n",
      "Epoch 197/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8810 - accuracy: 0.6362\n",
      "Epoch 198/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8791 - accuracy: 0.6359\n",
      "Epoch 199/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8806 - accuracy: 0.6355\n",
      "Epoch 200/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8803 - accuracy: 0.6349\n",
      "Epoch 201/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8855 - accuracy: 0.6337\n",
      "Epoch 202/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8803 - accuracy: 0.6380\n",
      "Epoch 203/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8864 - accuracy: 0.6338\n",
      "Epoch 204/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8838 - accuracy: 0.6377\n",
      "Epoch 205/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8759 - accuracy: 0.6370\n",
      "Epoch 206/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8768 - accuracy: 0.6436\n",
      "Epoch 207/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8804 - accuracy: 0.6343\n",
      "Epoch 208/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8797 - accuracy: 0.6362\n",
      "Epoch 209/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8797 - accuracy: 0.6388\n",
      "Epoch 210/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8811 - accuracy: 0.6340\n",
      "Epoch 211/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8819 - accuracy: 0.6296\n",
      "Epoch 212/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8779 - accuracy: 0.6362\n",
      "Epoch 213/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8828 - accuracy: 0.6328\n",
      "Epoch 214/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8786 - accuracy: 0.6378\n",
      "Epoch 215/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8755 - accuracy: 0.6425\n",
      "Epoch 216/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8752 - accuracy: 0.6381\n",
      "Epoch 217/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8763 - accuracy: 0.6398\n",
      "Epoch 218/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8735 - accuracy: 0.6389\n",
      "Epoch 219/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8784 - accuracy: 0.6388\n",
      "Epoch 220/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8760 - accuracy: 0.6379\n",
      "Epoch 221/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8727 - accuracy: 0.6400\n",
      "Epoch 222/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8764 - accuracy: 0.6411\n",
      "Epoch 223/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8766 - accuracy: 0.6381\n",
      "Epoch 224/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8792 - accuracy: 0.6366\n",
      "Epoch 225/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8761 - accuracy: 0.6396\n",
      "Epoch 226/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8710 - accuracy: 0.6394\n",
      "Epoch 227/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8686 - accuracy: 0.6402\n",
      "Epoch 228/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8683 - accuracy: 0.6399\n",
      "Epoch 229/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8710 - accuracy: 0.6403\n",
      "Epoch 230/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8722 - accuracy: 0.6363\n",
      "Epoch 231/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8725 - accuracy: 0.6398\n",
      "Epoch 232/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8677 - accuracy: 0.6442\n",
      "Epoch 233/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8692 - accuracy: 0.6420\n",
      "Epoch 234/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8672 - accuracy: 0.6441\n",
      "Epoch 235/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8690 - accuracy: 0.6395\n",
      "Epoch 236/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8688 - accuracy: 0.6400\n",
      "Epoch 237/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8678 - accuracy: 0.6430\n",
      "Epoch 238/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8676 - accuracy: 0.6406\n",
      "Epoch 239/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8656 - accuracy: 0.6396\n",
      "Epoch 240/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8671 - accuracy: 0.6412\n",
      "Epoch 241/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8672 - accuracy: 0.6430\n",
      "Epoch 242/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8685 - accuracy: 0.6430\n",
      "Epoch 243/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8627 - accuracy: 0.6419\n",
      "Epoch 244/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8698 - accuracy: 0.6427\n",
      "Epoch 245/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8611 - accuracy: 0.6467\n",
      "Epoch 246/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8622 - accuracy: 0.6494\n",
      "Epoch 247/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8633 - accuracy: 0.6433\n",
      "Epoch 248/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8657 - accuracy: 0.6401\n",
      "Epoch 249/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8697 - accuracy: 0.6389\n",
      "Epoch 250/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8659 - accuracy: 0.6426\n",
      "Epoch 251/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8597 - accuracy: 0.6463\n",
      "Epoch 252/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8662 - accuracy: 0.6433\n",
      "Epoch 253/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8657 - accuracy: 0.6427\n",
      "Epoch 254/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8642 - accuracy: 0.6420\n",
      "Epoch 255/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8600 - accuracy: 0.6460\n",
      "Epoch 256/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8649 - accuracy: 0.6446\n",
      "Epoch 257/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8651 - accuracy: 0.6453\n",
      "Epoch 258/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8646 - accuracy: 0.6447\n",
      "Epoch 259/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8630 - accuracy: 0.6458\n",
      "Epoch 260/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8635 - accuracy: 0.6420\n",
      "Epoch 261/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8630 - accuracy: 0.6443\n",
      "Epoch 262/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8588 - accuracy: 0.6433\n",
      "Epoch 263/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8613 - accuracy: 0.6463\n",
      "Epoch 264/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8604 - accuracy: 0.6471\n",
      "Epoch 265/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8629 - accuracy: 0.6450\n",
      "Epoch 266/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8630 - accuracy: 0.6407\n",
      "Epoch 267/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8563 - accuracy: 0.6477\n",
      "Epoch 268/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8553 - accuracy: 0.6494\n",
      "Epoch 269/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8570 - accuracy: 0.6469\n",
      "Epoch 270/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8566 - accuracy: 0.6452\n",
      "Epoch 271/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8552 - accuracy: 0.6456\n",
      "Epoch 272/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8559 - accuracy: 0.6486\n",
      "Epoch 273/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8585 - accuracy: 0.6487\n",
      "Epoch 274/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8561 - accuracy: 0.6483\n",
      "Epoch 275/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8617 - accuracy: 0.6466\n",
      "Epoch 276/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8553 - accuracy: 0.6475\n",
      "Epoch 277/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8527 - accuracy: 0.6541\n",
      "Epoch 278/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8531 - accuracy: 0.6454\n",
      "Epoch 279/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8512 - accuracy: 0.6503\n",
      "Epoch 280/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8580 - accuracy: 0.6481\n",
      "Epoch 281/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8588 - accuracy: 0.6463\n",
      "Epoch 282/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8544 - accuracy: 0.6456\n",
      "Epoch 283/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8525 - accuracy: 0.6502\n",
      "Epoch 284/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8533 - accuracy: 0.6506\n",
      "Epoch 285/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8559 - accuracy: 0.6477\n",
      "Epoch 286/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8598 - accuracy: 0.6458\n",
      "Epoch 287/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8543 - accuracy: 0.6503\n",
      "Epoch 288/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8483 - accuracy: 0.6513\n",
      "Epoch 289/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8527 - accuracy: 0.6475\n",
      "Epoch 290/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8562 - accuracy: 0.6475\n",
      "Epoch 291/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8530 - accuracy: 0.6494\n",
      "Epoch 292/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8549 - accuracy: 0.6488\n",
      "Epoch 293/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8507 - accuracy: 0.6520\n",
      "Epoch 294/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8509 - accuracy: 0.6510\n",
      "Epoch 295/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8491 - accuracy: 0.6525\n",
      "Epoch 296/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8455 - accuracy: 0.6500\n",
      "Epoch 297/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8464 - accuracy: 0.6506\n",
      "Epoch 298/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8547 - accuracy: 0.6468\n",
      "Epoch 299/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8563 - accuracy: 0.6465\n",
      "Epoch 300/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8570 - accuracy: 0.6466\n",
      "Epoch 301/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8534 - accuracy: 0.6493\n",
      "Epoch 302/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8506 - accuracy: 0.6494\n",
      "Epoch 303/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8542 - accuracy: 0.6481\n",
      "Epoch 304/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8479 - accuracy: 0.6494\n",
      "Epoch 305/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8490 - accuracy: 0.6488\n",
      "Epoch 306/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8480 - accuracy: 0.6491\n",
      "Epoch 307/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8490 - accuracy: 0.6481\n",
      "Epoch 308/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8470 - accuracy: 0.6529\n",
      "Epoch 309/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8506 - accuracy: 0.6499\n",
      "Epoch 310/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8490 - accuracy: 0.6507\n",
      "Epoch 311/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8520 - accuracy: 0.6513\n",
      "Epoch 312/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8460 - accuracy: 0.6487\n",
      "Epoch 313/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8409 - accuracy: 0.6536\n",
      "Epoch 314/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8475 - accuracy: 0.6540\n",
      "Epoch 315/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8507 - accuracy: 0.6493\n",
      "Epoch 316/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8463 - accuracy: 0.6560\n",
      "Epoch 317/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8473 - accuracy: 0.6529\n",
      "Epoch 318/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8449 - accuracy: 0.6509\n",
      "Epoch 319/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8432 - accuracy: 0.6528\n",
      "Epoch 320/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8445 - accuracy: 0.6503\n",
      "Epoch 321/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8411 - accuracy: 0.6537\n",
      "Epoch 322/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8414 - accuracy: 0.6540\n",
      "Epoch 323/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8448 - accuracy: 0.6527\n",
      "Epoch 324/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8414 - accuracy: 0.6553\n",
      "Epoch 325/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8410 - accuracy: 0.6559\n",
      "Epoch 326/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.8443 - accuracy: 0.6550\n",
      "Epoch 327/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8449 - accuracy: 0.6490\n",
      "Epoch 328/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8395 - accuracy: 0.6533\n",
      "Epoch 329/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8459 - accuracy: 0.6517\n",
      "Epoch 330/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8416 - accuracy: 0.6534\n",
      "Epoch 331/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8443 - accuracy: 0.6547\n",
      "Epoch 332/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8406 - accuracy: 0.6548\n",
      "Epoch 333/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8462 - accuracy: 0.6528\n",
      "Epoch 334/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8457 - accuracy: 0.6526\n",
      "Epoch 335/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8426 - accuracy: 0.6560\n",
      "Epoch 336/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8416 - accuracy: 0.6560\n",
      "Epoch 337/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8411 - accuracy: 0.6560\n",
      "Epoch 338/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8417 - accuracy: 0.6558\n",
      "Epoch 339/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8366 - accuracy: 0.6606\n",
      "Epoch 340/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8437 - accuracy: 0.6527\n",
      "Epoch 341/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8415 - accuracy: 0.6573\n",
      "Epoch 342/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8405 - accuracy: 0.6565\n",
      "Epoch 343/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8382 - accuracy: 0.6556\n",
      "Epoch 344/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8434 - accuracy: 0.6516\n",
      "Epoch 345/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8416 - accuracy: 0.6539\n",
      "Epoch 346/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8374 - accuracy: 0.6595\n",
      "Epoch 347/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8379 - accuracy: 0.6557\n",
      "Epoch 348/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8450 - accuracy: 0.6527\n",
      "Epoch 349/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8349 - accuracy: 0.6552\n",
      "Epoch 350/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8348 - accuracy: 0.6566\n",
      "Epoch 351/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8392 - accuracy: 0.6540\n",
      "Epoch 352/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8407 - accuracy: 0.6538\n",
      "Epoch 353/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8390 - accuracy: 0.6585\n",
      "Epoch 354/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8350 - accuracy: 0.6581\n",
      "Epoch 355/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8316 - accuracy: 0.6579\n",
      "Epoch 356/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8389 - accuracy: 0.6567\n",
      "Epoch 357/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8333 - accuracy: 0.6587\n",
      "Epoch 358/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8371 - accuracy: 0.6542\n",
      "Epoch 359/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8344 - accuracy: 0.6589\n",
      "Epoch 360/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8378 - accuracy: 0.6564\n",
      "Epoch 361/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8345 - accuracy: 0.6610\n",
      "Epoch 362/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8395 - accuracy: 0.6545\n",
      "Epoch 363/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8340 - accuracy: 0.6553\n",
      "Epoch 364/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8297 - accuracy: 0.6589\n",
      "Epoch 365/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8385 - accuracy: 0.6577\n",
      "Epoch 366/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8367 - accuracy: 0.6533\n",
      "Epoch 367/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8352 - accuracy: 0.6579\n",
      "Epoch 368/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8363 - accuracy: 0.6551\n",
      "Epoch 369/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8387 - accuracy: 0.6533\n",
      "Epoch 370/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8321 - accuracy: 0.6596\n",
      "Epoch 371/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8326 - accuracy: 0.6575\n",
      "Epoch 372/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8303 - accuracy: 0.6590\n",
      "Epoch 373/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8318 - accuracy: 0.6605\n",
      "Epoch 374/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8344 - accuracy: 0.6596\n",
      "Epoch 375/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8350 - accuracy: 0.6574\n",
      "Epoch 376/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8348 - accuracy: 0.6568\n",
      "Epoch 377/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8279 - accuracy: 0.6632\n",
      "Epoch 378/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8331 - accuracy: 0.6585\n",
      "Epoch 379/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8319 - accuracy: 0.6596\n",
      "Epoch 380/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8266 - accuracy: 0.6595\n",
      "Epoch 381/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8229 - accuracy: 0.6637\n",
      "Epoch 382/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8288 - accuracy: 0.6580\n",
      "Epoch 383/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8301 - accuracy: 0.6592\n",
      "Epoch 384/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8245 - accuracy: 0.6644\n",
      "Epoch 385/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8328 - accuracy: 0.6610\n",
      "Epoch 386/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8235 - accuracy: 0.6642\n",
      "Epoch 387/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8270 - accuracy: 0.6581\n",
      "Epoch 388/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8324 - accuracy: 0.6586\n",
      "Epoch 389/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8274 - accuracy: 0.6601\n",
      "Epoch 390/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8287 - accuracy: 0.6596\n",
      "Epoch 391/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8246 - accuracy: 0.6578\n",
      "Epoch 392/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8251 - accuracy: 0.6649\n",
      "Epoch 393/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8267 - accuracy: 0.6608\n",
      "Epoch 394/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8338 - accuracy: 0.6572\n",
      "Epoch 395/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8280 - accuracy: 0.6591\n",
      "Epoch 396/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8214 - accuracy: 0.6609\n",
      "Epoch 397/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8277 - accuracy: 0.6617\n",
      "Epoch 398/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8266 - accuracy: 0.6678\n",
      "Epoch 399/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8292 - accuracy: 0.6625\n",
      "Epoch 400/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8280 - accuracy: 0.6597\n",
      "Epoch 401/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8281 - accuracy: 0.6592\n",
      "Epoch 402/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8257 - accuracy: 0.6635\n",
      "Epoch 403/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8257 - accuracy: 0.6573\n",
      "Epoch 404/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8276 - accuracy: 0.6605\n",
      "Epoch 405/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8276 - accuracy: 0.6593\n",
      "Epoch 406/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8311 - accuracy: 0.6590\n",
      "Epoch 407/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8373 - accuracy: 0.6555\n",
      "Epoch 408/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8182 - accuracy: 0.6678\n",
      "Epoch 409/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8263 - accuracy: 0.6563\n",
      "Epoch 410/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8249 - accuracy: 0.6622\n",
      "Epoch 411/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8224 - accuracy: 0.6620\n",
      "Epoch 412/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8330 - accuracy: 0.6600\n",
      "Epoch 413/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8208 - accuracy: 0.6625\n",
      "Epoch 414/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8219 - accuracy: 0.6637\n",
      "Epoch 415/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8239 - accuracy: 0.6602\n",
      "Epoch 416/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8256 - accuracy: 0.6646\n",
      "Epoch 417/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8211 - accuracy: 0.6647\n",
      "Epoch 418/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8260 - accuracy: 0.6624\n",
      "Epoch 419/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8309 - accuracy: 0.6577\n",
      "Epoch 420/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8272 - accuracy: 0.6585\n",
      "Epoch 421/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8267 - accuracy: 0.6613\n",
      "Epoch 422/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8217 - accuracy: 0.6617\n",
      "Epoch 423/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8268 - accuracy: 0.6609\n",
      "Epoch 424/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8283 - accuracy: 0.6578\n",
      "Epoch 425/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8203 - accuracy: 0.6629\n",
      "Epoch 426/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8222 - accuracy: 0.6622\n",
      "Epoch 427/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8210 - accuracy: 0.6646\n",
      "Epoch 428/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8224 - accuracy: 0.6651\n",
      "Epoch 429/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8192 - accuracy: 0.6637\n",
      "Epoch 430/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8240 - accuracy: 0.6636\n",
      "Epoch 431/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8232 - accuracy: 0.6608\n",
      "Epoch 432/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8223 - accuracy: 0.6674\n",
      "Epoch 433/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8174 - accuracy: 0.6650\n",
      "Epoch 434/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8221 - accuracy: 0.6663\n",
      "Epoch 435/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8235 - accuracy: 0.6612\n",
      "Epoch 436/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8155 - accuracy: 0.6641\n",
      "Epoch 437/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8182 - accuracy: 0.6600\n",
      "Epoch 438/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8159 - accuracy: 0.6649\n",
      "Epoch 439/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8189 - accuracy: 0.6647\n",
      "Epoch 440/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8180 - accuracy: 0.6630\n",
      "Epoch 441/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8207 - accuracy: 0.6678\n",
      "Epoch 442/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8234 - accuracy: 0.6618\n",
      "Epoch 443/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8133 - accuracy: 0.6677\n",
      "Epoch 444/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8235 - accuracy: 0.6605\n",
      "Epoch 445/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8211 - accuracy: 0.6659\n",
      "Epoch 446/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8204 - accuracy: 0.6638\n",
      "Epoch 447/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8172 - accuracy: 0.6637\n",
      "Epoch 448/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8172 - accuracy: 0.6660\n",
      "Epoch 449/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8175 - accuracy: 0.6682\n",
      "Epoch 450/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8160 - accuracy: 0.6656\n",
      "Epoch 451/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8156 - accuracy: 0.6671\n",
      "Epoch 452/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8182 - accuracy: 0.6640\n",
      "Epoch 453/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8091 - accuracy: 0.6697\n",
      "Epoch 454/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8166 - accuracy: 0.6638\n",
      "Epoch 455/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8195 - accuracy: 0.6624\n",
      "Epoch 456/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8164 - accuracy: 0.6675\n",
      "Epoch 457/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8203 - accuracy: 0.6641\n",
      "Epoch 458/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8134 - accuracy: 0.6657\n",
      "Epoch 459/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8154 - accuracy: 0.6634\n",
      "Epoch 460/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8121 - accuracy: 0.6665\n",
      "Epoch 461/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8125 - accuracy: 0.6675\n",
      "Epoch 462/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8146 - accuracy: 0.6664\n",
      "Epoch 463/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8138 - accuracy: 0.6664\n",
      "Epoch 464/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8186 - accuracy: 0.6653\n",
      "Epoch 465/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8099 - accuracy: 0.6667\n",
      "Epoch 466/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8123 - accuracy: 0.6695\n",
      "Epoch 467/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8217 - accuracy: 0.6635\n",
      "Epoch 468/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8105 - accuracy: 0.6710\n",
      "Epoch 469/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8144 - accuracy: 0.6668\n",
      "Epoch 470/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8135 - accuracy: 0.6688\n",
      "Epoch 471/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8149 - accuracy: 0.6654\n",
      "Epoch 472/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8099 - accuracy: 0.6649\n",
      "Epoch 473/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8135 - accuracy: 0.6656\n",
      "Epoch 474/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8159 - accuracy: 0.6669\n",
      "Epoch 475/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8172 - accuracy: 0.6668\n",
      "Epoch 476/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8134 - accuracy: 0.6693\n",
      "Epoch 477/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8113 - accuracy: 0.6710\n",
      "Epoch 478/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8115 - accuracy: 0.6659\n",
      "Epoch 479/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8117 - accuracy: 0.6655\n",
      "Epoch 480/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8093 - accuracy: 0.6698\n",
      "Epoch 481/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8110 - accuracy: 0.6673\n",
      "Epoch 482/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8116 - accuracy: 0.6668\n",
      "Epoch 483/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8077 - accuracy: 0.6699\n",
      "Epoch 484/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8114 - accuracy: 0.6683\n",
      "Epoch 485/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8095 - accuracy: 0.6681\n",
      "Epoch 486/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8111 - accuracy: 0.6667\n",
      "Epoch 487/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8088 - accuracy: 0.6697\n",
      "Epoch 488/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8040 - accuracy: 0.6739\n",
      "Epoch 489/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8107 - accuracy: 0.6673\n",
      "Epoch 490/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8098 - accuracy: 0.6678\n",
      "Epoch 491/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8101 - accuracy: 0.6680\n",
      "Epoch 492/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8048 - accuracy: 0.6716\n",
      "Epoch 493/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8088 - accuracy: 0.6661\n",
      "Epoch 494/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8113 - accuracy: 0.6694\n",
      "Epoch 495/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8114 - accuracy: 0.6672\n",
      "Epoch 496/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8059 - accuracy: 0.6685\n",
      "Epoch 497/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8121 - accuracy: 0.6666\n",
      "Epoch 498/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8065 - accuracy: 0.6710\n",
      "Epoch 499/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8135 - accuracy: 0.6739\n",
      "Epoch 500/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8101 - accuracy: 0.6654\n",
      "Epoch 501/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8072 - accuracy: 0.6686\n",
      "Epoch 502/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8087 - accuracy: 0.6717\n",
      "Epoch 503/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8066 - accuracy: 0.6683\n",
      "Epoch 504/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8114 - accuracy: 0.6683\n",
      "Epoch 505/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8092 - accuracy: 0.6653\n",
      "Epoch 506/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8053 - accuracy: 0.6712\n",
      "Epoch 507/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8097 - accuracy: 0.6662\n",
      "Epoch 508/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8044 - accuracy: 0.6698\n",
      "Epoch 509/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8090 - accuracy: 0.6705\n",
      "Epoch 510/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8084 - accuracy: 0.6726\n",
      "Epoch 511/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8092 - accuracy: 0.6693\n",
      "Epoch 512/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8131 - accuracy: 0.6674\n",
      "Epoch 513/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8058 - accuracy: 0.6706\n",
      "Epoch 514/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8054 - accuracy: 0.6715\n",
      "Epoch 515/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8122 - accuracy: 0.6672\n",
      "Epoch 516/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8093 - accuracy: 0.6695\n",
      "Epoch 517/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8042 - accuracy: 0.6720\n",
      "Epoch 518/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8052 - accuracy: 0.6679\n",
      "Epoch 519/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8013 - accuracy: 0.6718\n",
      "Epoch 520/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.8097 - accuracy: 0.6701\n",
      "Epoch 521/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8078 - accuracy: 0.6680\n",
      "Epoch 522/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8045 - accuracy: 0.6710\n",
      "Epoch 523/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8122 - accuracy: 0.6672\n",
      "Epoch 524/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8099 - accuracy: 0.6708\n",
      "Epoch 525/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8073 - accuracy: 0.6677\n",
      "Epoch 526/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8070 - accuracy: 0.6691\n",
      "Epoch 527/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8059 - accuracy: 0.6727\n",
      "Epoch 528/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8097 - accuracy: 0.6696\n",
      "Epoch 529/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8110 - accuracy: 0.6686\n",
      "Epoch 530/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8094 - accuracy: 0.6682\n",
      "Epoch 531/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7983 - accuracy: 0.6739\n",
      "Epoch 532/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8042 - accuracy: 0.6718\n",
      "Epoch 533/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7985 - accuracy: 0.6757\n",
      "Epoch 534/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8051 - accuracy: 0.6678\n",
      "Epoch 535/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8062 - accuracy: 0.6719\n",
      "Epoch 536/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7987 - accuracy: 0.6740\n",
      "Epoch 537/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8075 - accuracy: 0.6686\n",
      "Epoch 538/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8012 - accuracy: 0.6721\n",
      "Epoch 539/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8023 - accuracy: 0.6731\n",
      "Epoch 540/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8039 - accuracy: 0.6663\n",
      "Epoch 541/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8036 - accuracy: 0.6725\n",
      "Epoch 542/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.8030 - accuracy: 0.6703\n",
      "Epoch 543/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8019 - accuracy: 0.6758\n",
      "Epoch 544/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8061 - accuracy: 0.6692\n",
      "Epoch 545/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8004 - accuracy: 0.6700\n",
      "Epoch 546/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7983 - accuracy: 0.6726\n",
      "Epoch 547/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8019 - accuracy: 0.6724\n",
      "Epoch 548/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8021 - accuracy: 0.6706\n",
      "Epoch 549/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8042 - accuracy: 0.6687\n",
      "Epoch 550/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7995 - accuracy: 0.6730\n",
      "Epoch 551/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.8014 - accuracy: 0.6708\n",
      "Epoch 552/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8028 - accuracy: 0.6721\n",
      "Epoch 553/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8003 - accuracy: 0.6707\n",
      "Epoch 554/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8025 - accuracy: 0.6714\n",
      "Epoch 555/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8031 - accuracy: 0.6708\n",
      "Epoch 556/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7988 - accuracy: 0.6701\n",
      "Epoch 557/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7972 - accuracy: 0.6718\n",
      "Epoch 558/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8029 - accuracy: 0.6712\n",
      "Epoch 559/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7950 - accuracy: 0.6725\n",
      "Epoch 560/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8011 - accuracy: 0.6727\n",
      "Epoch 561/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8030 - accuracy: 0.6736\n",
      "Epoch 562/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8046 - accuracy: 0.6714\n",
      "Epoch 563/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7973 - accuracy: 0.6738\n",
      "Epoch 564/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7958 - accuracy: 0.6768\n",
      "Epoch 565/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7985 - accuracy: 0.6742\n",
      "Epoch 566/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8008 - accuracy: 0.6770\n",
      "Epoch 567/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7982 - accuracy: 0.6725\n",
      "Epoch 568/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8008 - accuracy: 0.6723\n",
      "Epoch 569/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7958 - accuracy: 0.6757\n",
      "Epoch 570/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8061 - accuracy: 0.6724\n",
      "Epoch 571/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7966 - accuracy: 0.6748\n",
      "Epoch 572/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8054 - accuracy: 0.6743\n",
      "Epoch 573/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7968 - accuracy: 0.6733\n",
      "Epoch 574/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7976 - accuracy: 0.6731\n",
      "Epoch 575/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7990 - accuracy: 0.6752\n",
      "Epoch 576/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8089 - accuracy: 0.6705\n",
      "Epoch 577/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7936 - accuracy: 0.6708\n",
      "Epoch 578/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7978 - accuracy: 0.6733\n",
      "Epoch 579/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7994 - accuracy: 0.6748\n",
      "Epoch 580/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7954 - accuracy: 0.6765\n",
      "Epoch 581/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7907 - accuracy: 0.6765\n",
      "Epoch 582/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8039 - accuracy: 0.6715\n",
      "Epoch 583/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7992 - accuracy: 0.6757\n",
      "Epoch 584/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8016 - accuracy: 0.6750\n",
      "Epoch 585/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7923 - accuracy: 0.6769\n",
      "Epoch 586/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7965 - accuracy: 0.6790\n",
      "Epoch 587/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7939 - accuracy: 0.6767\n",
      "Epoch 588/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7949 - accuracy: 0.6764\n",
      "Epoch 589/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7947 - accuracy: 0.6777\n",
      "Epoch 590/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7964 - accuracy: 0.6747\n",
      "Epoch 591/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7956 - accuracy: 0.6742\n",
      "Epoch 592/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7976 - accuracy: 0.6768\n",
      "Epoch 593/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7933 - accuracy: 0.6763\n",
      "Epoch 594/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7887 - accuracy: 0.6756\n",
      "Epoch 595/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7936 - accuracy: 0.6748\n",
      "Epoch 596/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7990 - accuracy: 0.6698\n",
      "Epoch 597/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7947 - accuracy: 0.6780\n",
      "Epoch 598/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7975 - accuracy: 0.6721\n",
      "Epoch 599/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7962 - accuracy: 0.6742\n",
      "Epoch 600/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8039 - accuracy: 0.6727\n",
      "Epoch 601/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7988 - accuracy: 0.6720\n",
      "Epoch 602/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7947 - accuracy: 0.6752\n",
      "Epoch 603/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8002 - accuracy: 0.6718\n",
      "Epoch 604/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7951 - accuracy: 0.6725\n",
      "Epoch 605/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7918 - accuracy: 0.6767\n",
      "Epoch 606/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7901 - accuracy: 0.6766\n",
      "Epoch 607/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7952 - accuracy: 0.6725\n",
      "Epoch 608/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7991 - accuracy: 0.6710\n",
      "Epoch 609/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7937 - accuracy: 0.6764\n",
      "Epoch 610/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7894 - accuracy: 0.6760\n",
      "Epoch 611/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8056 - accuracy: 0.6717\n",
      "Epoch 612/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7932 - accuracy: 0.6764\n",
      "Epoch 613/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.8019 - accuracy: 0.6742\n",
      "Epoch 614/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7882 - accuracy: 0.6793\n",
      "Epoch 615/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7911 - accuracy: 0.6776\n",
      "Epoch 616/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7953 - accuracy: 0.6745\n",
      "Epoch 617/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7975 - accuracy: 0.6740\n",
      "Epoch 618/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7995 - accuracy: 0.6717\n",
      "Epoch 619/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7923 - accuracy: 0.6803\n",
      "Epoch 620/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7918 - accuracy: 0.6748\n",
      "Epoch 621/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7871 - accuracy: 0.6783\n",
      "Epoch 622/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7927 - accuracy: 0.6771\n",
      "Epoch 623/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7876 - accuracy: 0.6796\n",
      "Epoch 624/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7943 - accuracy: 0.6757\n",
      "Epoch 625/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7947 - accuracy: 0.6737\n",
      "Epoch 626/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7908 - accuracy: 0.6758\n",
      "Epoch 627/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7919 - accuracy: 0.6751\n",
      "Epoch 628/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7913 - accuracy: 0.6774\n",
      "Epoch 629/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7851 - accuracy: 0.6800\n",
      "Epoch 630/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7918 - accuracy: 0.6797\n",
      "Epoch 631/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7802 - accuracy: 0.6813\n",
      "Epoch 632/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7911 - accuracy: 0.6782\n",
      "Epoch 633/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7883 - accuracy: 0.6777\n",
      "Epoch 634/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7911 - accuracy: 0.6751\n",
      "Epoch 635/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7994 - accuracy: 0.6701\n",
      "Epoch 636/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7938 - accuracy: 0.6759\n",
      "Epoch 637/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7913 - accuracy: 0.6763\n",
      "Epoch 638/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7877 - accuracy: 0.6787\n",
      "Epoch 639/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7867 - accuracy: 0.6781\n",
      "Epoch 640/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7945 - accuracy: 0.6783\n",
      "Epoch 641/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7881 - accuracy: 0.6785\n",
      "Epoch 642/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7928 - accuracy: 0.6763\n",
      "Epoch 643/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7944 - accuracy: 0.6775\n",
      "Epoch 644/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7901 - accuracy: 0.6765\n",
      "Epoch 645/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7873 - accuracy: 0.6826\n",
      "Epoch 646/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7929 - accuracy: 0.6745\n",
      "Epoch 647/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7919 - accuracy: 0.6756\n",
      "Epoch 648/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7856 - accuracy: 0.6769\n",
      "Epoch 649/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7835 - accuracy: 0.6814\n",
      "Epoch 650/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7872 - accuracy: 0.6804\n",
      "Epoch 651/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7939 - accuracy: 0.6769\n",
      "Epoch 652/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7866 - accuracy: 0.6791\n",
      "Epoch 653/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7905 - accuracy: 0.6782\n",
      "Epoch 654/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7846 - accuracy: 0.6787\n",
      "Epoch 655/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7926 - accuracy: 0.6775\n",
      "Epoch 656/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7840 - accuracy: 0.6785\n",
      "Epoch 657/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7902 - accuracy: 0.6726\n",
      "Epoch 658/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7878 - accuracy: 0.6812\n",
      "Epoch 659/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7825 - accuracy: 0.6798\n",
      "Epoch 660/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7933 - accuracy: 0.6789\n",
      "Epoch 661/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7886 - accuracy: 0.6781\n",
      "Epoch 662/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7865 - accuracy: 0.6775\n",
      "Epoch 663/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7913 - accuracy: 0.6767\n",
      "Epoch 664/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7850 - accuracy: 0.6813\n",
      "Epoch 665/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7858 - accuracy: 0.6802\n",
      "Epoch 666/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7860 - accuracy: 0.6785\n",
      "Epoch 667/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7856 - accuracy: 0.6776\n",
      "Epoch 668/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7831 - accuracy: 0.6805\n",
      "Epoch 669/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7868 - accuracy: 0.6770\n",
      "Epoch 670/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7847 - accuracy: 0.6785\n",
      "Epoch 671/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7863 - accuracy: 0.6780\n",
      "Epoch 672/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7911 - accuracy: 0.6753\n",
      "Epoch 673/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7880 - accuracy: 0.6777\n",
      "Epoch 674/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7814 - accuracy: 0.6833\n",
      "Epoch 675/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7860 - accuracy: 0.6763\n",
      "Epoch 676/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7889 - accuracy: 0.6742\n",
      "Epoch 677/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7879 - accuracy: 0.6781\n",
      "Epoch 678/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7804 - accuracy: 0.6858\n",
      "Epoch 679/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7904 - accuracy: 0.6780\n",
      "Epoch 680/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7781 - accuracy: 0.6851\n",
      "Epoch 681/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7798 - accuracy: 0.6833\n",
      "Epoch 682/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7842 - accuracy: 0.6802\n",
      "Epoch 683/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7832 - accuracy: 0.6792\n",
      "Epoch 684/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7844 - accuracy: 0.6835\n",
      "Epoch 685/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7909 - accuracy: 0.6791\n",
      "Epoch 686/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7838 - accuracy: 0.6776\n",
      "Epoch 687/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7852 - accuracy: 0.6818\n",
      "Epoch 688/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7816 - accuracy: 0.6833\n",
      "Epoch 689/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7820 - accuracy: 0.6763\n",
      "Epoch 690/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7842 - accuracy: 0.6819\n",
      "Epoch 691/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7886 - accuracy: 0.6767\n",
      "Epoch 692/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7861 - accuracy: 0.6826\n",
      "Epoch 693/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7841 - accuracy: 0.6822\n",
      "Epoch 694/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7855 - accuracy: 0.6808\n",
      "Epoch 695/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7844 - accuracy: 0.6806\n",
      "Epoch 696/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7824 - accuracy: 0.6840\n",
      "Epoch 697/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7816 - accuracy: 0.6795\n",
      "Epoch 698/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7838 - accuracy: 0.6812\n",
      "Epoch 699/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7782 - accuracy: 0.6800\n",
      "Epoch 700/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7834 - accuracy: 0.6819\n",
      "Epoch 701/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7804 - accuracy: 0.6829\n",
      "Epoch 702/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7826 - accuracy: 0.6768\n",
      "Epoch 703/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7922 - accuracy: 0.6776\n",
      "Epoch 704/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7856 - accuracy: 0.6766\n",
      "Epoch 705/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7787 - accuracy: 0.6817\n",
      "Epoch 706/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7790 - accuracy: 0.6819\n",
      "Epoch 707/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7839 - accuracy: 0.6827\n",
      "Epoch 708/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7852 - accuracy: 0.6810\n",
      "Epoch 709/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7788 - accuracy: 0.6849\n",
      "Epoch 710/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7718 - accuracy: 0.6858\n",
      "Epoch 711/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7785 - accuracy: 0.6852\n",
      "Epoch 712/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7758 - accuracy: 0.6857\n",
      "Epoch 713/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7826 - accuracy: 0.6771\n",
      "Epoch 714/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7774 - accuracy: 0.6839\n",
      "Epoch 715/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7795 - accuracy: 0.6793\n",
      "Epoch 716/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7862 - accuracy: 0.6822\n",
      "Epoch 717/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7811 - accuracy: 0.6797\n",
      "Epoch 718/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7807 - accuracy: 0.6796\n",
      "Epoch 719/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7809 - accuracy: 0.6813\n",
      "Epoch 720/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7831 - accuracy: 0.6791\n",
      "Epoch 721/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7780 - accuracy: 0.6816\n",
      "Epoch 722/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7828 - accuracy: 0.6806\n",
      "Epoch 723/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7712 - accuracy: 0.6836\n",
      "Epoch 724/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7850 - accuracy: 0.6790\n",
      "Epoch 725/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7797 - accuracy: 0.6798\n",
      "Epoch 726/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7778 - accuracy: 0.6840\n",
      "Epoch 727/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7805 - accuracy: 0.6839\n",
      "Epoch 728/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7772 - accuracy: 0.6832\n",
      "Epoch 729/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7747 - accuracy: 0.6827\n",
      "Epoch 730/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7833 - accuracy: 0.6794\n",
      "Epoch 731/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7789 - accuracy: 0.6842\n",
      "Epoch 732/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7821 - accuracy: 0.6825\n",
      "Epoch 733/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7821 - accuracy: 0.6793\n",
      "Epoch 734/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7807 - accuracy: 0.6820\n",
      "Epoch 735/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7782 - accuracy: 0.6816\n",
      "Epoch 736/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7781 - accuracy: 0.6832\n",
      "Epoch 737/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7800 - accuracy: 0.6842\n",
      "Epoch 738/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7788 - accuracy: 0.6861\n",
      "Epoch 739/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7828 - accuracy: 0.6805\n",
      "Epoch 740/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7791 - accuracy: 0.6826\n",
      "Epoch 741/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7776 - accuracy: 0.6814\n",
      "Epoch 742/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7751 - accuracy: 0.6844\n",
      "Epoch 743/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7813 - accuracy: 0.6808\n",
      "Epoch 744/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7816 - accuracy: 0.6782\n",
      "Epoch 745/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7769 - accuracy: 0.6806\n",
      "Epoch 746/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7702 - accuracy: 0.6854\n",
      "Epoch 747/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7750 - accuracy: 0.6851\n",
      "Epoch 748/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7844 - accuracy: 0.6804\n",
      "Epoch 749/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7766 - accuracy: 0.6870\n",
      "Epoch 750/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7758 - accuracy: 0.6824\n",
      "Epoch 751/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7766 - accuracy: 0.6841\n",
      "Epoch 752/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7778 - accuracy: 0.6826\n",
      "Epoch 753/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7816 - accuracy: 0.6800\n",
      "Epoch 754/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7786 - accuracy: 0.6821\n",
      "Epoch 755/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7741 - accuracy: 0.6827\n",
      "Epoch 756/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7759 - accuracy: 0.6872\n",
      "Epoch 757/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7742 - accuracy: 0.6832\n",
      "Epoch 758/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7735 - accuracy: 0.6852\n",
      "Epoch 759/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7735 - accuracy: 0.6870\n",
      "Epoch 760/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7712 - accuracy: 0.6865\n",
      "Epoch 761/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7802 - accuracy: 0.6786\n",
      "Epoch 762/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7770 - accuracy: 0.6827\n",
      "Epoch 763/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7714 - accuracy: 0.6850\n",
      "Epoch 764/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7777 - accuracy: 0.6828\n",
      "Epoch 765/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7736 - accuracy: 0.6833\n",
      "Epoch 766/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7770 - accuracy: 0.6838\n",
      "Epoch 767/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7782 - accuracy: 0.6806\n",
      "Epoch 768/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7746 - accuracy: 0.6825\n",
      "Epoch 769/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7732 - accuracy: 0.6853\n",
      "Epoch 770/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7774 - accuracy: 0.6809\n",
      "Epoch 771/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7747 - accuracy: 0.6883\n",
      "Epoch 772/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7798 - accuracy: 0.6842\n",
      "Epoch 773/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7759 - accuracy: 0.6827\n",
      "Epoch 774/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7734 - accuracy: 0.6864\n",
      "Epoch 775/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7719 - accuracy: 0.6819\n",
      "Epoch 776/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7743 - accuracy: 0.6869\n",
      "Epoch 777/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7753 - accuracy: 0.6844\n",
      "Epoch 778/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7756 - accuracy: 0.6838\n",
      "Epoch 779/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7733 - accuracy: 0.6855\n",
      "Epoch 780/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7714 - accuracy: 0.6839\n",
      "Epoch 781/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7671 - accuracy: 0.6877\n",
      "Epoch 782/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7689 - accuracy: 0.6877\n",
      "Epoch 783/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7734 - accuracy: 0.6867\n",
      "Epoch 784/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7748 - accuracy: 0.6864\n",
      "Epoch 785/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7729 - accuracy: 0.6839\n",
      "Epoch 786/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7804 - accuracy: 0.6841\n",
      "Epoch 787/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7719 - accuracy: 0.6851\n",
      "Epoch 788/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7760 - accuracy: 0.6807\n",
      "Epoch 789/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7704 - accuracy: 0.6866\n",
      "Epoch 790/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7708 - accuracy: 0.6865\n",
      "Epoch 791/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7754 - accuracy: 0.6871\n",
      "Epoch 792/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7712 - accuracy: 0.6883\n",
      "Epoch 793/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7726 - accuracy: 0.6879\n",
      "Epoch 794/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7741 - accuracy: 0.6850\n",
      "Epoch 795/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7733 - accuracy: 0.6852\n",
      "Epoch 796/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7725 - accuracy: 0.6851\n",
      "Epoch 797/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7749 - accuracy: 0.6868\n",
      "Epoch 798/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7713 - accuracy: 0.6847\n",
      "Epoch 799/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7769 - accuracy: 0.6841\n",
      "Epoch 800/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7706 - accuracy: 0.6873\n",
      "Epoch 801/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7748 - accuracy: 0.6825\n",
      "Epoch 802/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7722 - accuracy: 0.6846\n",
      "Epoch 803/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7682 - accuracy: 0.6831\n",
      "Epoch 804/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7770 - accuracy: 0.6839\n",
      "Epoch 805/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7747 - accuracy: 0.6877\n",
      "Epoch 806/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7691 - accuracy: 0.6855\n",
      "Epoch 807/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7747 - accuracy: 0.6866\n",
      "Epoch 808/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7733 - accuracy: 0.6880\n",
      "Epoch 809/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7774 - accuracy: 0.6814\n",
      "Epoch 810/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7747 - accuracy: 0.6847\n",
      "Epoch 811/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7722 - accuracy: 0.6897\n",
      "Epoch 812/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7746 - accuracy: 0.6844\n",
      "Epoch 813/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7734 - accuracy: 0.6879\n",
      "Epoch 814/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7653 - accuracy: 0.6836\n",
      "Epoch 815/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7665 - accuracy: 0.6904\n",
      "Epoch 816/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7739 - accuracy: 0.6858\n",
      "Epoch 817/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7686 - accuracy: 0.6887\n",
      "Epoch 818/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7703 - accuracy: 0.6876\n",
      "Epoch 819/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7720 - accuracy: 0.6836\n",
      "Epoch 820/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7646 - accuracy: 0.6906\n",
      "Epoch 821/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7650 - accuracy: 0.6868\n",
      "Epoch 822/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7661 - accuracy: 0.6887\n",
      "Epoch 823/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7733 - accuracy: 0.6864\n",
      "Epoch 824/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7688 - accuracy: 0.6905\n",
      "Epoch 825/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7719 - accuracy: 0.6852\n",
      "Epoch 826/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7670 - accuracy: 0.6886\n",
      "Epoch 827/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7687 - accuracy: 0.6904\n",
      "Epoch 828/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7689 - accuracy: 0.6858\n",
      "Epoch 829/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7710 - accuracy: 0.6850\n",
      "Epoch 830/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7696 - accuracy: 0.6896\n",
      "Epoch 831/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7718 - accuracy: 0.6845\n",
      "Epoch 832/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7668 - accuracy: 0.6863\n",
      "Epoch 833/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7708 - accuracy: 0.6871\n",
      "Epoch 834/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7697 - accuracy: 0.6900\n",
      "Epoch 835/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7646 - accuracy: 0.6889\n",
      "Epoch 836/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7732 - accuracy: 0.6846\n",
      "Epoch 837/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7684 - accuracy: 0.6902\n",
      "Epoch 838/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7682 - accuracy: 0.6889\n",
      "Epoch 839/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7663 - accuracy: 0.6899\n",
      "Epoch 840/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7672 - accuracy: 0.6884\n",
      "Epoch 841/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7619 - accuracy: 0.6895\n",
      "Epoch 842/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7678 - accuracy: 0.6873\n",
      "Epoch 843/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7666 - accuracy: 0.6875\n",
      "Epoch 844/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7632 - accuracy: 0.6841\n",
      "Epoch 845/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7685 - accuracy: 0.6870\n",
      "Epoch 846/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7657 - accuracy: 0.6895\n",
      "Epoch 847/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7610 - accuracy: 0.6930\n",
      "Epoch 848/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7583 - accuracy: 0.6927\n",
      "Epoch 849/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7654 - accuracy: 0.6917\n",
      "Epoch 850/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7641 - accuracy: 0.6845\n",
      "Epoch 851/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7708 - accuracy: 0.6884\n",
      "Epoch 852/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7686 - accuracy: 0.6854\n",
      "Epoch 853/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7687 - accuracy: 0.6866\n",
      "Epoch 854/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7730 - accuracy: 0.6847\n",
      "Epoch 855/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7629 - accuracy: 0.6882\n",
      "Epoch 856/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7645 - accuracy: 0.6922\n",
      "Epoch 857/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7655 - accuracy: 0.6885\n",
      "Epoch 858/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7632 - accuracy: 0.6894\n",
      "Epoch 859/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7607 - accuracy: 0.6901\n",
      "Epoch 860/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7714 - accuracy: 0.6877\n",
      "Epoch 861/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7654 - accuracy: 0.6862\n",
      "Epoch 862/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7718 - accuracy: 0.6870\n",
      "Epoch 863/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7651 - accuracy: 0.6869\n",
      "Epoch 864/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7668 - accuracy: 0.6878\n",
      "Epoch 865/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7700 - accuracy: 0.6846\n",
      "Epoch 866/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7651 - accuracy: 0.6899\n",
      "Epoch 867/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7697 - accuracy: 0.6897\n",
      "Epoch 868/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7685 - accuracy: 0.6855\n",
      "Epoch 869/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7669 - accuracy: 0.6865\n",
      "Epoch 870/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7719 - accuracy: 0.6875\n",
      "Epoch 871/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7613 - accuracy: 0.6897\n",
      "Epoch 872/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7638 - accuracy: 0.6905\n",
      "Epoch 873/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7655 - accuracy: 0.6899\n",
      "Epoch 874/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7544 - accuracy: 0.6926\n",
      "Epoch 875/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7602 - accuracy: 0.6930\n",
      "Epoch 876/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7634 - accuracy: 0.6909\n",
      "Epoch 877/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7656 - accuracy: 0.6904\n",
      "Epoch 878/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7642 - accuracy: 0.6878\n",
      "Epoch 879/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7661 - accuracy: 0.6894\n",
      "Epoch 880/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7676 - accuracy: 0.6849\n",
      "Epoch 881/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7678 - accuracy: 0.6848\n",
      "Epoch 882/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7596 - accuracy: 0.6930\n",
      "Epoch 883/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7651 - accuracy: 0.6879\n",
      "Epoch 884/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7642 - accuracy: 0.6919\n",
      "Epoch 885/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7652 - accuracy: 0.6890\n",
      "Epoch 886/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7654 - accuracy: 0.6877\n",
      "Epoch 887/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7648 - accuracy: 0.6885\n",
      "Epoch 888/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7591 - accuracy: 0.6910\n",
      "Epoch 889/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7608 - accuracy: 0.6872\n",
      "Epoch 890/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7657 - accuracy: 0.6887\n",
      "Epoch 891/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7579 - accuracy: 0.6904\n",
      "Epoch 892/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7727 - accuracy: 0.6855\n",
      "Epoch 893/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7618 - accuracy: 0.6902\n",
      "Epoch 894/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7699 - accuracy: 0.6861\n",
      "Epoch 895/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7631 - accuracy: 0.6925\n",
      "Epoch 896/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7594 - accuracy: 0.6893\n",
      "Epoch 897/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7584 - accuracy: 0.6924\n",
      "Epoch 898/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7568 - accuracy: 0.6914\n",
      "Epoch 899/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7576 - accuracy: 0.6935\n",
      "Epoch 900/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7651 - accuracy: 0.6871\n",
      "Epoch 901/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7660 - accuracy: 0.6877\n",
      "Epoch 902/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7598 - accuracy: 0.6916\n",
      "Epoch 903/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7649 - accuracy: 0.6895\n",
      "Epoch 904/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7578 - accuracy: 0.6932\n",
      "Epoch 905/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7673 - accuracy: 0.6897\n",
      "Epoch 906/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7559 - accuracy: 0.6909\n",
      "Epoch 907/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7625 - accuracy: 0.6878\n",
      "Epoch 908/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7619 - accuracy: 0.6897\n",
      "Epoch 909/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7646 - accuracy: 0.6908\n",
      "Epoch 910/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7600 - accuracy: 0.6934\n",
      "Epoch 911/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7627 - accuracy: 0.6864\n",
      "Epoch 912/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7620 - accuracy: 0.6919\n",
      "Epoch 913/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7555 - accuracy: 0.6953\n",
      "Epoch 914/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7589 - accuracy: 0.6944\n",
      "Epoch 915/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7641 - accuracy: 0.6885\n",
      "Epoch 916/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7576 - accuracy: 0.6868\n",
      "Epoch 917/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7637 - accuracy: 0.6911\n",
      "Epoch 918/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7591 - accuracy: 0.6916\n",
      "Epoch 919/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7582 - accuracy: 0.6912\n",
      "Epoch 920/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7575 - accuracy: 0.6946\n",
      "Epoch 921/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7615 - accuracy: 0.6899\n",
      "Epoch 922/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7589 - accuracy: 0.6892\n",
      "Epoch 923/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7587 - accuracy: 0.6921\n",
      "Epoch 924/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7559 - accuracy: 0.6927\n",
      "Epoch 925/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7651 - accuracy: 0.6897\n",
      "Epoch 926/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7645 - accuracy: 0.6912\n",
      "Epoch 927/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7595 - accuracy: 0.6936\n",
      "Epoch 928/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7584 - accuracy: 0.6903\n",
      "Epoch 929/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7607 - accuracy: 0.6903\n",
      "Epoch 930/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7588 - accuracy: 0.6923\n",
      "Epoch 931/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7576 - accuracy: 0.6937\n",
      "Epoch 932/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7514 - accuracy: 0.6952\n",
      "Epoch 933/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7562 - accuracy: 0.6937\n",
      "Epoch 934/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7612 - accuracy: 0.6891\n",
      "Epoch 935/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7618 - accuracy: 0.6906\n",
      "Epoch 936/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7590 - accuracy: 0.6919\n",
      "Epoch 937/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7527 - accuracy: 0.6941\n",
      "Epoch 938/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7560 - accuracy: 0.6913\n",
      "Epoch 939/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7623 - accuracy: 0.6912\n",
      "Epoch 940/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7580 - accuracy: 0.6900\n",
      "Epoch 941/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7650 - accuracy: 0.6925\n",
      "Epoch 942/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7668 - accuracy: 0.6868\n",
      "Epoch 943/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7619 - accuracy: 0.6890\n",
      "Epoch 944/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7611 - accuracy: 0.6902\n",
      "Epoch 945/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7561 - accuracy: 0.6929\n",
      "Epoch 946/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7586 - accuracy: 0.6920\n",
      "Epoch 947/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7546 - accuracy: 0.6940\n",
      "Epoch 948/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7599 - accuracy: 0.6918\n",
      "Epoch 949/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7568 - accuracy: 0.6920\n",
      "Epoch 950/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7543 - accuracy: 0.6935\n",
      "Epoch 951/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7608 - accuracy: 0.6971\n",
      "Epoch 952/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7559 - accuracy: 0.6927\n",
      "Epoch 953/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7601 - accuracy: 0.6887\n",
      "Epoch 954/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7567 - accuracy: 0.6935\n",
      "Epoch 955/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7642 - accuracy: 0.6913\n",
      "Epoch 956/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7580 - accuracy: 0.6889\n",
      "Epoch 957/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7536 - accuracy: 0.6897\n",
      "Epoch 958/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7589 - accuracy: 0.6921\n",
      "Epoch 959/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7549 - accuracy: 0.6940\n",
      "Epoch 960/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7610 - accuracy: 0.6917\n",
      "Epoch 961/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7518 - accuracy: 0.6935\n",
      "Epoch 962/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7531 - accuracy: 0.6951\n",
      "Epoch 963/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7488 - accuracy: 0.6965\n",
      "Epoch 964/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7550 - accuracy: 0.6938\n",
      "Epoch 965/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7541 - accuracy: 0.6967\n",
      "Epoch 966/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7567 - accuracy: 0.6966\n",
      "Epoch 967/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7548 - accuracy: 0.6942\n",
      "Epoch 968/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7580 - accuracy: 0.6950\n",
      "Epoch 969/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7628 - accuracy: 0.6902\n",
      "Epoch 970/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7538 - accuracy: 0.6959\n",
      "Epoch 971/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7545 - accuracy: 0.6956\n",
      "Epoch 972/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7553 - accuracy: 0.6915\n",
      "Epoch 973/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7496 - accuracy: 0.6981\n",
      "Epoch 974/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7584 - accuracy: 0.6916\n",
      "Epoch 975/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7480 - accuracy: 0.6979\n",
      "Epoch 976/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7495 - accuracy: 0.6930\n",
      "Epoch 977/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7569 - accuracy: 0.6911\n",
      "Epoch 978/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7561 - accuracy: 0.6969\n",
      "Epoch 979/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7554 - accuracy: 0.6947\n",
      "Epoch 980/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7539 - accuracy: 0.6935\n",
      "Epoch 981/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7543 - accuracy: 0.6930\n",
      "Epoch 982/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7548 - accuracy: 0.6959\n",
      "Epoch 983/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7549 - accuracy: 0.6938\n",
      "Epoch 984/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7552 - accuracy: 0.6956\n",
      "Epoch 985/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7513 - accuracy: 0.6941\n",
      "Epoch 986/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7489 - accuracy: 0.6948\n",
      "Epoch 987/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7530 - accuracy: 0.6944\n",
      "Epoch 988/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7529 - accuracy: 0.6915\n",
      "Epoch 989/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7520 - accuracy: 0.6975\n",
      "Epoch 990/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7513 - accuracy: 0.6973\n",
      "Epoch 991/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7572 - accuracy: 0.6957\n",
      "Epoch 992/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7462 - accuracy: 0.6987\n",
      "Epoch 993/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7507 - accuracy: 0.6946\n",
      "Epoch 994/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7530 - accuracy: 0.6949\n",
      "Epoch 995/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7575 - accuracy: 0.6946\n",
      "Epoch 996/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7556 - accuracy: 0.6922\n",
      "Epoch 997/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7496 - accuracy: 0.6961\n",
      "Epoch 998/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7524 - accuracy: 0.6951\n",
      "Epoch 999/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7496 - accuracy: 0.6946\n",
      "Epoch 1000/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7542 - accuracy: 0.6951\n",
      "Epoch 1001/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7596 - accuracy: 0.6892\n",
      "Epoch 1002/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7533 - accuracy: 0.6946\n",
      "Epoch 1003/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7577 - accuracy: 0.6908\n",
      "Epoch 1004/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7527 - accuracy: 0.6951\n",
      "Epoch 1005/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7461 - accuracy: 0.6986\n",
      "Epoch 1006/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7538 - accuracy: 0.6966\n",
      "Epoch 1007/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7498 - accuracy: 0.6945\n",
      "Epoch 1008/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7507 - accuracy: 0.6978\n",
      "Epoch 1009/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7484 - accuracy: 0.6979\n",
      "Epoch 1010/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7583 - accuracy: 0.6933\n",
      "Epoch 1011/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7539 - accuracy: 0.6954\n",
      "Epoch 1012/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7502 - accuracy: 0.6968\n",
      "Epoch 1013/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7558 - accuracy: 0.6937\n",
      "Epoch 1014/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7538 - accuracy: 0.6942\n",
      "Epoch 1015/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7516 - accuracy: 0.6903\n",
      "Epoch 1016/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7509 - accuracy: 0.6945\n",
      "Epoch 1017/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7541 - accuracy: 0.6966\n",
      "Epoch 1018/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7478 - accuracy: 0.6950\n",
      "Epoch 1019/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7614 - accuracy: 0.6904\n",
      "Epoch 1020/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7502 - accuracy: 0.6949\n",
      "Epoch 1021/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7505 - accuracy: 0.6949\n",
      "Epoch 1022/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7494 - accuracy: 0.6984\n",
      "Epoch 1023/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7545 - accuracy: 0.6958\n",
      "Epoch 1024/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7535 - accuracy: 0.6946\n",
      "Epoch 1025/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7533 - accuracy: 0.6966\n",
      "Epoch 1026/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7440 - accuracy: 0.6979\n",
      "Epoch 1027/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7579 - accuracy: 0.6933\n",
      "Epoch 1028/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7560 - accuracy: 0.6918\n",
      "Epoch 1029/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7519 - accuracy: 0.6973\n",
      "Epoch 1030/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7545 - accuracy: 0.6963\n",
      "Epoch 1031/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7516 - accuracy: 0.6955\n",
      "Epoch 1032/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7504 - accuracy: 0.6946\n",
      "Epoch 1033/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7533 - accuracy: 0.6951\n",
      "Epoch 1034/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7467 - accuracy: 0.6971\n",
      "Epoch 1035/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7529 - accuracy: 0.6918\n",
      "Epoch 1036/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7510 - accuracy: 0.6953\n",
      "Epoch 1037/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7471 - accuracy: 0.6984\n",
      "Epoch 1038/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7524 - accuracy: 0.6938\n",
      "Epoch 1039/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7522 - accuracy: 0.6947\n",
      "Epoch 1040/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7523 - accuracy: 0.6955\n",
      "Epoch 1041/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7509 - accuracy: 0.6961\n",
      "Epoch 1042/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7519 - accuracy: 0.6938\n",
      "Epoch 1043/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7456 - accuracy: 0.6964\n",
      "Epoch 1044/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7487 - accuracy: 0.6975\n",
      "Epoch 1045/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7496 - accuracy: 0.6981\n",
      "Epoch 1046/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7554 - accuracy: 0.6929\n",
      "Epoch 1047/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7459 - accuracy: 0.6976\n",
      "Epoch 1048/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7534 - accuracy: 0.6941\n",
      "Epoch 1049/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7527 - accuracy: 0.6916\n",
      "Epoch 1050/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7476 - accuracy: 0.6964\n",
      "Epoch 1051/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7495 - accuracy: 0.6951\n",
      "Epoch 1052/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7491 - accuracy: 0.6991\n",
      "Epoch 1053/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7484 - accuracy: 0.6989\n",
      "Epoch 1054/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7530 - accuracy: 0.6916\n",
      "Epoch 1055/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7528 - accuracy: 0.6944\n",
      "Epoch 1056/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7567 - accuracy: 0.6923\n",
      "Epoch 1057/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7558 - accuracy: 0.6914\n",
      "Epoch 1058/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7436 - accuracy: 0.7012\n",
      "Epoch 1059/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7480 - accuracy: 0.6951\n",
      "Epoch 1060/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7493 - accuracy: 0.6958\n",
      "Epoch 1061/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7486 - accuracy: 0.6974\n",
      "Epoch 1062/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7458 - accuracy: 0.6967\n",
      "Epoch 1063/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7565 - accuracy: 0.6931\n",
      "Epoch 1064/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7479 - accuracy: 0.6976\n",
      "Epoch 1065/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7558 - accuracy: 0.6914\n",
      "Epoch 1066/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7483 - accuracy: 0.6961\n",
      "Epoch 1067/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7479 - accuracy: 0.6956\n",
      "Epoch 1068/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7501 - accuracy: 0.6969\n",
      "Epoch 1069/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7394 - accuracy: 0.6992\n",
      "Epoch 1070/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7486 - accuracy: 0.7016\n",
      "Epoch 1071/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7482 - accuracy: 0.6925\n",
      "Epoch 1072/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7524 - accuracy: 0.6959\n",
      "Epoch 1073/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7472 - accuracy: 0.6985\n",
      "Epoch 1074/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7465 - accuracy: 0.6980\n",
      "Epoch 1075/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7451 - accuracy: 0.6977\n",
      "Epoch 1076/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7445 - accuracy: 0.6943\n",
      "Epoch 1077/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7494 - accuracy: 0.6951\n",
      "Epoch 1078/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7441 - accuracy: 0.6967\n",
      "Epoch 1079/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7415 - accuracy: 0.7017\n",
      "Epoch 1080/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7413 - accuracy: 0.7028\n",
      "Epoch 1081/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7410 - accuracy: 0.7030\n",
      "Epoch 1082/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7470 - accuracy: 0.6986\n",
      "Epoch 1083/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7469 - accuracy: 0.6937\n",
      "Epoch 1084/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7505 - accuracy: 0.6928\n",
      "Epoch 1085/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7505 - accuracy: 0.6969\n",
      "Epoch 1086/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7529 - accuracy: 0.6918\n",
      "Epoch 1087/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7441 - accuracy: 0.6961\n",
      "Epoch 1088/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7497 - accuracy: 0.6987\n",
      "Epoch 1089/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7432 - accuracy: 0.7007\n",
      "Epoch 1090/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7457 - accuracy: 0.6974\n",
      "Epoch 1091/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7475 - accuracy: 0.6969\n",
      "Epoch 1092/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7468 - accuracy: 0.6956\n",
      "Epoch 1093/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7506 - accuracy: 0.6959\n",
      "Epoch 1094/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7476 - accuracy: 0.6975\n",
      "Epoch 1095/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7447 - accuracy: 0.6988\n",
      "Epoch 1096/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7446 - accuracy: 0.6974\n",
      "Epoch 1097/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7539 - accuracy: 0.6960\n",
      "Epoch 1098/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7412 - accuracy: 0.6990\n",
      "Epoch 1099/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7457 - accuracy: 0.6998\n",
      "Epoch 1100/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7468 - accuracy: 0.6992\n",
      "Epoch 1101/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7451 - accuracy: 0.6992\n",
      "Epoch 1102/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7439 - accuracy: 0.6998\n",
      "Epoch 1103/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7405 - accuracy: 0.7019\n",
      "Epoch 1104/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7509 - accuracy: 0.7002\n",
      "Epoch 1105/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7542 - accuracy: 0.6984\n",
      "Epoch 1106/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7466 - accuracy: 0.6954\n",
      "Epoch 1107/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7487 - accuracy: 0.6978\n",
      "Epoch 1108/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7476 - accuracy: 0.6954\n",
      "Epoch 1109/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7467 - accuracy: 0.6987\n",
      "Epoch 1110/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7489 - accuracy: 0.6970\n",
      "Epoch 1111/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7431 - accuracy: 0.6988\n",
      "Epoch 1112/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7435 - accuracy: 0.6991\n",
      "Epoch 1113/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7439 - accuracy: 0.6975\n",
      "Epoch 1114/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7447 - accuracy: 0.7005\n",
      "Epoch 1115/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7490 - accuracy: 0.6973\n",
      "Epoch 1116/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7418 - accuracy: 0.7007\n",
      "Epoch 1117/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7458 - accuracy: 0.6980\n",
      "Epoch 1118/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7427 - accuracy: 0.6998\n",
      "Epoch 1119/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7502 - accuracy: 0.6971\n",
      "Epoch 1120/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7485 - accuracy: 0.6963\n",
      "Epoch 1121/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7415 - accuracy: 0.6963\n",
      "Epoch 1122/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7407 - accuracy: 0.7010\n",
      "Epoch 1123/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7423 - accuracy: 0.7013\n",
      "Epoch 1124/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7463 - accuracy: 0.6986\n",
      "Epoch 1125/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7470 - accuracy: 0.6993\n",
      "Epoch 1126/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7418 - accuracy: 0.7026\n",
      "Epoch 1127/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7397 - accuracy: 0.6988\n",
      "Epoch 1128/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7458 - accuracy: 0.6988\n",
      "Epoch 1129/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7428 - accuracy: 0.6990\n",
      "Epoch 1130/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7579 - accuracy: 0.6927\n",
      "Epoch 1131/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7418 - accuracy: 0.6993\n",
      "Epoch 1132/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7384 - accuracy: 0.7002\n",
      "Epoch 1133/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7445 - accuracy: 0.6984\n",
      "Epoch 1134/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7465 - accuracy: 0.6953\n",
      "Epoch 1135/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7431 - accuracy: 0.6991\n",
      "Epoch 1136/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7352 - accuracy: 0.7004\n",
      "Epoch 1137/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7443 - accuracy: 0.7002\n",
      "Epoch 1138/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7469 - accuracy: 0.6988\n",
      "Epoch 1139/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7428 - accuracy: 0.6963\n",
      "Epoch 1140/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7396 - accuracy: 0.7016\n",
      "Epoch 1141/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7497 - accuracy: 0.6946\n",
      "Epoch 1142/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7416 - accuracy: 0.6962\n",
      "Epoch 1143/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7346 - accuracy: 0.7007\n",
      "Epoch 1144/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7403 - accuracy: 0.6986\n",
      "Epoch 1145/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7475 - accuracy: 0.6976\n",
      "Epoch 1146/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7476 - accuracy: 0.6943\n",
      "Epoch 1147/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7461 - accuracy: 0.6982\n",
      "Epoch 1148/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7438 - accuracy: 0.7018\n",
      "Epoch 1149/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7416 - accuracy: 0.6992\n",
      "Epoch 1150/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7460 - accuracy: 0.7005\n",
      "Epoch 1151/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7474 - accuracy: 0.6992\n",
      "Epoch 1152/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7331 - accuracy: 0.7043\n",
      "Epoch 1153/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7488 - accuracy: 0.6950\n",
      "Epoch 1154/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7417 - accuracy: 0.7006\n",
      "Epoch 1155/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7391 - accuracy: 0.7045\n",
      "Epoch 1156/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7435 - accuracy: 0.6986\n",
      "Epoch 1157/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7425 - accuracy: 0.6978\n",
      "Epoch 1158/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7437 - accuracy: 0.7000\n",
      "Epoch 1159/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7417 - accuracy: 0.7003\n",
      "Epoch 1160/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7393 - accuracy: 0.7043\n",
      "Epoch 1161/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7409 - accuracy: 0.7014\n",
      "Epoch 1162/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7407 - accuracy: 0.6995\n",
      "Epoch 1163/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7458 - accuracy: 0.6956\n",
      "Epoch 1164/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7354 - accuracy: 0.7016\n",
      "Epoch 1165/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7372 - accuracy: 0.7010\n",
      "Epoch 1166/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7417 - accuracy: 0.6981\n",
      "Epoch 1167/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7417 - accuracy: 0.7011\n",
      "Epoch 1168/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7432 - accuracy: 0.6979\n",
      "Epoch 1169/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7322 - accuracy: 0.7023\n",
      "Epoch 1170/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7405 - accuracy: 0.6997\n",
      "Epoch 1171/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7379 - accuracy: 0.7006\n",
      "Epoch 1172/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7404 - accuracy: 0.7021\n",
      "Epoch 1173/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7395 - accuracy: 0.7005\n",
      "Epoch 1174/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7434 - accuracy: 0.7000\n",
      "Epoch 1175/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7413 - accuracy: 0.7063\n",
      "Epoch 1176/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7485 - accuracy: 0.6962\n",
      "Epoch 1177/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7402 - accuracy: 0.6986\n",
      "Epoch 1178/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7438 - accuracy: 0.7013\n",
      "Epoch 1179/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7497 - accuracy: 0.6930\n",
      "Epoch 1180/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7406 - accuracy: 0.6966\n",
      "Epoch 1181/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7388 - accuracy: 0.7016\n",
      "Epoch 1182/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7403 - accuracy: 0.7001\n",
      "Epoch 1183/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7367 - accuracy: 0.6997\n",
      "Epoch 1184/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7370 - accuracy: 0.7039\n",
      "Epoch 1185/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7352 - accuracy: 0.7010\n",
      "Epoch 1186/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7429 - accuracy: 0.7002\n",
      "Epoch 1187/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7415 - accuracy: 0.6991\n",
      "Epoch 1188/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7329 - accuracy: 0.7042\n",
      "Epoch 1189/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7390 - accuracy: 0.7019\n",
      "Epoch 1190/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7434 - accuracy: 0.7055\n",
      "Epoch 1191/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7437 - accuracy: 0.6979\n",
      "Epoch 1192/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7328 - accuracy: 0.7035\n",
      "Epoch 1193/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7430 - accuracy: 0.6997\n",
      "Epoch 1194/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7346 - accuracy: 0.7009\n",
      "Epoch 1195/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7374 - accuracy: 0.6998\n",
      "Epoch 1196/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7431 - accuracy: 0.6981\n",
      "Epoch 1197/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7401 - accuracy: 0.7002\n",
      "Epoch 1198/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7367 - accuracy: 0.7020\n",
      "Epoch 1199/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7380 - accuracy: 0.7011\n",
      "Epoch 1200/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7389 - accuracy: 0.7009\n",
      "Epoch 1201/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7326 - accuracy: 0.7027\n",
      "Epoch 1202/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7382 - accuracy: 0.7039\n",
      "Epoch 1203/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7342 - accuracy: 0.7052\n",
      "Epoch 1204/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7364 - accuracy: 0.7017\n",
      "Epoch 1205/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7368 - accuracy: 0.7019\n",
      "Epoch 1206/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7416 - accuracy: 0.6987\n",
      "Epoch 1207/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7382 - accuracy: 0.6969\n",
      "Epoch 1208/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7458 - accuracy: 0.6983\n",
      "Epoch 1209/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7434 - accuracy: 0.7004\n",
      "Epoch 1210/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7361 - accuracy: 0.7001\n",
      "Epoch 1211/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7377 - accuracy: 0.7017\n",
      "Epoch 1212/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7408 - accuracy: 0.7035\n",
      "Epoch 1213/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7439 - accuracy: 0.7011\n",
      "Epoch 1214/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7369 - accuracy: 0.7005\n",
      "Epoch 1215/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7424 - accuracy: 0.6995\n",
      "Epoch 1216/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7404 - accuracy: 0.7006\n",
      "Epoch 1217/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7348 - accuracy: 0.7020\n",
      "Epoch 1218/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7356 - accuracy: 0.7027\n",
      "Epoch 1219/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7337 - accuracy: 0.6991\n",
      "Epoch 1220/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7318 - accuracy: 0.7035\n",
      "Epoch 1221/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7313 - accuracy: 0.7031\n",
      "Epoch 1222/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7418 - accuracy: 0.7012\n",
      "Epoch 1223/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7399 - accuracy: 0.6989\n",
      "Epoch 1224/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7353 - accuracy: 0.7010\n",
      "Epoch 1225/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7400 - accuracy: 0.7006\n",
      "Epoch 1226/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7393 - accuracy: 0.7001\n",
      "Epoch 1227/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7411 - accuracy: 0.6993\n",
      "Epoch 1228/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7371 - accuracy: 0.7038\n",
      "Epoch 1229/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7359 - accuracy: 0.7025\n",
      "Epoch 1230/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7387 - accuracy: 0.6997\n",
      "Epoch 1231/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7317 - accuracy: 0.7050\n",
      "Epoch 1232/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7281 - accuracy: 0.7083\n",
      "Epoch 1233/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7381 - accuracy: 0.7075\n",
      "Epoch 1234/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7367 - accuracy: 0.7014\n",
      "Epoch 1235/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7334 - accuracy: 0.7058\n",
      "Epoch 1236/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7385 - accuracy: 0.7014\n",
      "Epoch 1237/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7356 - accuracy: 0.7018\n",
      "Epoch 1238/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7370 - accuracy: 0.7015\n",
      "Epoch 1239/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7381 - accuracy: 0.7030\n",
      "Epoch 1240/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7358 - accuracy: 0.7008\n",
      "Epoch 1241/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7402 - accuracy: 0.7000\n",
      "Epoch 1242/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7397 - accuracy: 0.7010\n",
      "Epoch 1243/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7325 - accuracy: 0.7018\n",
      "Epoch 1244/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7410 - accuracy: 0.7058\n",
      "Epoch 1245/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7342 - accuracy: 0.7010\n",
      "Epoch 1246/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7309 - accuracy: 0.7027\n",
      "Epoch 1247/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7323 - accuracy: 0.7045\n",
      "Epoch 1248/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7329 - accuracy: 0.7056\n",
      "Epoch 1249/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7314 - accuracy: 0.7019\n",
      "Epoch 1250/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7365 - accuracy: 0.7027\n",
      "Epoch 1251/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7376 - accuracy: 0.7072\n",
      "Epoch 1252/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7349 - accuracy: 0.7036\n",
      "Epoch 1253/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7293 - accuracy: 0.7088\n",
      "Epoch 1254/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7335 - accuracy: 0.7048\n",
      "Epoch 1255/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7364 - accuracy: 0.7023\n",
      "Epoch 1256/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7368 - accuracy: 0.7030\n",
      "Epoch 1257/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7314 - accuracy: 0.7044\n",
      "Epoch 1258/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7390 - accuracy: 0.7008\n",
      "Epoch 1259/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7361 - accuracy: 0.7036\n",
      "Epoch 1260/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7361 - accuracy: 0.7054\n",
      "Epoch 1261/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7331 - accuracy: 0.7049\n",
      "Epoch 1262/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7372 - accuracy: 0.7009\n",
      "Epoch 1263/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7394 - accuracy: 0.7016\n",
      "Epoch 1264/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7328 - accuracy: 0.7048\n",
      "Epoch 1265/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7367 - accuracy: 0.7028\n",
      "Epoch 1266/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7340 - accuracy: 0.7059\n",
      "Epoch 1267/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7313 - accuracy: 0.7061\n",
      "Epoch 1268/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7342 - accuracy: 0.7048\n",
      "Epoch 1269/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7314 - accuracy: 0.7071\n",
      "Epoch 1270/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7424 - accuracy: 0.6984\n",
      "Epoch 1271/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7383 - accuracy: 0.7002\n",
      "Epoch 1272/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7434 - accuracy: 0.6994\n",
      "Epoch 1273/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7347 - accuracy: 0.6987\n",
      "Epoch 1274/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7355 - accuracy: 0.7052\n",
      "Epoch 1275/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7338 - accuracy: 0.7030\n",
      "Epoch 1276/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7276 - accuracy: 0.7055\n",
      "Epoch 1277/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7396 - accuracy: 0.7012\n",
      "Epoch 1278/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7283 - accuracy: 0.7057\n",
      "Epoch 1279/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7361 - accuracy: 0.7013\n",
      "Epoch 1280/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7285 - accuracy: 0.7023\n",
      "Epoch 1281/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7349 - accuracy: 0.7054\n",
      "Epoch 1282/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7292 - accuracy: 0.7050\n",
      "Epoch 1283/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7340 - accuracy: 0.7034\n",
      "Epoch 1284/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7270 - accuracy: 0.7064\n",
      "Epoch 1285/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7259 - accuracy: 0.7026\n",
      "Epoch 1286/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7344 - accuracy: 0.7068\n",
      "Epoch 1287/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7344 - accuracy: 0.7037\n",
      "Epoch 1288/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7289 - accuracy: 0.7034\n",
      "Epoch 1289/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7264 - accuracy: 0.7053\n",
      "Epoch 1290/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7375 - accuracy: 0.7014\n",
      "Epoch 1291/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7409 - accuracy: 0.7008\n",
      "Epoch 1292/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7220 - accuracy: 0.7078\n",
      "Epoch 1293/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7385 - accuracy: 0.6997\n",
      "Epoch 1294/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7307 - accuracy: 0.7037\n",
      "Epoch 1295/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7343 - accuracy: 0.7042\n",
      "Epoch 1296/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7298 - accuracy: 0.7057\n",
      "Epoch 1297/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7380 - accuracy: 0.7018\n",
      "Epoch 1298/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7318 - accuracy: 0.7076\n",
      "Epoch 1299/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7339 - accuracy: 0.7012\n",
      "Epoch 1300/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7349 - accuracy: 0.7009\n",
      "Epoch 1301/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7308 - accuracy: 0.7072\n",
      "Epoch 1302/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7273 - accuracy: 0.7059\n",
      "Epoch 1303/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7305 - accuracy: 0.7045\n",
      "Epoch 1304/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7318 - accuracy: 0.7017\n",
      "Epoch 1305/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7273 - accuracy: 0.7058\n",
      "Epoch 1306/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7324 - accuracy: 0.7019\n",
      "Epoch 1307/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7370 - accuracy: 0.7016\n",
      "Epoch 1308/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7358 - accuracy: 0.7027\n",
      "Epoch 1309/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7359 - accuracy: 0.7045\n",
      "Epoch 1310/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7285 - accuracy: 0.7056\n",
      "Epoch 1311/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7324 - accuracy: 0.7033\n",
      "Epoch 1312/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7262 - accuracy: 0.7068\n",
      "Epoch 1313/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7344 - accuracy: 0.7054\n",
      "Epoch 1314/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7281 - accuracy: 0.7055\n",
      "Epoch 1315/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7361 - accuracy: 0.7001\n",
      "Epoch 1316/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7357 - accuracy: 0.7032\n",
      "Epoch 1317/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7269 - accuracy: 0.7097\n",
      "Epoch 1318/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7273 - accuracy: 0.7085\n",
      "Epoch 1319/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7339 - accuracy: 0.7020\n",
      "Epoch 1320/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7267 - accuracy: 0.7069\n",
      "Epoch 1321/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7371 - accuracy: 0.7041\n",
      "Epoch 1322/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7334 - accuracy: 0.7026\n",
      "Epoch 1323/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7328 - accuracy: 0.7056\n",
      "Epoch 1324/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7366 - accuracy: 0.7036\n",
      "Epoch 1325/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7352 - accuracy: 0.7024\n",
      "Epoch 1326/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7264 - accuracy: 0.7098\n",
      "Epoch 1327/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7297 - accuracy: 0.7074\n",
      "Epoch 1328/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7251 - accuracy: 0.7088\n",
      "Epoch 1329/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7277 - accuracy: 0.7049\n",
      "Epoch 1330/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7293 - accuracy: 0.7050\n",
      "Epoch 1331/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7360 - accuracy: 0.7029\n",
      "Epoch 1332/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7349 - accuracy: 0.7032\n",
      "Epoch 1333/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7342 - accuracy: 0.7042\n",
      "Epoch 1334/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7315 - accuracy: 0.7046\n",
      "Epoch 1335/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7270 - accuracy: 0.7062\n",
      "Epoch 1336/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7288 - accuracy: 0.7052\n",
      "Epoch 1337/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7383 - accuracy: 0.7013\n",
      "Epoch 1338/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7289 - accuracy: 0.7031\n",
      "Epoch 1339/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7322 - accuracy: 0.7043\n",
      "Epoch 1340/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7285 - accuracy: 0.7063\n",
      "Epoch 1341/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7246 - accuracy: 0.7102\n",
      "Epoch 1342/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7336 - accuracy: 0.7039\n",
      "Epoch 1343/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7222 - accuracy: 0.7081\n",
      "Epoch 1344/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7244 - accuracy: 0.7077\n",
      "Epoch 1345/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7276 - accuracy: 0.7057\n",
      "Epoch 1346/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7296 - accuracy: 0.7084\n",
      "Epoch 1347/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7236 - accuracy: 0.7065\n",
      "Epoch 1348/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7302 - accuracy: 0.7080\n",
      "Epoch 1349/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7227 - accuracy: 0.7072\n",
      "Epoch 1350/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7312 - accuracy: 0.7067\n",
      "Epoch 1351/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7282 - accuracy: 0.7050\n",
      "Epoch 1352/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7260 - accuracy: 0.7045\n",
      "Epoch 1353/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7307 - accuracy: 0.7052\n",
      "Epoch 1354/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7261 - accuracy: 0.7087\n",
      "Epoch 1355/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7327 - accuracy: 0.7046\n",
      "Epoch 1356/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7271 - accuracy: 0.7038\n",
      "Epoch 1357/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7316 - accuracy: 0.7039\n",
      "Epoch 1358/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7299 - accuracy: 0.7048\n",
      "Epoch 1359/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7226 - accuracy: 0.7068\n",
      "Epoch 1360/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7299 - accuracy: 0.7056\n",
      "Epoch 1361/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7245 - accuracy: 0.7058\n",
      "Epoch 1391/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7302 - accuracy: 0.7071\n",
      "Epoch 1392/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7277 - accuracy: 0.7063\n",
      "Epoch 1393/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7290 - accuracy: 0.7109\n",
      "Epoch 1394/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7197 - accuracy: 0.7081\n",
      "Epoch 1395/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7232 - accuracy: 0.7065\n",
      "Epoch 1396/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7246 - accuracy: 0.7064\n",
      "Epoch 1397/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7268 - accuracy: 0.7035\n",
      "Epoch 1398/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7294 - accuracy: 0.7099\n",
      "Epoch 1399/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7289 - accuracy: 0.7077\n",
      "Epoch 1400/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7235 - accuracy: 0.7061\n",
      "Epoch 1401/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7328 - accuracy: 0.7023\n",
      "Epoch 1402/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7238 - accuracy: 0.7077\n",
      "Epoch 1403/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7295 - accuracy: 0.7045\n",
      "Epoch 1404/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7284 - accuracy: 0.7054\n",
      "Epoch 1362/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7290 - accuracy: 0.7086\n",
      "Epoch 1363/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7267 - accuracy: 0.7040\n",
      "Epoch 1364/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7276 - accuracy: 0.7030\n",
      "Epoch 1365/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7288 - accuracy: 0.7090\n",
      "Epoch 1366/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7293 - accuracy: 0.7078\n",
      "Epoch 1367/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7359 - accuracy: 0.7045\n",
      "Epoch 1368/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7269 - accuracy: 0.7058\n",
      "Epoch 1369/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7281 - accuracy: 0.7063\n",
      "Epoch 1370/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7259 - accuracy: 0.7068\n",
      "Epoch 1371/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7259 - accuracy: 0.7088\n",
      "Epoch 1372/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7285 - accuracy: 0.7055\n",
      "Epoch 1373/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7293 - accuracy: 0.7079\n",
      "Epoch 1374/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7278 - accuracy: 0.7086\n",
      "Epoch 1375/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7273 - accuracy: 0.7072\n",
      "Epoch 1376/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7246 - accuracy: 0.7085\n",
      "Epoch 1377/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7259 - accuracy: 0.7100\n",
      "Epoch 1378/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7265 - accuracy: 0.7107\n",
      "Epoch 1379/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7259 - accuracy: 0.7075\n",
      "Epoch 1380/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7274 - accuracy: 0.7087\n",
      "Epoch 1381/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7273 - accuracy: 0.7070\n",
      "Epoch 1382/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7270 - accuracy: 0.7091\n",
      "Epoch 1383/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7314 - accuracy: 0.7045\n",
      "Epoch 1384/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7293 - accuracy: 0.7088\n",
      "Epoch 1385/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7322 - accuracy: 0.7031\n",
      "Epoch 1386/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7208 - accuracy: 0.7087\n",
      "Epoch 1387/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7307 - accuracy: 0.7038\n",
      "Epoch 1388/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7234 - accuracy: 0.7094\n",
      "Epoch 1389/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7241 - accuracy: 0.7093\n",
      "Epoch 1390/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7274 - accuracy: 0.7100\n",
      "Epoch 1405/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7276 - accuracy: 0.7084\n",
      "Epoch 1406/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7300 - accuracy: 0.7078\n",
      "Epoch 1407/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7223 - accuracy: 0.7052\n",
      "Epoch 1408/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7304 - accuracy: 0.7045\n",
      "Epoch 1409/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7272 - accuracy: 0.7048\n",
      "Epoch 1410/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7242 - accuracy: 0.7080\n",
      "Epoch 1411/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7262 - accuracy: 0.7108\n",
      "Epoch 1412/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7326 - accuracy: 0.7063\n",
      "Epoch 1413/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7226 - accuracy: 0.7073\n",
      "Epoch 1414/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7239 - accuracy: 0.7113\n",
      "Epoch 1415/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7166 - accuracy: 0.7112\n",
      "Epoch 1416/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7177 - accuracy: 0.7081\n",
      "Epoch 1417/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7351 - accuracy: 0.7030\n",
      "Epoch 1418/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7293 - accuracy: 0.7055\n",
      "Epoch 1419/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7222 - accuracy: 0.7101\n",
      "Epoch 1420/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7281 - accuracy: 0.7044\n",
      "Epoch 1421/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7276 - accuracy: 0.7097\n",
      "Epoch 1422/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7283 - accuracy: 0.7053\n",
      "Epoch 1423/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7209 - accuracy: 0.7094\n",
      "Epoch 1424/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7224 - accuracy: 0.7124\n",
      "Epoch 1425/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7216 - accuracy: 0.7055\n",
      "Epoch 1426/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7147 - accuracy: 0.7082\n",
      "Epoch 1427/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7255 - accuracy: 0.7068\n",
      "Epoch 1428/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7266 - accuracy: 0.7094\n",
      "Epoch 1429/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7263 - accuracy: 0.7046\n",
      "Epoch 1430/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7171 - accuracy: 0.7111\n",
      "Epoch 1431/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7249 - accuracy: 0.7078\n",
      "Epoch 1432/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7214 - accuracy: 0.7083\n",
      "Epoch 1433/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7241 - accuracy: 0.7082\n",
      "Epoch 1434/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7223 - accuracy: 0.7100\n",
      "Epoch 1435/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7245 - accuracy: 0.7093\n",
      "Epoch 1436/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7247 - accuracy: 0.7100\n",
      "Epoch 1437/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7238 - accuracy: 0.7093\n",
      "Epoch 1438/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7220 - accuracy: 0.7112\n",
      "Epoch 1439/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7254 - accuracy: 0.7081\n",
      "Epoch 1440/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7236 - accuracy: 0.7100\n",
      "Epoch 1441/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7242 - accuracy: 0.7071\n",
      "Epoch 1442/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7252 - accuracy: 0.7071\n",
      "Epoch 1443/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7213 - accuracy: 0.7078\n",
      "Epoch 1444/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7304 - accuracy: 0.7058\n",
      "Epoch 1445/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7238 - accuracy: 0.7086\n",
      "Epoch 1446/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7196 - accuracy: 0.7077\n",
      "Epoch 1447/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7293 - accuracy: 0.7070\n",
      "Epoch 1448/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7235 - accuracy: 0.7075\n",
      "Epoch 1449/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7272 - accuracy: 0.7034\n",
      "Epoch 1450/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7162 - accuracy: 0.7124\n",
      "Epoch 1451/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7252 - accuracy: 0.7113\n",
      "Epoch 1452/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7210 - accuracy: 0.7090\n",
      "Epoch 1453/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7237 - accuracy: 0.7104\n",
      "Epoch 1454/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7301 - accuracy: 0.7064\n",
      "Epoch 1455/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7198 - accuracy: 0.7094\n",
      "Epoch 1456/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7289 - accuracy: 0.7057\n",
      "Epoch 1457/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7275 - accuracy: 0.7053\n",
      "Epoch 1458/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7200 - accuracy: 0.7108\n",
      "Epoch 1459/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7240 - accuracy: 0.7096\n",
      "Epoch 1460/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7223 - accuracy: 0.7082\n",
      "Epoch 1461/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7278 - accuracy: 0.7058\n",
      "Epoch 1462/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7231 - accuracy: 0.7077\n",
      "Epoch 1463/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7267 - accuracy: 0.7053\n",
      "Epoch 1464/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7257 - accuracy: 0.7080\n",
      "Epoch 1465/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7274 - accuracy: 0.7088\n",
      "Epoch 1466/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7235 - accuracy: 0.7082\n",
      "Epoch 1467/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7202 - accuracy: 0.7124\n",
      "Epoch 1468/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7250 - accuracy: 0.7080\n",
      "Epoch 1469/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7256 - accuracy: 0.7095\n",
      "Epoch 1470/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7266 - accuracy: 0.7048\n",
      "Epoch 1471/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7217 - accuracy: 0.7080\n",
      "Epoch 1472/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7215 - accuracy: 0.7085\n",
      "Epoch 1473/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7228 - accuracy: 0.7099\n",
      "Epoch 1474/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7159 - accuracy: 0.7106\n",
      "Epoch 1475/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7237 - accuracy: 0.7042\n",
      "Epoch 1476/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7229 - accuracy: 0.7078\n",
      "Epoch 1477/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7206 - accuracy: 0.7127\n",
      "Epoch 1478/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7233 - accuracy: 0.7091\n",
      "Epoch 1479/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7149 - accuracy: 0.7115\n",
      "Epoch 1480/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7160 - accuracy: 0.7116\n",
      "Epoch 1481/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7149 - accuracy: 0.7163\n",
      "Epoch 1482/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7158 - accuracy: 0.7113\n",
      "Epoch 1483/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7201 - accuracy: 0.7104\n",
      "Epoch 1484/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7214 - accuracy: 0.7115\n",
      "Epoch 1485/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7193 - accuracy: 0.7091\n",
      "Epoch 1486/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7270 - accuracy: 0.7088\n",
      "Epoch 1487/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7151 - accuracy: 0.7083\n",
      "Epoch 1488/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7184 - accuracy: 0.7075\n",
      "Epoch 1489/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7198 - accuracy: 0.7082\n",
      "Epoch 1490/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7209 - accuracy: 0.7055\n",
      "Epoch 1491/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7188 - accuracy: 0.7124\n",
      "Epoch 1492/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7179 - accuracy: 0.7094\n",
      "Epoch 1493/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7165 - accuracy: 0.7120\n",
      "Epoch 1494/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7243 - accuracy: 0.7082\n",
      "Epoch 1495/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7248 - accuracy: 0.7067\n",
      "Epoch 1496/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7195 - accuracy: 0.7084\n",
      "Epoch 1497/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7133 - accuracy: 0.7158\n",
      "Epoch 1498/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7231 - accuracy: 0.7112\n",
      "Epoch 1499/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7083 - accuracy: 0.7144\n",
      "Epoch 1500/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7204 - accuracy: 0.7133\n",
      "Epoch 1501/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7207 - accuracy: 0.7100\n",
      "Epoch 1502/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7205 - accuracy: 0.7126\n",
      "Epoch 1503/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7193 - accuracy: 0.7094\n",
      "Epoch 1504/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7300 - accuracy: 0.7097\n",
      "Epoch 1505/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7269 - accuracy: 0.7096\n",
      "Epoch 1506/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7287 - accuracy: 0.7059\n",
      "Epoch 1507/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7195 - accuracy: 0.7096\n",
      "Epoch 1508/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7194 - accuracy: 0.7120\n",
      "Epoch 1509/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7223 - accuracy: 0.7093\n",
      "Epoch 1510/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7220 - accuracy: 0.7066\n",
      "Epoch 1511/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7159 - accuracy: 0.7148\n",
      "Epoch 1512/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7218 - accuracy: 0.7095\n",
      "Epoch 1513/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7213 - accuracy: 0.7084\n",
      "Epoch 1514/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7185 - accuracy: 0.7088\n",
      "Epoch 1515/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7162 - accuracy: 0.7126\n",
      "Epoch 1516/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7176 - accuracy: 0.7112\n",
      "Epoch 1517/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7249 - accuracy: 0.7086\n",
      "Epoch 1518/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7290 - accuracy: 0.7057\n",
      "Epoch 1519/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7104 - accuracy: 0.7146\n",
      "Epoch 1520/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7178 - accuracy: 0.7102\n",
      "Epoch 1521/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7202 - accuracy: 0.7121\n",
      "Epoch 1522/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7228 - accuracy: 0.7106\n",
      "Epoch 1523/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7246 - accuracy: 0.7078\n",
      "Epoch 1524/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7192 - accuracy: 0.7110\n",
      "Epoch 1525/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7216 - accuracy: 0.7119\n",
      "Epoch 1526/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7159 - accuracy: 0.7116\n",
      "Epoch 1527/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7173 - accuracy: 0.7078\n",
      "Epoch 1528/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7215 - accuracy: 0.7104\n",
      "Epoch 1529/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7178 - accuracy: 0.7083\n",
      "Epoch 1530/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7193 - accuracy: 0.7081\n",
      "Epoch 1531/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7137 - accuracy: 0.7149\n",
      "Epoch 1532/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7221 - accuracy: 0.7107\n",
      "Epoch 1533/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7229 - accuracy: 0.7043\n",
      "Epoch 1534/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7234 - accuracy: 0.7063\n",
      "Epoch 1535/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7190 - accuracy: 0.7100\n",
      "Epoch 1536/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7187 - accuracy: 0.7080\n",
      "Epoch 1537/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7174 - accuracy: 0.7095\n",
      "Epoch 1538/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7208 - accuracy: 0.7089\n",
      "Epoch 1539/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7155 - accuracy: 0.7069\n",
      "Epoch 1540/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7205 - accuracy: 0.7126\n",
      "Epoch 1541/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7176 - accuracy: 0.7106\n",
      "Epoch 1542/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7169 - accuracy: 0.7129\n",
      "Epoch 1543/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7209 - accuracy: 0.7094\n",
      "Epoch 1544/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7148 - accuracy: 0.7125\n",
      "Epoch 1545/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7203 - accuracy: 0.7119\n",
      "Epoch 1546/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7183 - accuracy: 0.7064\n",
      "Epoch 1547/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7157 - accuracy: 0.7096\n",
      "Epoch 1548/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7186 - accuracy: 0.7121\n",
      "Epoch 1549/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7208 - accuracy: 0.7118\n",
      "Epoch 1550/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7142 - accuracy: 0.7109\n",
      "Epoch 1551/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7142 - accuracy: 0.7133\n",
      "Epoch 1552/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7132 - accuracy: 0.7100\n",
      "Epoch 1553/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7180 - accuracy: 0.7100\n",
      "Epoch 1554/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7196 - accuracy: 0.7088\n",
      "Epoch 1555/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7153 - accuracy: 0.7121\n",
      "Epoch 1556/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7176 - accuracy: 0.7102\n",
      "Epoch 1557/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7173 - accuracy: 0.7083\n",
      "Epoch 1558/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7174 - accuracy: 0.7119\n",
      "Epoch 1559/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7158 - accuracy: 0.7126\n",
      "Epoch 1560/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7197 - accuracy: 0.7096\n",
      "Epoch 1561/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7209 - accuracy: 0.7098\n",
      "Epoch 1562/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7224 - accuracy: 0.7090\n",
      "Epoch 1563/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7195 - accuracy: 0.7077\n",
      "Epoch 1564/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7177 - accuracy: 0.7113\n",
      "Epoch 1565/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7126 - accuracy: 0.7133\n",
      "Epoch 1566/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7161 - accuracy: 0.7093\n",
      "Epoch 1567/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7216 - accuracy: 0.7101\n",
      "Epoch 1568/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7221 - accuracy: 0.7109\n",
      "Epoch 1569/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7118 - accuracy: 0.7132\n",
      "Epoch 1570/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7135 - accuracy: 0.7140\n",
      "Epoch 1571/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7178 - accuracy: 0.7100\n",
      "Epoch 1572/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7167 - accuracy: 0.7093\n",
      "Epoch 1573/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7224 - accuracy: 0.7115\n",
      "Epoch 1574/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7110 - accuracy: 0.7129\n",
      "Epoch 1575/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7250 - accuracy: 0.7098\n",
      "Epoch 1576/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7151 - accuracy: 0.7146\n",
      "Epoch 1577/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7143 - accuracy: 0.7107\n",
      "Epoch 1578/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7169 - accuracy: 0.7111\n",
      "Epoch 1579/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7142 - accuracy: 0.7132\n",
      "Epoch 1580/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7134 - accuracy: 0.7102\n",
      "Epoch 1581/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7202 - accuracy: 0.7127\n",
      "Epoch 1582/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7111 - accuracy: 0.7115\n",
      "Epoch 1583/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7142 - accuracy: 0.7116\n",
      "Epoch 1584/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7168 - accuracy: 0.7135\n",
      "Epoch 1585/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7187 - accuracy: 0.7122\n",
      "Epoch 1586/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7122 - accuracy: 0.7133\n",
      "Epoch 1587/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7189 - accuracy: 0.7106\n",
      "Epoch 1588/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7065 - accuracy: 0.7143\n",
      "Epoch 1589/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7166 - accuracy: 0.7129\n",
      "Epoch 1590/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7166 - accuracy: 0.7148\n",
      "Epoch 1591/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7188 - accuracy: 0.7121\n",
      "Epoch 1592/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7156 - accuracy: 0.7073\n",
      "Epoch 1593/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7135 - accuracy: 0.7097\n",
      "Epoch 1594/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7163 - accuracy: 0.7128\n",
      "Epoch 1595/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7197 - accuracy: 0.7095\n",
      "Epoch 1596/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7117 - accuracy: 0.7152\n",
      "Epoch 1597/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7091 - accuracy: 0.7176\n",
      "Epoch 1598/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7144 - accuracy: 0.7117\n",
      "Epoch 1599/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7193 - accuracy: 0.7097\n",
      "Epoch 1600/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7159 - accuracy: 0.7137\n",
      "Epoch 1601/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7139 - accuracy: 0.7133\n",
      "Epoch 1602/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7185 - accuracy: 0.7133\n",
      "Epoch 1603/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7157 - accuracy: 0.7103\n",
      "Epoch 1604/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7166 - accuracy: 0.7129\n",
      "Epoch 1605/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7114 - accuracy: 0.7131\n",
      "Epoch 1606/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7166 - accuracy: 0.7146\n",
      "Epoch 1607/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7135 - accuracy: 0.7107\n",
      "Epoch 1608/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7168 - accuracy: 0.7126\n",
      "Epoch 1609/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7129 - accuracy: 0.7126\n",
      "Epoch 1610/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7151 - accuracy: 0.7120\n",
      "Epoch 1611/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7182 - accuracy: 0.7105\n",
      "Epoch 1612/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7093 - accuracy: 0.7110\n",
      "Epoch 1613/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7114 - accuracy: 0.7150\n",
      "Epoch 1614/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7091 - accuracy: 0.7155\n",
      "Epoch 1615/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7197 - accuracy: 0.7087\n",
      "Epoch 1616/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7178 - accuracy: 0.7073\n",
      "Epoch 1617/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7134 - accuracy: 0.7135\n",
      "Epoch 1618/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7173 - accuracy: 0.7120\n",
      "Epoch 1619/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7107 - accuracy: 0.7137\n",
      "Epoch 1620/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7164 - accuracy: 0.7146\n",
      "Epoch 1621/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7161 - accuracy: 0.7119\n",
      "Epoch 1622/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7113 - accuracy: 0.7176\n",
      "Epoch 1623/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7206 - accuracy: 0.7147\n",
      "Epoch 1624/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7200 - accuracy: 0.7108\n",
      "Epoch 1625/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7116 - accuracy: 0.7134\n",
      "Epoch 1626/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7141 - accuracy: 0.7136\n",
      "Epoch 1627/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7111 - accuracy: 0.7162\n",
      "Epoch 1628/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7134 - accuracy: 0.7121\n",
      "Epoch 1629/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7086 - accuracy: 0.7140\n",
      "Epoch 1630/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7148 - accuracy: 0.7095\n",
      "Epoch 1631/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7094 - accuracy: 0.7128\n",
      "Epoch 1632/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7136 - accuracy: 0.7124\n",
      "Epoch 1633/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7125 - accuracy: 0.7099\n",
      "Epoch 1634/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7102 - accuracy: 0.7163\n",
      "Epoch 1635/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7190 - accuracy: 0.7106\n",
      "Epoch 1636/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7119 - accuracy: 0.7138\n",
      "Epoch 1637/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7111 - accuracy: 0.7116\n",
      "Epoch 1638/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7165 - accuracy: 0.7106\n",
      "Epoch 1639/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7126 - accuracy: 0.7146\n",
      "Epoch 1640/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7060 - accuracy: 0.7173\n",
      "Epoch 1641/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7208 - accuracy: 0.7103\n",
      "Epoch 1642/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7140 - accuracy: 0.7134\n",
      "Epoch 1643/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7172 - accuracy: 0.7120\n",
      "Epoch 1644/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7134 - accuracy: 0.7137\n",
      "Epoch 1645/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7119 - accuracy: 0.7114\n",
      "Epoch 1646/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7095 - accuracy: 0.7149\n",
      "Epoch 1647/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7116 - accuracy: 0.7126\n",
      "Epoch 1648/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7106 - accuracy: 0.7160\n",
      "Epoch 1649/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7123 - accuracy: 0.7126\n",
      "Epoch 1650/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7142 - accuracy: 0.7142\n",
      "Epoch 1651/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7082 - accuracy: 0.7159\n",
      "Epoch 1652/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7116 - accuracy: 0.7089\n",
      "Epoch 1653/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7101 - accuracy: 0.7142\n",
      "Epoch 1654/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7083 - accuracy: 0.7120\n",
      "Epoch 1655/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7153 - accuracy: 0.7142\n",
      "Epoch 1656/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7170 - accuracy: 0.7112\n",
      "Epoch 1657/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7106 - accuracy: 0.7131\n",
      "Epoch 1658/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7164 - accuracy: 0.7113\n",
      "Epoch 1659/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7155 - accuracy: 0.7107\n",
      "Epoch 1660/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7097 - accuracy: 0.7119\n",
      "Epoch 1661/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7086 - accuracy: 0.7178\n",
      "Epoch 1662/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7155 - accuracy: 0.7115\n",
      "Epoch 1663/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7119 - accuracy: 0.7133\n",
      "Epoch 1664/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7131 - accuracy: 0.7154\n",
      "Epoch 1665/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7085 - accuracy: 0.7170\n",
      "Epoch 1666/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7042 - accuracy: 0.7180\n",
      "Epoch 1667/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7125 - accuracy: 0.7110\n",
      "Epoch 1668/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7103 - accuracy: 0.7140\n",
      "Epoch 1669/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7131 - accuracy: 0.7141\n",
      "Epoch 1670/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7056 - accuracy: 0.7183\n",
      "Epoch 1671/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7061 - accuracy: 0.7161\n",
      "Epoch 1672/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7134 - accuracy: 0.7152\n",
      "Epoch 1673/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7172 - accuracy: 0.7137\n",
      "Epoch 1674/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7031 - accuracy: 0.7182\n",
      "Epoch 1675/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7114 - accuracy: 0.7135\n",
      "Epoch 1676/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7066 - accuracy: 0.7186\n",
      "Epoch 1677/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7102 - accuracy: 0.7148\n",
      "Epoch 1678/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7112 - accuracy: 0.7129\n",
      "Epoch 1679/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7054 - accuracy: 0.7146\n",
      "Epoch 1680/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7118 - accuracy: 0.7154\n",
      "Epoch 1681/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7131 - accuracy: 0.7128\n",
      "Epoch 1682/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7113 - accuracy: 0.7143\n",
      "Epoch 1683/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7097 - accuracy: 0.7151\n",
      "Epoch 1684/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7129 - accuracy: 0.7134\n",
      "Epoch 1685/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7146 - accuracy: 0.7165\n",
      "Epoch 1686/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7214 - accuracy: 0.7115\n",
      "Epoch 1687/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7140 - accuracy: 0.7148\n",
      "Epoch 1688/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7108 - accuracy: 0.7156\n",
      "Epoch 1689/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7191 - accuracy: 0.7125\n",
      "Epoch 1690/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7119 - accuracy: 0.7150\n",
      "Epoch 1691/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7038 - accuracy: 0.7170\n",
      "Epoch 1692/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7080 - accuracy: 0.7165\n",
      "Epoch 1693/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7085 - accuracy: 0.7178\n",
      "Epoch 1694/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7132 - accuracy: 0.7113\n",
      "Epoch 1695/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7095 - accuracy: 0.7143\n",
      "Epoch 1696/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7041 - accuracy: 0.7164\n",
      "Epoch 1697/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7058 - accuracy: 0.7174\n",
      "Epoch 1698/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7168 - accuracy: 0.7113\n",
      "Epoch 1699/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7244 - accuracy: 0.7087\n",
      "Epoch 1700/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7145 - accuracy: 0.7114\n",
      "Epoch 1701/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7115 - accuracy: 0.7090\n",
      "Epoch 1702/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7061 - accuracy: 0.7169\n",
      "Epoch 1703/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7111 - accuracy: 0.7136\n",
      "Epoch 1704/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7062 - accuracy: 0.7145\n",
      "Epoch 1705/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7146 - accuracy: 0.7116\n",
      "Epoch 1706/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7144 - accuracy: 0.7135\n",
      "Epoch 1707/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7095 - accuracy: 0.7168\n",
      "Epoch 1708/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7108 - accuracy: 0.7148\n",
      "Epoch 1709/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7086 - accuracy: 0.7178\n",
      "Epoch 1710/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7120 - accuracy: 0.7154\n",
      "Epoch 1711/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7054 - accuracy: 0.7174\n",
      "Epoch 1712/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7146 - accuracy: 0.7180\n",
      "Epoch 1713/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7145 - accuracy: 0.7109\n",
      "Epoch 1714/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7085 - accuracy: 0.7154\n",
      "Epoch 1715/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7023 - accuracy: 0.7186\n",
      "Epoch 1716/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7113 - accuracy: 0.7153\n",
      "Epoch 1717/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7106 - accuracy: 0.7124\n",
      "Epoch 1718/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7140 - accuracy: 0.7126\n",
      "Epoch 1719/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7133 - accuracy: 0.7137\n",
      "Epoch 1720/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7091 - accuracy: 0.7185\n",
      "Epoch 1721/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7100 - accuracy: 0.7147\n",
      "Epoch 1722/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7051 - accuracy: 0.7171\n",
      "Epoch 1723/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7074 - accuracy: 0.7172\n",
      "Epoch 1724/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7019 - accuracy: 0.7217\n",
      "Epoch 1725/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7067 - accuracy: 0.7128\n",
      "Epoch 1726/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7132 - accuracy: 0.7151\n",
      "Epoch 1727/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7124 - accuracy: 0.7115\n",
      "Epoch 1728/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7120 - accuracy: 0.7119\n",
      "Epoch 1729/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7073 - accuracy: 0.7152\n",
      "Epoch 1730/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7101 - accuracy: 0.7155\n",
      "Epoch 1731/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7104 - accuracy: 0.7126\n",
      "Epoch 1732/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7073 - accuracy: 0.7151\n",
      "Epoch 1733/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7107 - accuracy: 0.7156\n",
      "Epoch 1734/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7078 - accuracy: 0.7160\n",
      "Epoch 1735/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7056 - accuracy: 0.7190\n",
      "Epoch 1736/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7118 - accuracy: 0.7114\n",
      "Epoch 1737/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7125 - accuracy: 0.7131\n",
      "Epoch 1738/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7099 - accuracy: 0.7194\n",
      "Epoch 1739/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7043 - accuracy: 0.7178\n",
      "Epoch 1740/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7069 - accuracy: 0.7175\n",
      "Epoch 1741/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7137 - accuracy: 0.7150\n",
      "Epoch 1742/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7139 - accuracy: 0.7161\n",
      "Epoch 1743/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7146 - accuracy: 0.7106\n",
      "Epoch 1744/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7081 - accuracy: 0.7163\n",
      "Epoch 1745/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7086 - accuracy: 0.7163\n",
      "Epoch 1746/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7089 - accuracy: 0.7161\n",
      "Epoch 1747/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7074 - accuracy: 0.7142\n",
      "Epoch 1748/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7057 - accuracy: 0.7161\n",
      "Epoch 1749/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7070 - accuracy: 0.7133\n",
      "Epoch 1750/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7153 - accuracy: 0.7172\n",
      "Epoch 1751/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7052 - accuracy: 0.7204\n",
      "Epoch 1752/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7078 - accuracy: 0.7156\n",
      "Epoch 1753/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7101 - accuracy: 0.7182\n",
      "Epoch 1754/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7070 - accuracy: 0.7158\n",
      "Epoch 1755/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7158 - accuracy: 0.7110\n",
      "Epoch 1756/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7056 - accuracy: 0.7174\n",
      "Epoch 1757/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7065 - accuracy: 0.7170\n",
      "Epoch 1758/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7137 - accuracy: 0.7142\n",
      "Epoch 1759/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7083 - accuracy: 0.7139\n",
      "Epoch 1760/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7091 - accuracy: 0.7133\n",
      "Epoch 1761/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7055 - accuracy: 0.7176\n",
      "Epoch 1762/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7165 - accuracy: 0.7113\n",
      "Epoch 1763/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7089 - accuracy: 0.7132\n",
      "Epoch 1764/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7059 - accuracy: 0.7142\n",
      "Epoch 1765/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7127 - accuracy: 0.7154\n",
      "Epoch 1766/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7088 - accuracy: 0.7139\n",
      "Epoch 1767/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7092 - accuracy: 0.7171\n",
      "Epoch 1768/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7071 - accuracy: 0.7144\n",
      "Epoch 1769/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7115 - accuracy: 0.7164\n",
      "Epoch 1770/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7077 - accuracy: 0.7146\n",
      "Epoch 1771/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7141 - accuracy: 0.7089\n",
      "Epoch 1772/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7084 - accuracy: 0.7155\n",
      "Epoch 1773/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7044 - accuracy: 0.7161\n",
      "Epoch 1774/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7115 - accuracy: 0.7157\n",
      "Epoch 1775/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7104 - accuracy: 0.7134\n",
      "Epoch 1776/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7088 - accuracy: 0.7170\n",
      "Epoch 1777/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7087 - accuracy: 0.7182\n",
      "Epoch 1778/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7034 - accuracy: 0.7192\n",
      "Epoch 1779/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7062 - accuracy: 0.7173\n",
      "Epoch 1780/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7046 - accuracy: 0.7176\n",
      "Epoch 1781/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7042 - accuracy: 0.7181\n",
      "Epoch 1782/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7082 - accuracy: 0.7178\n",
      "Epoch 1783/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7052 - accuracy: 0.7145\n",
      "Epoch 1784/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7052 - accuracy: 0.7178\n",
      "Epoch 1785/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7056 - accuracy: 0.7161\n",
      "Epoch 1786/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7071 - accuracy: 0.7154\n",
      "Epoch 1787/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7056 - accuracy: 0.7161\n",
      "Epoch 1788/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7055 - accuracy: 0.7173\n",
      "Epoch 1789/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6990 - accuracy: 0.7191\n",
      "Epoch 1790/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7075 - accuracy: 0.7153\n",
      "Epoch 1791/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7035 - accuracy: 0.7220\n",
      "Epoch 1792/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6959 - accuracy: 0.7175\n",
      "Epoch 1793/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7029 - accuracy: 0.7204\n",
      "Epoch 1794/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7141 - accuracy: 0.7119\n",
      "Epoch 1795/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7058 - accuracy: 0.7157\n",
      "Epoch 1796/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7016 - accuracy: 0.7154\n",
      "Epoch 1797/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7076 - accuracy: 0.7186\n",
      "Epoch 1798/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7044 - accuracy: 0.7164\n",
      "Epoch 1799/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7017 - accuracy: 0.7201\n",
      "Epoch 1800/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7052 - accuracy: 0.7177\n",
      "Epoch 1801/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7014 - accuracy: 0.7183\n",
      "Epoch 1802/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6988 - accuracy: 0.7195\n",
      "Epoch 1803/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7093 - accuracy: 0.7127\n",
      "Epoch 1804/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7061 - accuracy: 0.7181\n",
      "Epoch 1805/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7037 - accuracy: 0.7154\n",
      "Epoch 1806/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7118 - accuracy: 0.7142\n",
      "Epoch 1807/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7066 - accuracy: 0.7155\n",
      "Epoch 1808/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7048 - accuracy: 0.7150\n",
      "Epoch 1809/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7091 - accuracy: 0.7162\n",
      "Epoch 1810/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7014 - accuracy: 0.7173\n",
      "Epoch 1811/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7052 - accuracy: 0.7170\n",
      "Epoch 1812/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7012 - accuracy: 0.7166\n",
      "Epoch 1813/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7045 - accuracy: 0.7173\n",
      "Epoch 1814/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7027 - accuracy: 0.7199\n",
      "Epoch 1815/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7039 - accuracy: 0.7195\n",
      "Epoch 1816/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7063 - accuracy: 0.7146\n",
      "Epoch 1817/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7073 - accuracy: 0.7155\n",
      "Epoch 1818/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7072 - accuracy: 0.7145\n",
      "Epoch 1819/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7078 - accuracy: 0.7144\n",
      "Epoch 1820/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7047 - accuracy: 0.7179\n",
      "Epoch 1821/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7085 - accuracy: 0.7140\n",
      "Epoch 1822/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7088 - accuracy: 0.7140\n",
      "Epoch 1823/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7000 - accuracy: 0.7184\n",
      "Epoch 1824/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7084 - accuracy: 0.7163\n",
      "Epoch 1825/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6970 - accuracy: 0.7200\n",
      "Epoch 1826/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7092 - accuracy: 0.7145\n",
      "Epoch 1827/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7042 - accuracy: 0.7166\n",
      "Epoch 1828/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7026 - accuracy: 0.7167\n",
      "Epoch 1829/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7072 - accuracy: 0.7121\n",
      "Epoch 1830/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7051 - accuracy: 0.7168\n",
      "Epoch 1831/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7121 - accuracy: 0.7138\n",
      "Epoch 1832/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6996 - accuracy: 0.7171\n",
      "Epoch 1833/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6985 - accuracy: 0.7184\n",
      "Epoch 1834/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7096 - accuracy: 0.7174\n",
      "Epoch 1835/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7066 - accuracy: 0.7178\n",
      "Epoch 1836/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7031 - accuracy: 0.7178\n",
      "Epoch 1837/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7030 - accuracy: 0.7199\n",
      "Epoch 1838/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7050 - accuracy: 0.7174\n",
      "Epoch 1839/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7077 - accuracy: 0.7150\n",
      "Epoch 1840/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6997 - accuracy: 0.7194\n",
      "Epoch 1841/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.7185\n",
      "Epoch 1842/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7000 - accuracy: 0.7197\n",
      "Epoch 1843/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7073 - accuracy: 0.7191\n",
      "Epoch 1844/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7032 - accuracy: 0.7164\n",
      "Epoch 1845/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7045 - accuracy: 0.7170\n",
      "Epoch 1846/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7063 - accuracy: 0.7178\n",
      "Epoch 1847/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7070 - accuracy: 0.7168\n",
      "Epoch 1848/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7012 - accuracy: 0.7202\n",
      "Epoch 1849/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7033 - accuracy: 0.7169\n",
      "Epoch 1850/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7059 - accuracy: 0.7189\n",
      "Epoch 1851/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7064 - accuracy: 0.7186\n",
      "Epoch 1852/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7058 - accuracy: 0.7151\n",
      "Epoch 1853/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7079 - accuracy: 0.7164\n",
      "Epoch 1854/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7037 - accuracy: 0.7189\n",
      "Epoch 1855/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7040 - accuracy: 0.7151\n",
      "Epoch 1856/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7026 - accuracy: 0.7178\n",
      "Epoch 1857/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7021 - accuracy: 0.7160\n",
      "Epoch 1858/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7063 - accuracy: 0.7178\n",
      "Epoch 1859/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7008 - accuracy: 0.7197\n",
      "Epoch 1860/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7040 - accuracy: 0.7169\n",
      "Epoch 1861/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7055 - accuracy: 0.7190\n",
      "Epoch 1862/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7046 - accuracy: 0.7170\n",
      "Epoch 1863/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7020 - accuracy: 0.7178\n",
      "Epoch 1864/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7051 - accuracy: 0.7171\n",
      "Epoch 1865/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7050 - accuracy: 0.7160\n",
      "Epoch 1866/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7027 - accuracy: 0.7160\n",
      "Epoch 1867/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7012 - accuracy: 0.7182\n",
      "Epoch 1868/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7000 - accuracy: 0.7216\n",
      "Epoch 1869/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7022 - accuracy: 0.7173\n",
      "Epoch 1870/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7031 - accuracy: 0.7190\n",
      "Epoch 1871/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6981 - accuracy: 0.7179\n",
      "Epoch 1872/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.7157\n",
      "Epoch 1873/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6967 - accuracy: 0.7196\n",
      "Epoch 1874/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7032 - accuracy: 0.7163\n",
      "Epoch 1875/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6987 - accuracy: 0.7200\n",
      "Epoch 1876/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7021 - accuracy: 0.7168\n",
      "Epoch 1877/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7009 - accuracy: 0.7187\n",
      "Epoch 1878/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7080 - accuracy: 0.7183\n",
      "Epoch 1879/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6989 - accuracy: 0.7193\n",
      "Epoch 1880/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7060 - accuracy: 0.7173\n",
      "Epoch 1881/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7035 - accuracy: 0.7203\n",
      "Epoch 1882/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7069 - accuracy: 0.7167\n",
      "Epoch 1883/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7073 - accuracy: 0.7166\n",
      "Epoch 1884/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7047 - accuracy: 0.7178\n",
      "Epoch 1885/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7018 - accuracy: 0.7213\n",
      "Epoch 1886/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7078 - accuracy: 0.7136\n",
      "Epoch 1887/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6981 - accuracy: 0.7191\n",
      "Epoch 1888/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6994 - accuracy: 0.7191\n",
      "Epoch 1889/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7094 - accuracy: 0.7151\n",
      "Epoch 1890/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7066 - accuracy: 0.7185\n",
      "Epoch 1891/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7043 - accuracy: 0.7166\n",
      "Epoch 1892/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6998 - accuracy: 0.7222\n",
      "Epoch 1893/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7001 - accuracy: 0.7165\n",
      "Epoch 1894/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7055 - accuracy: 0.7167\n",
      "Epoch 1895/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7036 - accuracy: 0.7174\n",
      "Epoch 1896/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6997 - accuracy: 0.7189\n",
      "Epoch 1897/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6990 - accuracy: 0.7215\n",
      "Epoch 1898/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7073 - accuracy: 0.7171\n",
      "Epoch 1899/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7019 - accuracy: 0.7215\n",
      "Epoch 1900/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7039 - accuracy: 0.7170\n",
      "Epoch 1901/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7028 - accuracy: 0.7132\n",
      "Epoch 1902/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6993 - accuracy: 0.7210\n",
      "Epoch 1903/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7041 - accuracy: 0.7189\n",
      "Epoch 1904/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6964 - accuracy: 0.7228\n",
      "Epoch 1905/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7051 - accuracy: 0.7186\n",
      "Epoch 1906/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7003 - accuracy: 0.7206\n",
      "Epoch 1907/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7031 - accuracy: 0.7193\n",
      "Epoch 1908/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7033 - accuracy: 0.7191\n",
      "Epoch 1909/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7022 - accuracy: 0.7196\n",
      "Epoch 1910/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7033 - accuracy: 0.7163\n",
      "Epoch 1911/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7013 - accuracy: 0.7172\n",
      "Epoch 1912/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6989 - accuracy: 0.7209\n",
      "Epoch 1913/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7024 - accuracy: 0.7177\n",
      "Epoch 1914/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7057 - accuracy: 0.7169\n",
      "Epoch 1915/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7027 - accuracy: 0.7169\n",
      "Epoch 1916/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6992 - accuracy: 0.7196\n",
      "Epoch 1917/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.7153\n",
      "Epoch 1918/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7038 - accuracy: 0.7167\n",
      "Epoch 1919/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7038 - accuracy: 0.7161\n",
      "Epoch 1920/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7007 - accuracy: 0.7174\n",
      "Epoch 1921/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7009 - accuracy: 0.7173\n",
      "Epoch 1922/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7019 - accuracy: 0.7168\n",
      "Epoch 1923/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7015 - accuracy: 0.7217\n",
      "Epoch 1924/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6977 - accuracy: 0.7166\n",
      "Epoch 1925/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7010 - accuracy: 0.7180\n",
      "Epoch 1926/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7004 - accuracy: 0.7169\n",
      "Epoch 1927/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7004 - accuracy: 0.7171\n",
      "Epoch 1928/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7091 - accuracy: 0.7167\n",
      "Epoch 1929/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7006 - accuracy: 0.7217\n",
      "Epoch 1930/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6952 - accuracy: 0.7153\n",
      "Epoch 1931/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7018 - accuracy: 0.7190\n",
      "Epoch 1932/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7013 - accuracy: 0.7171\n",
      "Epoch 1933/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6978 - accuracy: 0.7180\n",
      "Epoch 1934/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7018 - accuracy: 0.7183\n",
      "Epoch 1935/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7023 - accuracy: 0.7210\n",
      "Epoch 1936/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6976 - accuracy: 0.7188\n",
      "Epoch 1937/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7009 - accuracy: 0.7165\n",
      "Epoch 1938/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6979 - accuracy: 0.7198\n",
      "Epoch 1939/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7018 - accuracy: 0.7146\n",
      "Epoch 1940/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6995 - accuracy: 0.7214\n",
      "Epoch 1941/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7032 - accuracy: 0.7160\n",
      "Epoch 1942/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7006 - accuracy: 0.7217\n",
      "Epoch 1943/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7048 - accuracy: 0.7149\n",
      "Epoch 1944/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7022 - accuracy: 0.7205\n",
      "Epoch 1945/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7002 - accuracy: 0.7155\n",
      "Epoch 1946/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6981 - accuracy: 0.7211\n",
      "Epoch 1947/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6964 - accuracy: 0.7214\n",
      "Epoch 1948/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7013 - accuracy: 0.7167\n",
      "Epoch 1949/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7004 - accuracy: 0.7201\n",
      "Epoch 1950/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7079 - accuracy: 0.7157\n",
      "Epoch 1951/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.7174\n",
      "Epoch 1952/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7007 - accuracy: 0.7202\n",
      "Epoch 1953/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7016 - accuracy: 0.7202\n",
      "Epoch 1954/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6996 - accuracy: 0.7169\n",
      "Epoch 1955/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.7204\n",
      "Epoch 1956/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7017 - accuracy: 0.7174\n",
      "Epoch 1957/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6983 - accuracy: 0.7240\n",
      "Epoch 1958/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7001 - accuracy: 0.7199\n",
      "Epoch 1959/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7021 - accuracy: 0.7202\n",
      "Epoch 1960/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6984 - accuracy: 0.7174\n",
      "Epoch 1961/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6945 - accuracy: 0.7218\n",
      "Epoch 1962/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7001 - accuracy: 0.7165\n",
      "Epoch 1963/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6979 - accuracy: 0.7192\n",
      "Epoch 1964/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7008 - accuracy: 0.7195\n",
      "Epoch 1965/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6990 - accuracy: 0.7201\n",
      "Epoch 1966/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.7199\n",
      "Epoch 1967/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7027 - accuracy: 0.7177\n",
      "Epoch 1968/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.7204\n",
      "Epoch 1969/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7016 - accuracy: 0.7202\n",
      "Epoch 1970/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6926 - accuracy: 0.7222\n",
      "Epoch 1971/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7004 - accuracy: 0.7157\n",
      "Epoch 1972/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6964 - accuracy: 0.7171\n",
      "Epoch 1973/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6972 - accuracy: 0.7201\n",
      "Epoch 1974/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6994 - accuracy: 0.7196\n",
      "Epoch 1975/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6926 - accuracy: 0.7214\n",
      "Epoch 1976/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7014 - accuracy: 0.7197\n",
      "Epoch 1977/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7007 - accuracy: 0.7189\n",
      "Epoch 1978/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6990 - accuracy: 0.7169\n",
      "Epoch 1979/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6987 - accuracy: 0.7203\n",
      "Epoch 1980/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7045 - accuracy: 0.7176\n",
      "Epoch 1981/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6973 - accuracy: 0.7215\n",
      "Epoch 1982/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6948 - accuracy: 0.7211\n",
      "Epoch 1983/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6966 - accuracy: 0.7199\n",
      "Epoch 1984/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7138 - accuracy: 0.7119\n",
      "Epoch 1985/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6954 - accuracy: 0.7198\n",
      "Epoch 1986/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6949 - accuracy: 0.7186\n",
      "Epoch 1987/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6938 - accuracy: 0.7208\n",
      "Epoch 1988/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6977 - accuracy: 0.7208\n",
      "Epoch 1989/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7012 - accuracy: 0.7189\n",
      "Epoch 1990/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6968 - accuracy: 0.7217\n",
      "Epoch 1991/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.7204\n",
      "Epoch 1992/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6993 - accuracy: 0.7207\n",
      "Epoch 1993/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6974 - accuracy: 0.7179\n",
      "Epoch 1994/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.7223\n",
      "Epoch 1995/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.7222\n",
      "Epoch 1996/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6984 - accuracy: 0.7210\n",
      "Epoch 1997/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6957 - accuracy: 0.7204\n",
      "Epoch 1998/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7009 - accuracy: 0.7161\n",
      "Epoch 1999/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6968 - accuracy: 0.7178\n",
      "Epoch 2000/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6876 - accuracy: 0.7221\n",
      "Epoch 2001/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6976 - accuracy: 0.7174\n",
      "Epoch 2002/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6981 - accuracy: 0.7206\n",
      "Epoch 2003/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6912 - accuracy: 0.7226\n",
      "Epoch 2004/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6977 - accuracy: 0.7213\n",
      "Epoch 2005/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6993 - accuracy: 0.7187\n",
      "Epoch 2006/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.7216\n",
      "Epoch 2007/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.7241\n",
      "Epoch 2008/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7017 - accuracy: 0.7190\n",
      "Epoch 2009/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6946 - accuracy: 0.7196\n",
      "Epoch 2010/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.7170\n",
      "Epoch 2011/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7004 - accuracy: 0.7170\n",
      "Epoch 2012/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.7196\n",
      "Epoch 2013/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6965 - accuracy: 0.7215\n",
      "Epoch 2014/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7002 - accuracy: 0.7179\n",
      "Epoch 2015/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6968 - accuracy: 0.7161\n",
      "Epoch 2016/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6984 - accuracy: 0.7197\n",
      "Epoch 2017/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6981 - accuracy: 0.7216\n",
      "Epoch 2018/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6876 - accuracy: 0.7232\n",
      "Epoch 2019/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6998 - accuracy: 0.7171\n",
      "Epoch 2020/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.7223\n",
      "Epoch 2021/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7055 - accuracy: 0.7173\n",
      "Epoch 2022/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7043 - accuracy: 0.7154\n",
      "Epoch 2023/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.7203\n",
      "Epoch 2024/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7029 - accuracy: 0.7149\n",
      "Epoch 2025/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6976 - accuracy: 0.7164\n",
      "Epoch 2026/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7003 - accuracy: 0.7209\n",
      "Epoch 2027/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6982 - accuracy: 0.7186\n",
      "Epoch 2028/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7032 - accuracy: 0.7157\n",
      "Epoch 2029/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.7237\n",
      "Epoch 2030/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.7223\n",
      "Epoch 2031/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6916 - accuracy: 0.7259\n",
      "Epoch 2032/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6906 - accuracy: 0.7191\n",
      "Epoch 2033/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6994 - accuracy: 0.7197\n",
      "Epoch 2034/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6970 - accuracy: 0.7201\n",
      "Epoch 2035/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6983 - accuracy: 0.7228\n",
      "Epoch 2036/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7022 - accuracy: 0.7142\n",
      "Epoch 2037/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6953 - accuracy: 0.7206\n",
      "Epoch 2038/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7026 - accuracy: 0.7195\n",
      "Epoch 2039/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6985 - accuracy: 0.7177\n",
      "Epoch 2040/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.7197\n",
      "Epoch 2041/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6979 - accuracy: 0.7199\n",
      "Epoch 2042/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6875 - accuracy: 0.7263\n",
      "Epoch 2043/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.7210\n",
      "Epoch 2044/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.7251\n",
      "Epoch 2045/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.7206\n",
      "Epoch 2046/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6955 - accuracy: 0.7198\n",
      "Epoch 2047/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.7198\n",
      "Epoch 2048/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6986 - accuracy: 0.7197\n",
      "Epoch 2049/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6958 - accuracy: 0.7174\n",
      "Epoch 2050/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6968 - accuracy: 0.7179\n",
      "Epoch 2051/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6964 - accuracy: 0.7185\n",
      "Epoch 2052/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6952 - accuracy: 0.7197\n",
      "Epoch 2053/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.7188\n",
      "Epoch 2054/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7009 - accuracy: 0.7200\n",
      "Epoch 2055/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.7201\n",
      "Epoch 2056/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6967 - accuracy: 0.7227\n",
      "Epoch 2057/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6945 - accuracy: 0.7225\n",
      "Epoch 2058/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.7005 - accuracy: 0.7184\n",
      "Epoch 2059/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6953 - accuracy: 0.7179\n",
      "Epoch 2060/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.7236\n",
      "Epoch 2061/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6909 - accuracy: 0.7223\n",
      "Epoch 2062/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6954 - accuracy: 0.7210\n",
      "Epoch 2063/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6984 - accuracy: 0.7201\n",
      "Epoch 2064/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6960 - accuracy: 0.7214\n",
      "Epoch 2065/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.7212\n",
      "Epoch 2066/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6976 - accuracy: 0.7180\n",
      "Epoch 2067/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6939 - accuracy: 0.7223\n",
      "Epoch 2068/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6920 - accuracy: 0.7217\n",
      "Epoch 2069/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7031 - accuracy: 0.7173\n",
      "Epoch 2070/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6984 - accuracy: 0.7203\n",
      "Epoch 2071/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6982 - accuracy: 0.7215\n",
      "Epoch 2072/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.7224\n",
      "Epoch 2073/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.7223\n",
      "Epoch 2074/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6970 - accuracy: 0.7204\n",
      "Epoch 2075/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6893 - accuracy: 0.7228\n",
      "Epoch 2076/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6976 - accuracy: 0.7233\n",
      "Epoch 2077/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6958 - accuracy: 0.7166\n",
      "Epoch 2078/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6972 - accuracy: 0.7191\n",
      "Epoch 2079/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.7227\n",
      "Epoch 2080/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.7201\n",
      "Epoch 2081/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6906 - accuracy: 0.7242\n",
      "Epoch 2082/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6969 - accuracy: 0.7206\n",
      "Epoch 2083/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.7241\n",
      "Epoch 2084/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6939 - accuracy: 0.7223\n",
      "Epoch 2085/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.7230\n",
      "Epoch 2086/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.7227\n",
      "Epoch 2087/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6939 - accuracy: 0.7209\n",
      "Epoch 2088/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6958 - accuracy: 0.7218\n",
      "Epoch 2089/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7006 - accuracy: 0.7167\n",
      "Epoch 2090/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.7241\n",
      "Epoch 2091/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.7230\n",
      "Epoch 2092/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.7230\n",
      "Epoch 2093/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.7230\n",
      "Epoch 2094/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.7252\n",
      "Epoch 2095/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.7243\n",
      "Epoch 2096/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6946 - accuracy: 0.7231\n",
      "Epoch 2097/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6956 - accuracy: 0.7211\n",
      "Epoch 2098/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6946 - accuracy: 0.7212\n",
      "Epoch 2099/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7012 - accuracy: 0.7198\n",
      "Epoch 2100/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.7237\n",
      "Epoch 2101/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6928 - accuracy: 0.7242\n",
      "Epoch 2102/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.7254\n",
      "Epoch 2103/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6969 - accuracy: 0.7201\n",
      "Epoch 2104/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7006 - accuracy: 0.7223\n",
      "Epoch 2105/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6982 - accuracy: 0.7169\n",
      "Epoch 2106/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.7228\n",
      "Epoch 2107/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6913 - accuracy: 0.7249\n",
      "Epoch 2108/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6888 - accuracy: 0.7247\n",
      "Epoch 2109/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.7217\n",
      "Epoch 2110/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6907 - accuracy: 0.7217\n",
      "Epoch 2111/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6906 - accuracy: 0.7227\n",
      "Epoch 2112/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6970 - accuracy: 0.7179\n",
      "Epoch 2113/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6928 - accuracy: 0.7221\n",
      "Epoch 2114/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6954 - accuracy: 0.7238\n",
      "Epoch 2115/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6957 - accuracy: 0.7202\n",
      "Epoch 2116/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.7202\n",
      "Epoch 2117/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.7208\n",
      "Epoch 2118/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6957 - accuracy: 0.7226\n",
      "Epoch 2119/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.7231\n",
      "Epoch 2120/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.7240\n",
      "Epoch 2121/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7009 - accuracy: 0.7185\n",
      "Epoch 2122/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.7238\n",
      "Epoch 2123/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6938 - accuracy: 0.7214\n",
      "Epoch 2124/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6974 - accuracy: 0.7210\n",
      "Epoch 2125/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.7238\n",
      "Epoch 2126/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.7228\n",
      "Epoch 2127/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6924 - accuracy: 0.7217\n",
      "Epoch 2128/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6955 - accuracy: 0.7221\n",
      "Epoch 2129/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6942 - accuracy: 0.7182\n",
      "Epoch 2130/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.7218\n",
      "Epoch 2131/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6911 - accuracy: 0.7224\n",
      "Epoch 2132/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.7236\n",
      "Epoch 2133/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6862 - accuracy: 0.7235\n",
      "Epoch 2134/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.7240\n",
      "Epoch 2135/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6895 - accuracy: 0.7211\n",
      "Epoch 2136/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6926 - accuracy: 0.7209\n",
      "Epoch 2137/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.7238\n",
      "Epoch 2138/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.7240\n",
      "Epoch 2139/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.7216\n",
      "Epoch 2140/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.7218\n",
      "Epoch 2141/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6892 - accuracy: 0.7258\n",
      "Epoch 2142/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.7201\n",
      "Epoch 2143/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6872 - accuracy: 0.7261\n",
      "Epoch 2144/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6896 - accuracy: 0.7238\n",
      "Epoch 2145/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6840 - accuracy: 0.7258\n",
      "Epoch 2146/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.7215\n",
      "Epoch 2147/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.7197\n",
      "Epoch 2148/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7005 - accuracy: 0.7186\n",
      "Epoch 2149/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.7268\n",
      "Epoch 2150/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6848 - accuracy: 0.7218\n",
      "Epoch 2151/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6964 - accuracy: 0.7205\n",
      "Epoch 2152/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.7234\n",
      "Epoch 2153/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6969 - accuracy: 0.7166\n",
      "Epoch 2154/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.7244\n",
      "Epoch 2155/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6848 - accuracy: 0.7266\n",
      "Epoch 2156/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6879 - accuracy: 0.7219\n",
      "Epoch 2157/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6910 - accuracy: 0.7241\n",
      "Epoch 2158/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6842 - accuracy: 0.7241\n",
      "Epoch 2159/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.7257\n",
      "Epoch 2160/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.7225\n",
      "Epoch 2161/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.7201\n",
      "Epoch 2162/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6822 - accuracy: 0.7263\n",
      "Epoch 2163/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6942 - accuracy: 0.7236\n",
      "Epoch 2164/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6907 - accuracy: 0.7213\n",
      "Epoch 2165/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6891 - accuracy: 0.7260\n",
      "Epoch 2166/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6958 - accuracy: 0.7231\n",
      "Epoch 2167/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6909 - accuracy: 0.7218\n",
      "Epoch 2168/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6985 - accuracy: 0.7190\n",
      "Epoch 2169/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6885 - accuracy: 0.7250\n",
      "Epoch 2170/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6965 - accuracy: 0.7206\n",
      "Epoch 2171/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6885 - accuracy: 0.7262\n",
      "Epoch 2172/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6876 - accuracy: 0.7296\n",
      "Epoch 2173/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6978 - accuracy: 0.7219\n",
      "Epoch 2174/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6943 - accuracy: 0.7214\n",
      "Epoch 2175/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6914 - accuracy: 0.7249\n",
      "Epoch 2176/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6924 - accuracy: 0.7222\n",
      "Epoch 2177/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.7237\n",
      "Epoch 2178/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6996 - accuracy: 0.7188\n",
      "Epoch 2179/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7014 - accuracy: 0.7194\n",
      "Epoch 2180/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6852 - accuracy: 0.7295\n",
      "Epoch 2181/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6893 - accuracy: 0.7222\n",
      "Epoch 2182/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.7222\n",
      "Epoch 2183/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6993 - accuracy: 0.7161\n",
      "Epoch 2184/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6976 - accuracy: 0.7214\n",
      "Epoch 2185/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6886 - accuracy: 0.7235\n",
      "Epoch 2186/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6894 - accuracy: 0.7222\n",
      "Epoch 2187/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.7262\n",
      "Epoch 2188/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.7252\n",
      "Epoch 2189/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.7214\n",
      "Epoch 2190/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6911 - accuracy: 0.7248\n",
      "Epoch 2191/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6911 - accuracy: 0.7246\n",
      "Epoch 2192/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6922 - accuracy: 0.7214\n",
      "Epoch 2193/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6969 - accuracy: 0.7190\n",
      "Epoch 2194/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.7211\n",
      "Epoch 2195/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6893 - accuracy: 0.7213\n",
      "Epoch 2196/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6913 - accuracy: 0.7229\n",
      "Epoch 2197/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6962 - accuracy: 0.7213\n",
      "Epoch 2198/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6914 - accuracy: 0.7230\n",
      "Epoch 2199/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6877 - accuracy: 0.7223\n",
      "Epoch 2200/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.7244\n",
      "Epoch 2201/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6938 - accuracy: 0.7244\n",
      "Epoch 2202/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6920 - accuracy: 0.7236\n",
      "Epoch 2203/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.7241\n",
      "Epoch 2204/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6965 - accuracy: 0.7199\n",
      "Epoch 2205/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.7267\n",
      "Epoch 2206/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.7215\n",
      "Epoch 2207/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6969 - accuracy: 0.7210\n",
      "Epoch 2208/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6945 - accuracy: 0.7233\n",
      "Epoch 2209/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.7240\n",
      "Epoch 2210/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6875 - accuracy: 0.7258\n",
      "Epoch 2211/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6874 - accuracy: 0.7231\n",
      "Epoch 2212/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6877 - accuracy: 0.7258\n",
      "Epoch 2213/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.7219\n",
      "Epoch 2214/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6898 - accuracy: 0.7249\n",
      "Epoch 2215/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6861 - accuracy: 0.7200\n",
      "Epoch 2216/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6895 - accuracy: 0.7221\n",
      "Epoch 2217/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6813 - accuracy: 0.7293\n",
      "Epoch 2218/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6874 - accuracy: 0.7222\n",
      "Epoch 2219/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6981 - accuracy: 0.7185\n",
      "Epoch 2220/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6951 - accuracy: 0.7195\n",
      "Epoch 2221/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6857 - accuracy: 0.7253\n",
      "Epoch 2222/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6914 - accuracy: 0.7227\n",
      "Epoch 2223/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.7223\n",
      "Epoch 2224/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6840 - accuracy: 0.7225\n",
      "Epoch 2225/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6886 - accuracy: 0.7247\n",
      "Epoch 2226/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.7234\n",
      "Epoch 2227/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6824 - accuracy: 0.7248\n",
      "Epoch 2228/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6897 - accuracy: 0.7237\n",
      "Epoch 2229/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6894 - accuracy: 0.7246\n",
      "Epoch 2230/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6857 - accuracy: 0.7232\n",
      "Epoch 2231/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6946 - accuracy: 0.7212\n",
      "Epoch 2232/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6876 - accuracy: 0.7234\n",
      "Epoch 2233/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6916 - accuracy: 0.7214\n",
      "Epoch 2234/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6914 - accuracy: 0.7209\n",
      "Epoch 2235/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.7218\n",
      "Epoch 2236/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6911 - accuracy: 0.7246\n",
      "Epoch 2237/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6955 - accuracy: 0.7205\n",
      "Epoch 2238/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6820 - accuracy: 0.7245\n",
      "Epoch 2239/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6832 - accuracy: 0.7284\n",
      "Epoch 2240/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6841 - accuracy: 0.7258\n",
      "Epoch 2241/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.7236\n",
      "Epoch 2242/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.7217\n",
      "Epoch 2243/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.7253\n",
      "Epoch 2244/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6922 - accuracy: 0.7197\n",
      "Epoch 2245/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.7230\n",
      "Epoch 2246/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6891 - accuracy: 0.7229\n",
      "Epoch 2247/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6865 - accuracy: 0.7268\n",
      "Epoch 2248/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6863 - accuracy: 0.7239\n",
      "Epoch 2249/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6882 - accuracy: 0.7257\n",
      "Epoch 2250/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6893 - accuracy: 0.7250\n",
      "Epoch 2251/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6915 - accuracy: 0.7249\n",
      "Epoch 2252/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6836 - accuracy: 0.7226\n",
      "Epoch 2253/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.7235\n",
      "Epoch 2254/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.7240\n",
      "Epoch 2255/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6909 - accuracy: 0.7229\n",
      "Epoch 2256/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6856 - accuracy: 0.7249\n",
      "Epoch 2257/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.7001 - accuracy: 0.7165\n",
      "Epoch 2258/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6818 - accuracy: 0.7263\n",
      "Epoch 2259/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.7278\n",
      "Epoch 2260/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6901 - accuracy: 0.7215\n",
      "Epoch 2261/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6825 - accuracy: 0.7252\n",
      "Epoch 2262/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6861 - accuracy: 0.7259\n",
      "Epoch 2263/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.7192\n",
      "Epoch 2264/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.7259\n",
      "Epoch 2265/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6854 - accuracy: 0.7255\n",
      "Epoch 2266/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6899 - accuracy: 0.7254\n",
      "Epoch 2267/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6867 - accuracy: 0.7247\n",
      "Epoch 2268/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6856 - accuracy: 0.7241\n",
      "Epoch 2269/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6897 - accuracy: 0.7243\n",
      "Epoch 2270/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.7220\n",
      "Epoch 2271/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6859 - accuracy: 0.7261\n",
      "Epoch 2272/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6846 - accuracy: 0.7283\n",
      "Epoch 2273/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6871 - accuracy: 0.7248\n",
      "Epoch 2274/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6926 - accuracy: 0.7257\n",
      "Epoch 2275/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.7211\n",
      "Epoch 2276/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.7244\n",
      "Epoch 2277/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6832 - accuracy: 0.7260\n",
      "Epoch 2278/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6867 - accuracy: 0.7223\n",
      "Epoch 2279/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6899 - accuracy: 0.7233\n",
      "Epoch 2280/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6874 - accuracy: 0.7258\n",
      "Epoch 2281/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.7234\n",
      "Epoch 2282/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.7222\n",
      "Epoch 2283/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6870 - accuracy: 0.7262\n",
      "Epoch 2284/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6874 - accuracy: 0.7234\n",
      "Epoch 2285/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6885 - accuracy: 0.7221\n",
      "Epoch 2286/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.7208\n",
      "Epoch 2287/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6823 - accuracy: 0.7274\n",
      "Epoch 2288/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6971 - accuracy: 0.7226\n",
      "Epoch 2289/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6891 - accuracy: 0.7244\n",
      "Epoch 2290/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.7229\n",
      "Epoch 2291/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6904 - accuracy: 0.7268\n",
      "Epoch 2292/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.7236\n",
      "Epoch 2293/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6854 - accuracy: 0.7268\n",
      "Epoch 2294/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.7237\n",
      "Epoch 2295/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6850 - accuracy: 0.7273\n",
      "Epoch 2296/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6903 - accuracy: 0.7215\n",
      "Epoch 2297/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6891 - accuracy: 0.7231\n",
      "Epoch 2298/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6883 - accuracy: 0.7234\n",
      "Epoch 2299/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6914 - accuracy: 0.7222\n",
      "Epoch 2300/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.7235\n",
      "Epoch 2301/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6838 - accuracy: 0.7278\n",
      "Epoch 2302/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6850 - accuracy: 0.7244\n",
      "Epoch 2303/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6899 - accuracy: 0.7210\n",
      "Epoch 2304/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6840 - accuracy: 0.7262\n",
      "Epoch 2305/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6888 - accuracy: 0.7234\n",
      "Epoch 2306/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6892 - accuracy: 0.7238\n",
      "Epoch 2307/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6799 - accuracy: 0.7299\n",
      "Epoch 2308/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6816 - accuracy: 0.7251\n",
      "Epoch 2309/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6870 - accuracy: 0.7265\n",
      "Epoch 2310/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6907 - accuracy: 0.7223\n",
      "Epoch 2311/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6849 - accuracy: 0.7262\n",
      "Epoch 2312/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6871 - accuracy: 0.7267\n",
      "Epoch 2313/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.7228\n",
      "Epoch 2314/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6920 - accuracy: 0.7225\n",
      "Epoch 2315/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6894 - accuracy: 0.7210\n",
      "Epoch 2316/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6893 - accuracy: 0.7233\n",
      "Epoch 2317/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6830 - accuracy: 0.7276\n",
      "Epoch 2318/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6845 - accuracy: 0.7253\n",
      "Epoch 2319/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6888 - accuracy: 0.7248\n",
      "Epoch 2320/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7256\n",
      "Epoch 2321/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6868 - accuracy: 0.7246\n",
      "Epoch 2322/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6837 - accuracy: 0.7278\n",
      "Epoch 2323/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6823 - accuracy: 0.7264\n",
      "Epoch 2324/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6859 - accuracy: 0.7262\n",
      "Epoch 2325/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6780 - accuracy: 0.7267\n",
      "Epoch 2326/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6850 - accuracy: 0.7223\n",
      "Epoch 2327/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6851 - accuracy: 0.7281\n",
      "Epoch 2328/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7262\n",
      "Epoch 2329/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6820 - accuracy: 0.7287\n",
      "Epoch 2330/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.7264\n",
      "Epoch 2331/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6825 - accuracy: 0.7253\n",
      "Epoch 2332/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.7225\n",
      "Epoch 2333/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.7225\n",
      "Epoch 2334/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6835 - accuracy: 0.7273\n",
      "Epoch 2335/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6863 - accuracy: 0.7259\n",
      "Epoch 2336/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6852 - accuracy: 0.7248\n",
      "Epoch 2337/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.7262\n",
      "Epoch 2338/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6899 - accuracy: 0.7262\n",
      "Epoch 2339/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6851 - accuracy: 0.7274\n",
      "Epoch 2340/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.7264\n",
      "Epoch 2341/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.7233\n",
      "Epoch 2342/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6823 - accuracy: 0.7266\n",
      "Epoch 2343/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6916 - accuracy: 0.7250\n",
      "Epoch 2344/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6847 - accuracy: 0.7238\n",
      "Epoch 2345/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7273\n",
      "Epoch 2346/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6810 - accuracy: 0.7279\n",
      "Epoch 2347/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.7244\n",
      "Epoch 2348/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6815 - accuracy: 0.7255\n",
      "Epoch 2349/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7242\n",
      "Epoch 2350/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6827 - accuracy: 0.7288\n",
      "Epoch 2351/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6826 - accuracy: 0.7279\n",
      "Epoch 2352/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.7271\n",
      "Epoch 2353/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6845 - accuracy: 0.7262\n",
      "Epoch 2354/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.7242\n",
      "Epoch 2355/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6835 - accuracy: 0.7269\n",
      "Epoch 2356/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.7236\n",
      "Epoch 2357/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.7244\n",
      "Epoch 2358/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6895 - accuracy: 0.7219\n",
      "Epoch 2359/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.7273\n",
      "Epoch 2360/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6872 - accuracy: 0.7255\n",
      "Epoch 2361/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6878 - accuracy: 0.7254\n",
      "Epoch 2362/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.7253\n",
      "Epoch 2363/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6767 - accuracy: 0.7292\n",
      "Epoch 2364/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6836 - accuracy: 0.7259\n",
      "Epoch 2365/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6903 - accuracy: 0.7242\n",
      "Epoch 2366/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7222\n",
      "Epoch 2367/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6816 - accuracy: 0.7278\n",
      "Epoch 2368/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6808 - accuracy: 0.7244\n",
      "Epoch 2369/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6815 - accuracy: 0.7246\n",
      "Epoch 2370/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6857 - accuracy: 0.7229\n",
      "Epoch 2371/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6810 - accuracy: 0.7278\n",
      "Epoch 2372/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7273\n",
      "Epoch 2373/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6852 - accuracy: 0.7251\n",
      "Epoch 2374/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6848 - accuracy: 0.7245\n",
      "Epoch 2375/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6874 - accuracy: 0.7246\n",
      "Epoch 2376/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6825 - accuracy: 0.7282\n",
      "Epoch 2377/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.7228\n",
      "Epoch 2378/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6827 - accuracy: 0.7249\n",
      "Epoch 2379/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.7246\n",
      "Epoch 2380/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6817 - accuracy: 0.7262\n",
      "Epoch 2381/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7267\n",
      "Epoch 2382/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6820 - accuracy: 0.7260\n",
      "Epoch 2383/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.7240\n",
      "Epoch 2384/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6818 - accuracy: 0.7284\n",
      "Epoch 2385/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.7236\n",
      "Epoch 2386/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6860 - accuracy: 0.7220\n",
      "Epoch 2387/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.7265\n",
      "Epoch 2388/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6854 - accuracy: 0.7272\n",
      "Epoch 2389/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6814 - accuracy: 0.7300\n",
      "Epoch 2390/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6835 - accuracy: 0.7251\n",
      "Epoch 2391/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6797 - accuracy: 0.7277\n",
      "Epoch 2392/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6784 - accuracy: 0.7272\n",
      "Epoch 2393/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.7231\n",
      "Epoch 2394/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6853 - accuracy: 0.7261\n",
      "Epoch 2395/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6818 - accuracy: 0.7265\n",
      "Epoch 2396/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6914 - accuracy: 0.7243\n",
      "Epoch 2397/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6838 - accuracy: 0.7254\n",
      "Epoch 2398/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6810 - accuracy: 0.7295\n",
      "Epoch 2399/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6845 - accuracy: 0.7225\n",
      "Epoch 2400/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6826 - accuracy: 0.7314\n",
      "Epoch 2401/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.7260\n",
      "Epoch 2402/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6792 - accuracy: 0.7304\n",
      "Epoch 2403/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6842 - accuracy: 0.7254\n",
      "Epoch 2404/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6860 - accuracy: 0.7253\n",
      "Epoch 2405/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7317\n",
      "Epoch 2406/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6824 - accuracy: 0.7242\n",
      "Epoch 2407/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6835 - accuracy: 0.7283\n",
      "Epoch 2408/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7295\n",
      "Epoch 2409/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6854 - accuracy: 0.7260\n",
      "Epoch 2410/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.7249\n",
      "Epoch 2411/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6776 - accuracy: 0.7299\n",
      "Epoch 2412/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6898 - accuracy: 0.7265\n",
      "Epoch 2413/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6839 - accuracy: 0.7249\n",
      "Epoch 2414/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6871 - accuracy: 0.7255\n",
      "Epoch 2415/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6826 - accuracy: 0.7312\n",
      "Epoch 2416/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6899 - accuracy: 0.7209\n",
      "Epoch 2417/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6888 - accuracy: 0.7248\n",
      "Epoch 2418/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6810 - accuracy: 0.7297\n",
      "Epoch 2419/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6819 - accuracy: 0.7286\n",
      "Epoch 2420/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6798 - accuracy: 0.7277\n",
      "Epoch 2421/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6842 - accuracy: 0.7263\n",
      "Epoch 2422/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6787 - accuracy: 0.7310\n",
      "Epoch 2423/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6851 - accuracy: 0.7239\n",
      "Epoch 2424/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6785 - accuracy: 0.7273\n",
      "Epoch 2425/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6839 - accuracy: 0.7282\n",
      "Epoch 2426/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6788 - accuracy: 0.7300\n",
      "Epoch 2427/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.7232\n",
      "Epoch 2428/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6800 - accuracy: 0.7252\n",
      "Epoch 2429/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6816 - accuracy: 0.7267\n",
      "Epoch 2430/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6807 - accuracy: 0.7275\n",
      "Epoch 2431/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6762 - accuracy: 0.7304\n",
      "Epoch 2432/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6890 - accuracy: 0.7225\n",
      "Epoch 2433/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6797 - accuracy: 0.7314\n",
      "Epoch 2434/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.7285\n",
      "Epoch 2435/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6779 - accuracy: 0.7296\n",
      "Epoch 2436/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6837 - accuracy: 0.7265\n",
      "Epoch 2437/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6850 - accuracy: 0.7266\n",
      "Epoch 2438/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6787 - accuracy: 0.7298\n",
      "Epoch 2439/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6799 - accuracy: 0.7282\n",
      "Epoch 2440/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6746 - accuracy: 0.7293\n",
      "Epoch 2441/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7313\n",
      "Epoch 2442/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6812 - accuracy: 0.7287\n",
      "Epoch 2443/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6827 - accuracy: 0.7209\n",
      "Epoch 2444/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6857 - accuracy: 0.7238\n",
      "Epoch 2445/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6815 - accuracy: 0.7278\n",
      "Epoch 2446/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6859 - accuracy: 0.7259\n",
      "Epoch 2447/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6798 - accuracy: 0.7281\n",
      "Epoch 2448/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6844 - accuracy: 0.7257\n",
      "Epoch 2449/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6859 - accuracy: 0.7237\n",
      "Epoch 2450/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6760 - accuracy: 0.7300\n",
      "Epoch 2451/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6780 - accuracy: 0.7304\n",
      "Epoch 2452/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7272\n",
      "Epoch 2453/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6841 - accuracy: 0.7310\n",
      "Epoch 2454/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6815 - accuracy: 0.7256\n",
      "Epoch 2455/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7256\n",
      "Epoch 2456/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6815 - accuracy: 0.7269\n",
      "Epoch 2457/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6807 - accuracy: 0.7269\n",
      "Epoch 2458/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7257\n",
      "Epoch 2459/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6858 - accuracy: 0.7253\n",
      "Epoch 2460/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6765 - accuracy: 0.7250\n",
      "Epoch 2461/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6853 - accuracy: 0.7277\n",
      "Epoch 2462/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6749 - accuracy: 0.7303\n",
      "Epoch 2463/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.7304\n",
      "Epoch 2464/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6799 - accuracy: 0.7318\n",
      "Epoch 2465/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.7237\n",
      "Epoch 2466/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6849 - accuracy: 0.7254\n",
      "Epoch 2467/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.7249\n",
      "Epoch 2468/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.7285\n",
      "Epoch 2469/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6812 - accuracy: 0.7276\n",
      "Epoch 2470/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6825 - accuracy: 0.7256\n",
      "Epoch 2471/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6814 - accuracy: 0.7261\n",
      "Epoch 2472/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6852 - accuracy: 0.7244\n",
      "Epoch 2473/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6755 - accuracy: 0.7276\n",
      "Epoch 2474/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.7272\n",
      "Epoch 2475/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6794 - accuracy: 0.7284\n",
      "Epoch 2476/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6849 - accuracy: 0.7259\n",
      "Epoch 2477/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.7249\n",
      "Epoch 2478/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6851 - accuracy: 0.7293\n",
      "Epoch 2479/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.7307\n",
      "Epoch 2480/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7305\n",
      "Epoch 2481/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6842 - accuracy: 0.7281\n",
      "Epoch 2482/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7297\n",
      "Epoch 2483/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6783 - accuracy: 0.7266\n",
      "Epoch 2484/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6825 - accuracy: 0.7255\n",
      "Epoch 2485/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7311\n",
      "Epoch 2486/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.7294\n",
      "Epoch 2487/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6847 - accuracy: 0.7257\n",
      "Epoch 2488/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6745 - accuracy: 0.7321\n",
      "Epoch 2489/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6811 - accuracy: 0.7272\n",
      "Epoch 2490/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6791 - accuracy: 0.7270\n",
      "Epoch 2491/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6841 - accuracy: 0.7263\n",
      "Epoch 2492/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6767 - accuracy: 0.7284\n",
      "Epoch 2493/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6818 - accuracy: 0.7237\n",
      "Epoch 2494/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6828 - accuracy: 0.7256\n",
      "Epoch 2495/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6806 - accuracy: 0.7278\n",
      "Epoch 2496/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6773 - accuracy: 0.7230\n",
      "Epoch 2497/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7265\n",
      "Epoch 2498/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6867 - accuracy: 0.7261\n",
      "Epoch 2499/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6755 - accuracy: 0.7281\n",
      "Epoch 2500/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6772 - accuracy: 0.7301\n",
      "Epoch 2501/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6785 - accuracy: 0.7291\n",
      "Epoch 2502/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.7289\n",
      "Epoch 2503/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6816 - accuracy: 0.7254\n",
      "Epoch 2504/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6810 - accuracy: 0.7275\n",
      "Epoch 2505/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6825 - accuracy: 0.7289\n",
      "Epoch 2506/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6757 - accuracy: 0.7319\n",
      "Epoch 2507/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6784 - accuracy: 0.7282\n",
      "Epoch 2508/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6817 - accuracy: 0.7260\n",
      "Epoch 2509/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.7291\n",
      "Epoch 2510/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6853 - accuracy: 0.7279\n",
      "Epoch 2511/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6822 - accuracy: 0.7255\n",
      "Epoch 2512/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6782 - accuracy: 0.7295\n",
      "Epoch 2513/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6762 - accuracy: 0.7281\n",
      "Epoch 2514/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6770 - accuracy: 0.7263\n",
      "Epoch 2515/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6743 - accuracy: 0.7318\n",
      "Epoch 2516/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6763 - accuracy: 0.7299\n",
      "Epoch 2517/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6751 - accuracy: 0.7297\n",
      "Epoch 2518/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.7289\n",
      "Epoch 2519/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6797 - accuracy: 0.7263\n",
      "Epoch 2520/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7262\n",
      "Epoch 2521/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6807 - accuracy: 0.7285\n",
      "Epoch 2522/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6798 - accuracy: 0.7281\n",
      "Epoch 2523/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6830 - accuracy: 0.7252\n",
      "Epoch 2524/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.7291\n",
      "Epoch 2525/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.7281\n",
      "Epoch 2526/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6795 - accuracy: 0.7269\n",
      "Epoch 2527/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6779 - accuracy: 0.7266\n",
      "Epoch 2528/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6828 - accuracy: 0.7268\n",
      "Epoch 2529/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.7293\n",
      "Epoch 2530/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.7283\n",
      "Epoch 2531/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6827 - accuracy: 0.7259\n",
      "Epoch 2532/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7284\n",
      "Epoch 2533/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6793 - accuracy: 0.7285\n",
      "Epoch 2534/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6784 - accuracy: 0.7268\n",
      "Epoch 2535/3000\n",
      "288/288 [==============================] - 1s 5ms/step - loss: 0.6835 - accuracy: 0.7274\n",
      "Epoch 2536/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6791 - accuracy: 0.7287\n",
      "Epoch 2537/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.7325\n",
      "Epoch 2538/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6817 - accuracy: 0.7259\n",
      "Epoch 2539/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6746 - accuracy: 0.7291\n",
      "Epoch 2540/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6694 - accuracy: 0.7312\n",
      "Epoch 2541/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6785 - accuracy: 0.7310\n",
      "Epoch 2542/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.7319\n",
      "Epoch 2543/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6774 - accuracy: 0.7276\n",
      "Epoch 2544/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6804 - accuracy: 0.7258\n",
      "Epoch 2545/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6830 - accuracy: 0.7255\n",
      "Epoch 2546/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6722 - accuracy: 0.7338\n",
      "Epoch 2547/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7256\n",
      "Epoch 2548/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6755 - accuracy: 0.7290\n",
      "Epoch 2549/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7278\n",
      "Epoch 2550/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6806 - accuracy: 0.7256\n",
      "Epoch 2551/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6792 - accuracy: 0.7299\n",
      "Epoch 2552/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6768 - accuracy: 0.7314\n",
      "Epoch 2553/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6840 - accuracy: 0.7233\n",
      "Epoch 2554/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6740 - accuracy: 0.7295\n",
      "Epoch 2555/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6755 - accuracy: 0.7313\n",
      "Epoch 2556/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6770 - accuracy: 0.7282\n",
      "Epoch 2557/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6805 - accuracy: 0.7266\n",
      "Epoch 2558/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6857 - accuracy: 0.7280\n",
      "Epoch 2559/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6797 - accuracy: 0.7256\n",
      "Epoch 2560/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7310\n",
      "Epoch 2561/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7261\n",
      "Epoch 2562/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6703 - accuracy: 0.7317\n",
      "Epoch 2563/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6765 - accuracy: 0.7277\n",
      "Epoch 2564/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6825 - accuracy: 0.7239\n",
      "Epoch 2565/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6773 - accuracy: 0.7291\n",
      "Epoch 2566/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6723 - accuracy: 0.7313\n",
      "Epoch 2567/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6839 - accuracy: 0.7288\n",
      "Epoch 2568/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6750 - accuracy: 0.7288\n",
      "Epoch 2569/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6697 - accuracy: 0.7321\n",
      "Epoch 2570/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6912 - accuracy: 0.7230\n",
      "Epoch 2571/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6726 - accuracy: 0.7298\n",
      "Epoch 2572/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6778 - accuracy: 0.7312\n",
      "Epoch 2573/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6789 - accuracy: 0.7261\n",
      "Epoch 2574/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6773 - accuracy: 0.7294\n",
      "Epoch 2575/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6843 - accuracy: 0.7285\n",
      "Epoch 2576/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7268\n",
      "Epoch 2577/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6714 - accuracy: 0.7321\n",
      "Epoch 2578/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6778 - accuracy: 0.7256\n",
      "Epoch 2579/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6779 - accuracy: 0.7294\n",
      "Epoch 2580/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6823 - accuracy: 0.7237\n",
      "Epoch 2581/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6820 - accuracy: 0.7263\n",
      "Epoch 2582/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6802 - accuracy: 0.7261\n",
      "Epoch 2583/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6747 - accuracy: 0.7272\n",
      "Epoch 2584/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7294\n",
      "Epoch 2585/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.7313\n",
      "Epoch 2586/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6753 - accuracy: 0.7275\n",
      "Epoch 2587/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6779 - accuracy: 0.7295\n",
      "Epoch 2588/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6672 - accuracy: 0.7306\n",
      "Epoch 2589/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6804 - accuracy: 0.7250\n",
      "Epoch 2590/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6776 - accuracy: 0.7263\n",
      "Epoch 2591/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6846 - accuracy: 0.7248\n",
      "Epoch 2592/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6754 - accuracy: 0.7295\n",
      "Epoch 2593/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6776 - accuracy: 0.7308\n",
      "Epoch 2594/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6828 - accuracy: 0.7289\n",
      "Epoch 2595/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6773 - accuracy: 0.7291\n",
      "Epoch 2596/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6747 - accuracy: 0.7322\n",
      "Epoch 2597/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6804 - accuracy: 0.7301\n",
      "Epoch 2598/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6767 - accuracy: 0.7316\n",
      "Epoch 2599/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6784 - accuracy: 0.7279\n",
      "Epoch 2600/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6777 - accuracy: 0.7268\n",
      "Epoch 2601/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6780 - accuracy: 0.7292\n",
      "Epoch 2602/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.7283\n",
      "Epoch 2603/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.7327\n",
      "Epoch 2604/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6803 - accuracy: 0.7287\n",
      "Epoch 2605/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6784 - accuracy: 0.7253\n",
      "Epoch 2606/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.7271\n",
      "Epoch 2607/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6817 - accuracy: 0.7274\n",
      "Epoch 2608/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6781 - accuracy: 0.7279\n",
      "Epoch 2609/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6691 - accuracy: 0.7340\n",
      "Epoch 2610/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6794 - accuracy: 0.7290\n",
      "Epoch 2611/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7330\n",
      "Epoch 2612/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.7276\n",
      "Epoch 2613/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6803 - accuracy: 0.7283\n",
      "Epoch 2614/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7315\n",
      "Epoch 2615/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7314\n",
      "Epoch 2616/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6766 - accuracy: 0.7318\n",
      "Epoch 2617/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6757 - accuracy: 0.7278\n",
      "Epoch 2618/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.7308\n",
      "Epoch 2619/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6791 - accuracy: 0.7244\n",
      "Epoch 2620/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6754 - accuracy: 0.7302\n",
      "Epoch 2621/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.7275\n",
      "Epoch 2622/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.7287\n",
      "Epoch 2623/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6765 - accuracy: 0.7285\n",
      "Epoch 2624/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6770 - accuracy: 0.7266\n",
      "Epoch 2625/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6789 - accuracy: 0.7297\n",
      "Epoch 2626/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6849 - accuracy: 0.7266\n",
      "Epoch 2627/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6751 - accuracy: 0.7316\n",
      "Epoch 2628/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6836 - accuracy: 0.7275\n",
      "Epoch 2629/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.7293\n",
      "Epoch 2630/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6774 - accuracy: 0.7310\n",
      "Epoch 2631/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.7300\n",
      "Epoch 2632/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6784 - accuracy: 0.7285\n",
      "Epoch 2633/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6743 - accuracy: 0.7303\n",
      "Epoch 2634/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6817 - accuracy: 0.7268\n",
      "Epoch 2635/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.7293\n",
      "Epoch 2636/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6717 - accuracy: 0.7321\n",
      "Epoch 2637/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6751 - accuracy: 0.7288\n",
      "Epoch 2638/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6808 - accuracy: 0.7267\n",
      "Epoch 2639/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6746 - accuracy: 0.7284\n",
      "Epoch 2640/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6735 - accuracy: 0.7283\n",
      "Epoch 2641/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6770 - accuracy: 0.7284\n",
      "Epoch 2642/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6768 - accuracy: 0.7238\n",
      "Epoch 2643/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7260\n",
      "Epoch 2644/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6738 - accuracy: 0.7294\n",
      "Epoch 2645/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.7318\n",
      "Epoch 2646/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6728 - accuracy: 0.7328\n",
      "Epoch 2647/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6737 - accuracy: 0.7288\n",
      "Epoch 2648/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6683 - accuracy: 0.7325\n",
      "Epoch 2649/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6744 - accuracy: 0.7305\n",
      "Epoch 2650/3000\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6783 - accuracy: 0.7264\n",
      "Epoch 2651/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7300\n",
      "Epoch 2652/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6774 - accuracy: 0.7271\n",
      "Epoch 2653/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.7350\n",
      "Epoch 2654/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7277\n",
      "Epoch 2655/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6765 - accuracy: 0.7317\n",
      "Epoch 2656/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.7268\n",
      "Epoch 2657/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7299\n",
      "Epoch 2658/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6686 - accuracy: 0.7295\n",
      "Epoch 2659/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6738 - accuracy: 0.7307\n",
      "Epoch 2660/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6793 - accuracy: 0.7248\n",
      "Epoch 2661/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6711 - accuracy: 0.7303\n",
      "Epoch 2662/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6778 - accuracy: 0.7263\n",
      "Epoch 2663/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7285\n",
      "Epoch 2664/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6760 - accuracy: 0.7292\n",
      "Epoch 2665/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.7279\n",
      "Epoch 2666/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6746 - accuracy: 0.7280\n",
      "Epoch 2667/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6779 - accuracy: 0.7314\n",
      "Epoch 2668/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6785 - accuracy: 0.7294\n",
      "Epoch 2669/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7295\n",
      "Epoch 2670/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6726 - accuracy: 0.7330\n",
      "Epoch 2671/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6713 - accuracy: 0.7310\n",
      "Epoch 2672/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6767 - accuracy: 0.7276\n",
      "Epoch 2673/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6797 - accuracy: 0.7274\n",
      "Epoch 2674/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.7291\n",
      "Epoch 2675/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6766 - accuracy: 0.7255\n",
      "Epoch 2676/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.7278\n",
      "Epoch 2677/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6788 - accuracy: 0.7281\n",
      "Epoch 2678/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6693 - accuracy: 0.7309\n",
      "Epoch 2679/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.7303\n",
      "Epoch 2680/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6762 - accuracy: 0.7300\n",
      "Epoch 2681/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6718 - accuracy: 0.7279\n",
      "Epoch 2682/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7288\n",
      "Epoch 2683/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6736 - accuracy: 0.7312\n",
      "Epoch 2684/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6699 - accuracy: 0.7327\n",
      "Epoch 2685/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6757 - accuracy: 0.7315\n",
      "Epoch 2686/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7281\n",
      "Epoch 2687/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6765 - accuracy: 0.7299\n",
      "Epoch 2688/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6779 - accuracy: 0.7243\n",
      "Epoch 2689/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6756 - accuracy: 0.7296\n",
      "Epoch 2690/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6698 - accuracy: 0.7301\n",
      "Epoch 2691/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6707 - accuracy: 0.7330\n",
      "Epoch 2692/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.7289\n",
      "Epoch 2693/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6738 - accuracy: 0.7312\n",
      "Epoch 2694/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6821 - accuracy: 0.7283\n",
      "Epoch 2695/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6750 - accuracy: 0.7300\n",
      "Epoch 2696/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6736 - accuracy: 0.7275\n",
      "Epoch 2697/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6731 - accuracy: 0.7299\n",
      "Epoch 2698/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6805 - accuracy: 0.7255\n",
      "Epoch 2699/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6830 - accuracy: 0.7268\n",
      "Epoch 2700/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6704 - accuracy: 0.7310\n",
      "Epoch 2701/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6783 - accuracy: 0.7306\n",
      "Epoch 2702/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7284\n",
      "Epoch 2703/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6723 - accuracy: 0.7306\n",
      "Epoch 2704/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6725 - accuracy: 0.7300\n",
      "Epoch 2705/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.7310\n",
      "Epoch 2706/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6753 - accuracy: 0.7306\n",
      "Epoch 2707/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6686 - accuracy: 0.7329\n",
      "Epoch 2708/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6717 - accuracy: 0.7293\n",
      "Epoch 2709/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7294\n",
      "Epoch 2710/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6743 - accuracy: 0.7289\n",
      "Epoch 2711/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6679 - accuracy: 0.7342\n",
      "Epoch 2712/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6784 - accuracy: 0.7321\n",
      "Epoch 2713/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6638 - accuracy: 0.7352\n",
      "Epoch 2714/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6755 - accuracy: 0.7286\n",
      "Epoch 2715/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.7314\n",
      "Epoch 2716/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.7289\n",
      "Epoch 2717/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7287\n",
      "Epoch 2718/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.7286\n",
      "Epoch 2719/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6697 - accuracy: 0.7317\n",
      "Epoch 2720/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6674 - accuracy: 0.7332\n",
      "Epoch 2721/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6808 - accuracy: 0.7294\n",
      "Epoch 2722/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.7311\n",
      "Epoch 2723/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6682 - accuracy: 0.7327\n",
      "Epoch 2724/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6653 - accuracy: 0.7299\n",
      "Epoch 2725/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6757 - accuracy: 0.7314\n",
      "Epoch 2726/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7280\n",
      "Epoch 2727/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6684 - accuracy: 0.7348\n",
      "Epoch 2728/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.7268\n",
      "Epoch 2729/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6679 - accuracy: 0.7321\n",
      "Epoch 2730/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6722 - accuracy: 0.7309\n",
      "Epoch 2731/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6783 - accuracy: 0.7294\n",
      "Epoch 2732/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6714 - accuracy: 0.7313\n",
      "Epoch 2733/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6672 - accuracy: 0.7308\n",
      "Epoch 2734/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6720 - accuracy: 0.7332\n",
      "Epoch 2735/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6688 - accuracy: 0.7334\n",
      "Epoch 2736/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6675 - accuracy: 0.7298\n",
      "Epoch 2737/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6712 - accuracy: 0.7294\n",
      "Epoch 2738/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6668 - accuracy: 0.7318\n",
      "Epoch 2739/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.7347\n",
      "Epoch 2740/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.7345\n",
      "Epoch 2741/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6756 - accuracy: 0.7313\n",
      "Epoch 2742/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6700 - accuracy: 0.7316\n",
      "Epoch 2743/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6746 - accuracy: 0.7310\n",
      "Epoch 2744/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6716 - accuracy: 0.7307\n",
      "Epoch 2745/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6791 - accuracy: 0.7303\n",
      "Epoch 2746/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6719 - accuracy: 0.7344\n",
      "Epoch 2747/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.7312\n",
      "Epoch 2748/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7289\n",
      "Epoch 2749/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6671 - accuracy: 0.7337\n",
      "Epoch 2750/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6746 - accuracy: 0.7293\n",
      "Epoch 2751/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6747 - accuracy: 0.7310\n",
      "Epoch 2752/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6702 - accuracy: 0.7316\n",
      "Epoch 2753/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6707 - accuracy: 0.7322\n",
      "Epoch 2754/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7287\n",
      "Epoch 2755/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7308\n",
      "Epoch 2756/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6716 - accuracy: 0.7340\n",
      "Epoch 2757/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6702 - accuracy: 0.7331\n",
      "Epoch 2758/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6719 - accuracy: 0.7332\n",
      "Epoch 2759/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.7312\n",
      "Epoch 2760/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6711 - accuracy: 0.7286\n",
      "Epoch 2761/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6773 - accuracy: 0.7316\n",
      "Epoch 2762/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6673 - accuracy: 0.7285\n",
      "Epoch 2763/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6754 - accuracy: 0.7314\n",
      "Epoch 2764/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6754 - accuracy: 0.7300\n",
      "Epoch 2765/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6641 - accuracy: 0.7342\n",
      "Epoch 2766/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6751 - accuracy: 0.7305\n",
      "Epoch 2767/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6764 - accuracy: 0.7274\n",
      "Epoch 2768/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7302\n",
      "Epoch 2769/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6687 - accuracy: 0.7318\n",
      "Epoch 2770/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6681 - accuracy: 0.7319\n",
      "Epoch 2771/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.7308\n",
      "Epoch 2772/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6661 - accuracy: 0.7300\n",
      "Epoch 2773/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.7286\n",
      "Epoch 2774/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6710 - accuracy: 0.7310\n",
      "Epoch 2775/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7296\n",
      "Epoch 2776/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6768 - accuracy: 0.7304\n",
      "Epoch 2777/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.7332\n",
      "Epoch 2778/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6728 - accuracy: 0.7305\n",
      "Epoch 2779/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6689 - accuracy: 0.7333\n",
      "Epoch 2780/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6730 - accuracy: 0.7312\n",
      "Epoch 2781/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6700 - accuracy: 0.7302\n",
      "Epoch 2782/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6723 - accuracy: 0.7337\n",
      "Epoch 2783/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6768 - accuracy: 0.7300\n",
      "Epoch 2784/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6669 - accuracy: 0.7347\n",
      "Epoch 2785/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.7324\n",
      "Epoch 2786/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6727 - accuracy: 0.7312\n",
      "Epoch 2787/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.7347\n",
      "Epoch 2788/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6690 - accuracy: 0.7308\n",
      "Epoch 2789/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6662 - accuracy: 0.7305\n",
      "Epoch 2790/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6719 - accuracy: 0.7293\n",
      "Epoch 2791/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6732 - accuracy: 0.7305\n",
      "Epoch 2792/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6682 - accuracy: 0.7316\n",
      "Epoch 2793/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6703 - accuracy: 0.7333\n",
      "Epoch 2794/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6793 - accuracy: 0.7295\n",
      "Epoch 2795/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6710 - accuracy: 0.7340\n",
      "Epoch 2796/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6715 - accuracy: 0.7309\n",
      "Epoch 2797/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6660 - accuracy: 0.7323\n",
      "Epoch 2798/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6723 - accuracy: 0.7329\n",
      "Epoch 2799/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.7291\n",
      "Epoch 2800/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.7294\n",
      "Epoch 2801/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6737 - accuracy: 0.7310\n",
      "Epoch 2802/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6743 - accuracy: 0.7285\n",
      "Epoch 2803/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.7297\n",
      "Epoch 2804/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6735 - accuracy: 0.7307\n",
      "Epoch 2805/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6688 - accuracy: 0.7332\n",
      "Epoch 2806/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6657 - accuracy: 0.7311\n",
      "Epoch 2807/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6722 - accuracy: 0.7308\n",
      "Epoch 2808/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6648 - accuracy: 0.7340\n",
      "Epoch 2809/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6729 - accuracy: 0.7289\n",
      "Epoch 2810/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6633 - accuracy: 0.7340\n",
      "Epoch 2811/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.7298\n",
      "Epoch 2812/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6675 - accuracy: 0.7311\n",
      "Epoch 2813/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6715 - accuracy: 0.7314\n",
      "Epoch 2814/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6709 - accuracy: 0.7349\n",
      "Epoch 2815/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6723 - accuracy: 0.7280\n",
      "Epoch 2816/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6726 - accuracy: 0.7329\n",
      "Epoch 2817/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6665 - accuracy: 0.7326\n",
      "Epoch 2818/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.7338\n",
      "Epoch 2819/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6722 - accuracy: 0.7314\n",
      "Epoch 2820/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6631 - accuracy: 0.7346\n",
      "Epoch 2821/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6684 - accuracy: 0.7317\n",
      "Epoch 2822/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6697 - accuracy: 0.7297\n",
      "Epoch 2823/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6675 - accuracy: 0.7349\n",
      "Epoch 2824/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6744 - accuracy: 0.7318\n",
      "Epoch 2825/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.7330\n",
      "Epoch 2826/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6659 - accuracy: 0.7316\n",
      "Epoch 2827/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6673 - accuracy: 0.7330\n",
      "Epoch 2828/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6675 - accuracy: 0.7339\n",
      "Epoch 2829/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7292\n",
      "Epoch 2830/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6730 - accuracy: 0.7332\n",
      "Epoch 2831/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6652 - accuracy: 0.7344\n",
      "Epoch 2832/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6664 - accuracy: 0.7325\n",
      "Epoch 2833/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6672 - accuracy: 0.7334\n",
      "Epoch 2834/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6728 - accuracy: 0.7314\n",
      "Epoch 2835/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6682 - accuracy: 0.7330\n",
      "Epoch 2836/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7340\n",
      "Epoch 2837/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6634 - accuracy: 0.7354\n",
      "Epoch 2838/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6702 - accuracy: 0.7319\n",
      "Epoch 2839/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6650 - accuracy: 0.7338\n",
      "Epoch 2840/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6715 - accuracy: 0.7358\n",
      "Epoch 2841/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6709 - accuracy: 0.7307\n",
      "Epoch 2842/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6697 - accuracy: 0.7334\n",
      "Epoch 2843/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6674 - accuracy: 0.7325\n",
      "Epoch 2844/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6748 - accuracy: 0.7308\n",
      "Epoch 2845/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6763 - accuracy: 0.7287\n",
      "Epoch 2846/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6662 - accuracy: 0.7355\n",
      "Epoch 2847/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.7330\n",
      "Epoch 2848/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6642 - accuracy: 0.7362\n",
      "Epoch 2849/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6638 - accuracy: 0.7330\n",
      "Epoch 2850/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6695 - accuracy: 0.7315\n",
      "Epoch 2851/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6717 - accuracy: 0.7337\n",
      "Epoch 2852/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6738 - accuracy: 0.7320\n",
      "Epoch 2853/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6675 - accuracy: 0.7351\n",
      "Epoch 2854/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6734 - accuracy: 0.7334\n",
      "Epoch 2855/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6664 - accuracy: 0.7356\n",
      "Epoch 2856/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6649 - accuracy: 0.7364\n",
      "Epoch 2857/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6698 - accuracy: 0.7327\n",
      "Epoch 2858/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6657 - accuracy: 0.7356\n",
      "Epoch 2859/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6694 - accuracy: 0.7343\n",
      "Epoch 2860/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6704 - accuracy: 0.7324\n",
      "Epoch 2861/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.7339\n",
      "Epoch 2862/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6632 - accuracy: 0.7372\n",
      "Epoch 2863/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6693 - accuracy: 0.7327\n",
      "Epoch 2864/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6729 - accuracy: 0.7339\n",
      "Epoch 2865/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6687 - accuracy: 0.7340\n",
      "Epoch 2866/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6714 - accuracy: 0.7320\n",
      "Epoch 2867/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6724 - accuracy: 0.7324\n",
      "Epoch 2868/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6658 - accuracy: 0.7316\n",
      "Epoch 2869/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6745 - accuracy: 0.7320\n",
      "Epoch 2870/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6709 - accuracy: 0.7305\n",
      "Epoch 2871/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6704 - accuracy: 0.7346\n",
      "Epoch 2872/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6726 - accuracy: 0.7336\n",
      "Epoch 2873/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6635 - accuracy: 0.7337\n",
      "Epoch 2874/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.7356\n",
      "Epoch 2875/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6735 - accuracy: 0.7294\n",
      "Epoch 2876/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6687 - accuracy: 0.7337\n",
      "Epoch 2877/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6692 - accuracy: 0.7348\n",
      "Epoch 2878/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6687 - accuracy: 0.7323\n",
      "Epoch 2879/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.7338\n",
      "Epoch 2880/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6665 - accuracy: 0.7328\n",
      "Epoch 2881/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6755 - accuracy: 0.7278\n",
      "Epoch 2882/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6722 - accuracy: 0.7306\n",
      "Epoch 2883/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6687 - accuracy: 0.7342\n",
      "Epoch 2884/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.7343\n",
      "Epoch 2885/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6622 - accuracy: 0.7333\n",
      "Epoch 2886/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6658 - accuracy: 0.7349\n",
      "Epoch 2887/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6746 - accuracy: 0.7276\n",
      "Epoch 2888/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6651 - accuracy: 0.7332\n",
      "Epoch 2889/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6758 - accuracy: 0.7295\n",
      "Epoch 2890/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6703 - accuracy: 0.7304\n",
      "Epoch 2891/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6683 - accuracy: 0.7290\n",
      "Epoch 2892/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6716 - accuracy: 0.7310\n",
      "Epoch 2893/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6666 - accuracy: 0.7327\n",
      "Epoch 2894/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6735 - accuracy: 0.7312\n",
      "Epoch 2895/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6705 - accuracy: 0.7310\n",
      "Epoch 2896/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.7361\n",
      "Epoch 2897/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.7347\n",
      "Epoch 2898/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6668 - accuracy: 0.7304\n",
      "Epoch 2899/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6677 - accuracy: 0.7331\n",
      "Epoch 2900/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6708 - accuracy: 0.7306\n",
      "Epoch 2901/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6727 - accuracy: 0.7312\n",
      "Epoch 2902/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6684 - accuracy: 0.7306\n",
      "Epoch 2903/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.7319\n",
      "Epoch 2904/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6640 - accuracy: 0.7357\n",
      "Epoch 2905/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6649 - accuracy: 0.7322\n",
      "Epoch 2906/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6660 - accuracy: 0.7364\n",
      "Epoch 2907/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6686 - accuracy: 0.7332\n",
      "Epoch 2908/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6748 - accuracy: 0.7311\n",
      "Epoch 2909/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6704 - accuracy: 0.7327\n",
      "Epoch 2910/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.7350\n",
      "Epoch 2911/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6719 - accuracy: 0.7336\n",
      "Epoch 2912/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6609 - accuracy: 0.7365\n",
      "Epoch 2913/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6708 - accuracy: 0.7316\n",
      "Epoch 2914/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6712 - accuracy: 0.7299\n",
      "Epoch 2915/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6601 - accuracy: 0.7371\n",
      "Epoch 2916/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6665 - accuracy: 0.7340\n",
      "Epoch 2917/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6725 - accuracy: 0.7307\n",
      "Epoch 2918/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.7356\n",
      "Epoch 2919/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6723 - accuracy: 0.7331\n",
      "Epoch 2920/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6714 - accuracy: 0.7329\n",
      "Epoch 2921/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6717 - accuracy: 0.7320\n",
      "Epoch 2922/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6708 - accuracy: 0.7311\n",
      "Epoch 2923/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6709 - accuracy: 0.7305\n",
      "Epoch 2924/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6673 - accuracy: 0.7329\n",
      "Epoch 2925/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6709 - accuracy: 0.7260\n",
      "Epoch 2926/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6642 - accuracy: 0.7342\n",
      "Epoch 2927/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6664 - accuracy: 0.7325\n",
      "Epoch 2928/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6683 - accuracy: 0.7349\n",
      "Epoch 2929/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6645 - accuracy: 0.7366\n",
      "Epoch 2930/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6690 - accuracy: 0.7320\n",
      "Epoch 2931/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6716 - accuracy: 0.7323\n",
      "Epoch 2932/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6595 - accuracy: 0.7370\n",
      "Epoch 2933/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6719 - accuracy: 0.7304\n",
      "Epoch 2934/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6662 - accuracy: 0.7354\n",
      "Epoch 2935/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6678 - accuracy: 0.7322\n",
      "Epoch 2936/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.7350\n",
      "Epoch 2937/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6712 - accuracy: 0.7326\n",
      "Epoch 2938/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6705 - accuracy: 0.7313\n",
      "Epoch 2939/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6699 - accuracy: 0.7352\n",
      "Epoch 2940/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6707 - accuracy: 0.7316\n",
      "Epoch 2941/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6697 - accuracy: 0.7302\n",
      "Epoch 2942/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6642 - accuracy: 0.7319\n",
      "Epoch 2943/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6627 - accuracy: 0.7343\n",
      "Epoch 2944/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6681 - accuracy: 0.7309\n",
      "Epoch 2945/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6692 - accuracy: 0.7312\n",
      "Epoch 2946/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6717 - accuracy: 0.7348\n",
      "Epoch 2947/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6631 - accuracy: 0.7355\n",
      "Epoch 2948/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.7331\n",
      "Epoch 2949/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6652 - accuracy: 0.7339\n",
      "Epoch 2950/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6713 - accuracy: 0.7327\n",
      "Epoch 2951/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6641 - accuracy: 0.7336\n",
      "Epoch 2952/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6649 - accuracy: 0.7334\n",
      "Epoch 2953/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6689 - accuracy: 0.7344\n",
      "Epoch 2954/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6647 - accuracy: 0.7340\n",
      "Epoch 2955/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6670 - accuracy: 0.7345\n",
      "Epoch 2956/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6644 - accuracy: 0.7313\n",
      "Epoch 2957/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6632 - accuracy: 0.7346\n",
      "Epoch 2958/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6761 - accuracy: 0.7319\n",
      "Epoch 2959/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6626 - accuracy: 0.7335\n",
      "Epoch 2960/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6679 - accuracy: 0.7301\n",
      "Epoch 2961/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6791 - accuracy: 0.7278\n",
      "Epoch 2962/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.7312\n",
      "Epoch 2963/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6763 - accuracy: 0.7318\n",
      "Epoch 2964/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6744 - accuracy: 0.7329\n",
      "Epoch 2965/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6745 - accuracy: 0.7332\n",
      "Epoch 2966/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6668 - accuracy: 0.7320\n",
      "Epoch 2967/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6693 - accuracy: 0.7383\n",
      "Epoch 2968/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6631 - accuracy: 0.7325\n",
      "Epoch 2969/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.7342\n",
      "Epoch 2970/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6718 - accuracy: 0.7326\n",
      "Epoch 2971/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6684 - accuracy: 0.7337\n",
      "Epoch 2972/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6680 - accuracy: 0.7339\n",
      "Epoch 2973/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6637 - accuracy: 0.7351\n",
      "Epoch 2974/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6691 - accuracy: 0.7327\n",
      "Epoch 2975/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6609 - accuracy: 0.7344\n",
      "Epoch 2976/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6691 - accuracy: 0.7292\n",
      "Epoch 2977/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.7308\n",
      "Epoch 2978/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6605 - accuracy: 0.7340\n",
      "Epoch 2979/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6626 - accuracy: 0.7382\n",
      "Epoch 2980/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6666 - accuracy: 0.7331\n",
      "Epoch 2981/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6633 - accuracy: 0.7353\n",
      "Epoch 2982/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6667 - accuracy: 0.7343\n",
      "Epoch 2983/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6694 - accuracy: 0.7336\n",
      "Epoch 2984/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.7363\n",
      "Epoch 2985/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6713 - accuracy: 0.7327\n",
      "Epoch 2986/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6656 - accuracy: 0.7362\n",
      "Epoch 2987/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6648 - accuracy: 0.7344\n",
      "Epoch 2988/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6592 - accuracy: 0.7365\n",
      "Epoch 2989/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.7332\n",
      "Epoch 2990/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6643 - accuracy: 0.7352\n",
      "Epoch 2991/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.7337\n",
      "Epoch 2992/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6649 - accuracy: 0.7346\n",
      "Epoch 2993/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6636 - accuracy: 0.7377\n",
      "Epoch 2994/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6686 - accuracy: 0.7325\n",
      "Epoch 2995/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6693 - accuracy: 0.7307\n",
      "Epoch 2996/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6594 - accuracy: 0.7371\n",
      "Epoch 2997/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6689 - accuracy: 0.7327\n",
      "Epoch 2998/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6698 - accuracy: 0.7340\n",
      "Epoch 2999/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6610 - accuracy: 0.7371\n",
      "Epoch 3000/3000\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.6644 - accuracy: 0.7346\n",
      "576/576 [==============================] - 2s 1ms/step - loss: 0.4828 - accuracy: 0.8088\n",
      "Train Loss: 0.4828\n",
      "Train Accuracy: 0.8088\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.7992 - accuracy: 0.7112\n",
      "Test Loss: 0.7992\n",
      "Test Accuracy: 0.7112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# DataFrame을 무작위로 섞기\n",
    "df_shuffled = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# 데이터를 입력 특성 (X)과 타겟 변수 (y)로 분할하기\n",
    "X = df_shuffled[['gx', 'gy', 'gz']].values\n",
    "y = df_shuffled['label'].values\n",
    "\n",
    "# 레이블을 인코딩하기 위해 LabelEncoder 사용\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 인코딩된 레이블을 원-핫 인코딩으로 변환하기\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# 입력 특성을 LSTM 모델의 예상 형태로 재구성\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(3, 1), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# LSTM 모델 훈련\n",
    "model.fit(X_train_reshaped, y_train, epochs=3000, batch_size=64)\n",
    "\n",
    "# 훈련 데이터에서 모델 평가\n",
    "train_loss, train_accuracy = model.evaluate(X_train_reshaped, y_train)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# 테스트 데이터에서 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:01:34.870995100Z",
     "start_time": "2023-06-07T05:10:54.727728Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_ID trial_ID task_ID        gx         gy         gz    label   \n",
      "0    SA01      R01     D01 -1.098633 -30.761719 -21.484375  walking  \\\n",
      "1    SA01      R01     D01 -3.234863 -34.667969 -18.676758  walking   \n",
      "2    SA01      R01     D01 -5.126953 -37.414551 -16.540527  walking   \n",
      "3    SA01      R01     D01 -6.347656 -39.489746 -13.854980  walking   \n",
      "4    SA01      R01     D01 -7.812500 -41.198730 -11.657715  walking   \n",
      "\n",
      "   scaled_gx  scaled_gy  scaled_gz  \n",
      "0   0.021823  -0.515393  -0.468850  \n",
      "1   0.007546  -0.549363  -0.439306  \n",
      "2  -0.005099  -0.573248  -0.416827  \n",
      "3  -0.013257  -0.591295  -0.388568  \n",
      "4  -0.023047  -0.606157  -0.365446  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz' 열의 데이터 추출\n",
    "data = df[['gx', 'gy', 'gz']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df['scaled_gx'] = scaled_data[:, 0]\n",
    "df['scaled_gy'] = scaled_data[:, 1]\n",
    "df['scaled_gz'] = scaled_data[:, 2]\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:31:14.339820400Z",
     "start_time": "2023-06-07T06:31:14.292955600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "576/576 [==============================] - 4s 2ms/step - loss: 1.4357 - accuracy: 0.3319\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.4144 - accuracy: 0.3303\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.3785 - accuracy: 0.3641\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.3369 - accuracy: 0.3972\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.3231 - accuracy: 0.4084\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.3142 - accuracy: 0.4159\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.3023 - accuracy: 0.4280\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2868 - accuracy: 0.4336\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2748 - accuracy: 0.4367\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2737 - accuracy: 0.4415\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2669 - accuracy: 0.4442\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2595 - accuracy: 0.4502\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2594 - accuracy: 0.4477\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2556 - accuracy: 0.4493\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2519 - accuracy: 0.4568\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2491 - accuracy: 0.4558\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2456 - accuracy: 0.4588\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2447 - accuracy: 0.4571\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2413 - accuracy: 0.4597\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2383 - accuracy: 0.4631\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2367 - accuracy: 0.4584\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2355 - accuracy: 0.4626\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2316 - accuracy: 0.4686\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2292 - accuracy: 0.4674\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2264 - accuracy: 0.4668\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2259 - accuracy: 0.4704\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2217 - accuracy: 0.4759\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2173 - accuracy: 0.4762\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2152 - accuracy: 0.4782\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2141 - accuracy: 0.4768\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2129 - accuracy: 0.4759\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2112 - accuracy: 0.4787\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2112 - accuracy: 0.4743\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2086 - accuracy: 0.4784\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2030 - accuracy: 0.4813\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2030 - accuracy: 0.4782\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.2024 - accuracy: 0.4787\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1998 - accuracy: 0.4817\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1938 - accuracy: 0.4810\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1939 - accuracy: 0.4847\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1902 - accuracy: 0.4881\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1901 - accuracy: 0.4868\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1882 - accuracy: 0.4881\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1868 - accuracy: 0.4867\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1779 - accuracy: 0.4897\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1836 - accuracy: 0.4905\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1842 - accuracy: 0.4871\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1772 - accuracy: 0.4894\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1774 - accuracy: 0.4959\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1717 - accuracy: 0.4977\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1732 - accuracy: 0.4990\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1739 - accuracy: 0.4944\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1670 - accuracy: 0.4976\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1707 - accuracy: 0.4940\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1647 - accuracy: 0.5003\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1641 - accuracy: 0.5049\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1622 - accuracy: 0.5004\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1588 - accuracy: 0.5007\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1577 - accuracy: 0.5033\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1587 - accuracy: 0.5036\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1554 - accuracy: 0.5031\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1513 - accuracy: 0.5053\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1539 - accuracy: 0.5025\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1517 - accuracy: 0.5060\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1475 - accuracy: 0.5069\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1452 - accuracy: 0.5116\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1438 - accuracy: 0.5099\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1439 - accuracy: 0.5115\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1432 - accuracy: 0.5112\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1409 - accuracy: 0.5151\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1402 - accuracy: 0.5129\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1377 - accuracy: 0.5123\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1372 - accuracy: 0.5133\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1397 - accuracy: 0.5135\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1332 - accuracy: 0.5219\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1340 - accuracy: 0.5184\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1346 - accuracy: 0.5187\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1316 - accuracy: 0.5227\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1275 - accuracy: 0.5188\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1294 - accuracy: 0.5201\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1275 - accuracy: 0.5193\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1274 - accuracy: 0.5196\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1240 - accuracy: 0.5227\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1215 - accuracy: 0.5220\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1229 - accuracy: 0.5244\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1213 - accuracy: 0.5192\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1180 - accuracy: 0.5248\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1188 - accuracy: 0.5262\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1192 - accuracy: 0.5233\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1109 - accuracy: 0.5310\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1132 - accuracy: 0.5266\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1119 - accuracy: 0.5265\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1121 - accuracy: 0.5265\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1087 - accuracy: 0.5273\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1079 - accuracy: 0.5284\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1068 - accuracy: 0.5332\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1055 - accuracy: 0.5335\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1117 - accuracy: 0.5286\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1056 - accuracy: 0.5278\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1074 - accuracy: 0.5311\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1061 - accuracy: 0.5322\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1054 - accuracy: 0.5290\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1012 - accuracy: 0.5320\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.1049 - accuracy: 0.5330\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0988 - accuracy: 0.5339\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0967 - accuracy: 0.5363\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0991 - accuracy: 0.5329\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0988 - accuracy: 0.5363\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0969 - accuracy: 0.5379\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0970 - accuracy: 0.5327\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0989 - accuracy: 0.5368\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0918 - accuracy: 0.5399\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0918 - accuracy: 0.5388\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0941 - accuracy: 0.5394\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0901 - accuracy: 0.5394\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0948 - accuracy: 0.5394\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0934 - accuracy: 0.5402\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0912 - accuracy: 0.5404\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0899 - accuracy: 0.5388\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0927 - accuracy: 0.5358\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0908 - accuracy: 0.5377\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0906 - accuracy: 0.5394\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0864 - accuracy: 0.5400\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0856 - accuracy: 0.5410\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0835 - accuracy: 0.5404\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0818 - accuracy: 0.5436\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0860 - accuracy: 0.5446\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0820 - accuracy: 0.5457\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0840 - accuracy: 0.5452\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0819 - accuracy: 0.5436\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0804 - accuracy: 0.5468\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0797 - accuracy: 0.5450\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0807 - accuracy: 0.5475\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0768 - accuracy: 0.5489\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0775 - accuracy: 0.5455\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0783 - accuracy: 0.5457\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0749 - accuracy: 0.5496\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0753 - accuracy: 0.5465\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0811 - accuracy: 0.5489\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0804 - accuracy: 0.5482\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0729 - accuracy: 0.5490\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0702 - accuracy: 0.5519\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0700 - accuracy: 0.5520\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0687 - accuracy: 0.5488\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0663 - accuracy: 0.5541\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0737 - accuracy: 0.5509\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0710 - accuracy: 0.5514\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0700 - accuracy: 0.5525\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0733 - accuracy: 0.5512\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0640 - accuracy: 0.5501\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0712 - accuracy: 0.5512\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0686 - accuracy: 0.5557\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0645 - accuracy: 0.5528\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0717 - accuracy: 0.5539\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0643 - accuracy: 0.5533\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0686 - accuracy: 0.5513\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0641 - accuracy: 0.5539\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0614 - accuracy: 0.5567\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0589 - accuracy: 0.5536\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0586 - accuracy: 0.5565\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0606 - accuracy: 0.5565\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0642 - accuracy: 0.5532\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0604 - accuracy: 0.5571\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0581 - accuracy: 0.5591\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0594 - accuracy: 0.5568\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0582 - accuracy: 0.5567\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0624 - accuracy: 0.5556\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0568 - accuracy: 0.5587\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0600 - accuracy: 0.5546\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0559 - accuracy: 0.5565\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0619 - accuracy: 0.5559\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0593 - accuracy: 0.5558\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0587 - accuracy: 0.5578\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0581 - accuracy: 0.5591\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0522 - accuracy: 0.5615\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0548 - accuracy: 0.5575\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0589 - accuracy: 0.5564\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0551 - accuracy: 0.5630\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0529 - accuracy: 0.5589\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0597 - accuracy: 0.5572\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0480 - accuracy: 0.5647\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0525 - accuracy: 0.5623\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0486 - accuracy: 0.5640\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0528 - accuracy: 0.5615\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0459 - accuracy: 0.5651\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0502 - accuracy: 0.5606\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0526 - accuracy: 0.5608\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0491 - accuracy: 0.5615\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0488 - accuracy: 0.5652\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0416 - accuracy: 0.5652\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0480 - accuracy: 0.5630\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0477 - accuracy: 0.5621\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0508 - accuracy: 0.5624\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0467 - accuracy: 0.5643\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0442 - accuracy: 0.5641\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0501 - accuracy: 0.5622\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0436 - accuracy: 0.5662\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0444 - accuracy: 0.5627\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0421 - accuracy: 0.5669\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0433 - accuracy: 0.5648\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0439 - accuracy: 0.5655\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0473 - accuracy: 0.5629\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0460 - accuracy: 0.5631\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0453 - accuracy: 0.5654\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0457 - accuracy: 0.5649\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0423 - accuracy: 0.5672\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0402 - accuracy: 0.5631\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0406 - accuracy: 0.5674\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0420 - accuracy: 0.5678\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0340 - accuracy: 0.5660\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0382 - accuracy: 0.5707\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0348 - accuracy: 0.5668\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0382 - accuracy: 0.5681\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0429 - accuracy: 0.5631\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0360 - accuracy: 0.5671\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0346 - accuracy: 0.5664\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0356 - accuracy: 0.5681\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0327 - accuracy: 0.5720\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0399 - accuracy: 0.5668\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0381 - accuracy: 0.5679\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0317 - accuracy: 0.5744\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0396 - accuracy: 0.5699\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0352 - accuracy: 0.5692\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0341 - accuracy: 0.5678\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0329 - accuracy: 0.5692\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0317 - accuracy: 0.5725\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0341 - accuracy: 0.5685\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0374 - accuracy: 0.5673\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0326 - accuracy: 0.5681\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0304 - accuracy: 0.5747\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0352 - accuracy: 0.5681\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0331 - accuracy: 0.5694\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0309 - accuracy: 0.5691\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0284 - accuracy: 0.5744\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0244 - accuracy: 0.5725\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0332 - accuracy: 0.5686\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0282 - accuracy: 0.5706\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0286 - accuracy: 0.5690\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0273 - accuracy: 0.5721\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0271 - accuracy: 0.5730\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0287 - accuracy: 0.5696\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0262 - accuracy: 0.5735\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0271 - accuracy: 0.5727\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0227 - accuracy: 0.5748\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0245 - accuracy: 0.5730\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0282 - accuracy: 0.5747\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0293 - accuracy: 0.5726\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0267 - accuracy: 0.5742\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0247 - accuracy: 0.5737\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0276 - accuracy: 0.5718\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0258 - accuracy: 0.5737\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0248 - accuracy: 0.5747\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0238 - accuracy: 0.5711\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0235 - accuracy: 0.5735\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0213 - accuracy: 0.5779\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0225 - accuracy: 0.5779\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0188 - accuracy: 0.5768\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0243 - accuracy: 0.5726\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0216 - accuracy: 0.5752\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0254 - accuracy: 0.5750\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0234 - accuracy: 0.5706\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0201 - accuracy: 0.5772\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0197 - accuracy: 0.5777\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0222 - accuracy: 0.5774\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0155 - accuracy: 0.5784\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0264 - accuracy: 0.5740\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0193 - accuracy: 0.5741\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0216 - accuracy: 0.5760\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0177 - accuracy: 0.5750\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0208 - accuracy: 0.5760\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0173 - accuracy: 0.5756\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0225 - accuracy: 0.5730\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0162 - accuracy: 0.5799\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0183 - accuracy: 0.5761\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0141 - accuracy: 0.5780\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0139 - accuracy: 0.5757\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0189 - accuracy: 0.5778\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0170 - accuracy: 0.5761\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0134 - accuracy: 0.5822\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0181 - accuracy: 0.5766\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0160 - accuracy: 0.5785\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0160 - accuracy: 0.5782\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0155 - accuracy: 0.5790\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0151 - accuracy: 0.5782\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0142 - accuracy: 0.5796\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0158 - accuracy: 0.5803\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0105 - accuracy: 0.5790\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0138 - accuracy: 0.5808\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0103 - accuracy: 0.5797\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0166 - accuracy: 0.5736\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0131 - accuracy: 0.5787\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0131 - accuracy: 0.5823\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0154 - accuracy: 0.5798\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0136 - accuracy: 0.5789\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0106 - accuracy: 0.5865\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0114 - accuracy: 0.5799\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0159 - accuracy: 0.5814\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0100 - accuracy: 0.5818\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0107 - accuracy: 0.5818\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0125 - accuracy: 0.5770\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0128 - accuracy: 0.5787\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0123 - accuracy: 0.5808\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0082 - accuracy: 0.5838\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0080 - accuracy: 0.5795\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0091 - accuracy: 0.5831\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0048 - accuracy: 0.5858\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0116 - accuracy: 0.5808\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0082 - accuracy: 0.5798\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.5785\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0067 - accuracy: 0.5843\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0083 - accuracy: 0.5786\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0039 - accuracy: 0.5839\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0022 - accuracy: 0.5828\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0035 - accuracy: 0.5825\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0064 - accuracy: 0.5823\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0012 - accuracy: 0.5859\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0125 - accuracy: 0.5792\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0062 - accuracy: 0.5839\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0078 - accuracy: 0.5813\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0007 - accuracy: 0.5829\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0040 - accuracy: 0.5829\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0126 - accuracy: 0.5789\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.5841\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0046 - accuracy: 0.5833\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0016 - accuracy: 0.5875\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0020 - accuracy: 0.5858\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0013 - accuracy: 0.5834\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9953 - accuracy: 0.5896\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0028 - accuracy: 0.5844\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0005 - accuracy: 0.5845\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0001 - accuracy: 0.5845\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0035 - accuracy: 0.5855\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0043 - accuracy: 0.5828\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0050 - accuracy: 0.5827\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0039 - accuracy: 0.5833\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9984 - accuracy: 0.5817\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0014 - accuracy: 0.5858\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0043 - accuracy: 0.5822\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0018 - accuracy: 0.5877\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0066 - accuracy: 0.5826\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0062 - accuracy: 0.5817\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9998 - accuracy: 0.5869\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9994 - accuracy: 0.5834\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9985 - accuracy: 0.5866\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9941 - accuracy: 0.5902\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9934 - accuracy: 0.5879\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9991 - accuracy: 0.5850\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9948 - accuracy: 0.5864\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0000 - accuracy: 0.5825\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9948 - accuracy: 0.5873\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9940 - accuracy: 0.5866\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0018 - accuracy: 0.5803\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 1.0042 - accuracy: 0.5832\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9999 - accuracy: 0.5825\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9949 - accuracy: 0.5898\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9971 - accuracy: 0.5883\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9966 - accuracy: 0.5889\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9961 - accuracy: 0.5862\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9951 - accuracy: 0.5876\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9948 - accuracy: 0.5854\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9900 - accuracy: 0.5892\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9963 - accuracy: 0.5868\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9878 - accuracy: 0.5941\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9966 - accuracy: 0.5870\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9926 - accuracy: 0.5883\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9979 - accuracy: 0.5841\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9948 - accuracy: 0.5881\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9943 - accuracy: 0.5903\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9974 - accuracy: 0.5860\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9950 - accuracy: 0.5882\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9871 - accuracy: 0.5873\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9924 - accuracy: 0.5856\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9880 - accuracy: 0.5888\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9915 - accuracy: 0.5914\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9957 - accuracy: 0.5868\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9908 - accuracy: 0.5869\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9936 - accuracy: 0.5875\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9963 - accuracy: 0.5876\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9899 - accuracy: 0.5888\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9941 - accuracy: 0.5909\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9970 - accuracy: 0.5918\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9886 - accuracy: 0.5890\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9951 - accuracy: 0.5889\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9922 - accuracy: 0.5908\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9936 - accuracy: 0.5878\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9934 - accuracy: 0.5900\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9857 - accuracy: 0.5927\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9947 - accuracy: 0.5875\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9874 - accuracy: 0.5874\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9892 - accuracy: 0.5890\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9921 - accuracy: 0.5941\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9870 - accuracy: 0.5908\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9895 - accuracy: 0.5922\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9896 - accuracy: 0.5910\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9882 - accuracy: 0.5883\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9950 - accuracy: 0.5861\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9838 - accuracy: 0.5912\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9892 - accuracy: 0.5889\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9901 - accuracy: 0.5919\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9913 - accuracy: 0.5872\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9863 - accuracy: 0.5902\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9870 - accuracy: 0.5931\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9882 - accuracy: 0.5917\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9874 - accuracy: 0.5917\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9901 - accuracy: 0.5921\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9889 - accuracy: 0.5880\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9916 - accuracy: 0.5876\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9868 - accuracy: 0.5900\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9890 - accuracy: 0.5896\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9914 - accuracy: 0.5913\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9810 - accuracy: 0.5929\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9880 - accuracy: 0.5934\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9871 - accuracy: 0.5900\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9821 - accuracy: 0.5921\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9885 - accuracy: 0.5918\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9876 - accuracy: 0.5913\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9867 - accuracy: 0.5898\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9841 - accuracy: 0.5924\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9849 - accuracy: 0.5911\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9847 - accuracy: 0.5920\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9846 - accuracy: 0.5947\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9906 - accuracy: 0.5891\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9891 - accuracy: 0.5929\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9847 - accuracy: 0.5956\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9824 - accuracy: 0.5904\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9838 - accuracy: 0.5926\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9841 - accuracy: 0.5928\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9818 - accuracy: 0.5928\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9827 - accuracy: 0.5921\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9867 - accuracy: 0.5927\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9870 - accuracy: 0.5907\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9820 - accuracy: 0.5955\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9867 - accuracy: 0.5896\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9829 - accuracy: 0.5914\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9848 - accuracy: 0.5922\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9826 - accuracy: 0.5918\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9769 - accuracy: 0.5955\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9827 - accuracy: 0.5917\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9815 - accuracy: 0.6000\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9832 - accuracy: 0.5952\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9794 - accuracy: 0.5976\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9783 - accuracy: 0.5958\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9854 - accuracy: 0.5930\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9772 - accuracy: 0.5967\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9852 - accuracy: 0.5925\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9842 - accuracy: 0.5903\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9832 - accuracy: 0.5919\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9802 - accuracy: 0.5960\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9833 - accuracy: 0.5898\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9798 - accuracy: 0.5934\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9785 - accuracy: 0.5971\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9727 - accuracy: 0.6000\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9785 - accuracy: 0.5951\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9766 - accuracy: 0.5991\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9788 - accuracy: 0.5948\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9787 - accuracy: 0.5926\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9757 - accuracy: 0.5947\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9792 - accuracy: 0.5963\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9792 - accuracy: 0.5929\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9801 - accuracy: 0.5954\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9783 - accuracy: 0.5942\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9785 - accuracy: 0.5923\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9757 - accuracy: 0.5950\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9782 - accuracy: 0.5955\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9764 - accuracy: 0.5969\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9718 - accuracy: 0.5985\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9758 - accuracy: 0.5953\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9797 - accuracy: 0.5972\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9783 - accuracy: 0.5941\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9762 - accuracy: 0.5933\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9761 - accuracy: 0.5966\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9752 - accuracy: 0.5981\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9766 - accuracy: 0.5994\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9819 - accuracy: 0.5952\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9793 - accuracy: 0.5971\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9779 - accuracy: 0.5935\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9790 - accuracy: 0.5956\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9757 - accuracy: 0.5933\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9727 - accuracy: 0.5980\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9804 - accuracy: 0.5947\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9750 - accuracy: 0.5998\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9784 - accuracy: 0.5978\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9770 - accuracy: 0.5932\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 1s 3ms/step - loss: 0.9784 - accuracy: 0.5931\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9709 - accuracy: 0.6022\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9784 - accuracy: 0.5959\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9766 - accuracy: 0.5988\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9781 - accuracy: 0.5951\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9768 - accuracy: 0.5940\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9737 - accuracy: 0.5988\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9710 - accuracy: 0.5994\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9685 - accuracy: 0.5971\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9719 - accuracy: 0.5970\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9728 - accuracy: 0.5988\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9769 - accuracy: 0.5954\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9684 - accuracy: 0.5955\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9743 - accuracy: 0.5949\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9697 - accuracy: 0.6026\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9745 - accuracy: 0.5958\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9749 - accuracy: 0.5977\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9693 - accuracy: 0.5973\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9739 - accuracy: 0.5947\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9713 - accuracy: 0.5994\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9704 - accuracy: 0.6013\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9693 - accuracy: 0.5992\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9715 - accuracy: 0.6012\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9696 - accuracy: 0.6015\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9756 - accuracy: 0.5969\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9686 - accuracy: 0.6038\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9733 - accuracy: 0.6005\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9677 - accuracy: 0.5999\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9700 - accuracy: 0.6028\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9688 - accuracy: 0.6024\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9761 - accuracy: 0.5977\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9643 - accuracy: 0.6022\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9746 - accuracy: 0.5935\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9724 - accuracy: 0.5989\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9654 - accuracy: 0.6016\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9666 - accuracy: 0.5995\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9758 - accuracy: 0.5972\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9727 - accuracy: 0.5979\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9713 - accuracy: 0.5983\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9699 - accuracy: 0.5980\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9703 - accuracy: 0.6000\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9653 - accuracy: 0.6021\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9722 - accuracy: 0.5985\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9665 - accuracy: 0.6017\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9684 - accuracy: 0.5982\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9708 - accuracy: 0.5996\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9618 - accuracy: 0.6017\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9697 - accuracy: 0.5990\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9716 - accuracy: 0.5992\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9666 - accuracy: 0.6004\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9685 - accuracy: 0.5997\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9712 - accuracy: 0.6014\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9679 - accuracy: 0.5986\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9649 - accuracy: 0.5998\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9690 - accuracy: 0.5976\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9653 - accuracy: 0.6048\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9670 - accuracy: 0.6000\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9640 - accuracy: 0.6054\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9691 - accuracy: 0.6011\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9615 - accuracy: 0.5998\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9682 - accuracy: 0.5961\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9636 - accuracy: 0.6019\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9634 - accuracy: 0.6021\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9639 - accuracy: 0.6008\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9692 - accuracy: 0.5992\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9651 - accuracy: 0.5972\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9604 - accuracy: 0.6039\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9631 - accuracy: 0.6025\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9630 - accuracy: 0.6011\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9669 - accuracy: 0.5966\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9629 - accuracy: 0.6009\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9675 - accuracy: 0.6016\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9641 - accuracy: 0.6026\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9608 - accuracy: 0.6045\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9627 - accuracy: 0.6036\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9676 - accuracy: 0.6000\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9640 - accuracy: 0.6010\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9688 - accuracy: 0.5996\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9619 - accuracy: 0.6042\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9658 - accuracy: 0.6013\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9697 - accuracy: 0.5960\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9602 - accuracy: 0.6022\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9647 - accuracy: 0.6036\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9669 - accuracy: 0.5980\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9675 - accuracy: 0.6051\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9623 - accuracy: 0.6019\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9654 - accuracy: 0.6044\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9689 - accuracy: 0.5979\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9583 - accuracy: 0.6082\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9689 - accuracy: 0.5984\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9644 - accuracy: 0.6012\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9599 - accuracy: 0.6025\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9599 - accuracy: 0.6042\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9547 - accuracy: 0.6057\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9657 - accuracy: 0.5993\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9652 - accuracy: 0.6019\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9665 - accuracy: 0.6000\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9648 - accuracy: 0.6019\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9609 - accuracy: 0.5987\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9612 - accuracy: 0.6105\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9561 - accuracy: 0.6068\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9603 - accuracy: 0.6045\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9633 - accuracy: 0.6036\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9600 - accuracy: 0.6053\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9589 - accuracy: 0.6028\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9530 - accuracy: 0.6055\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9616 - accuracy: 0.6025\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9572 - accuracy: 0.6075\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9592 - accuracy: 0.6038\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9614 - accuracy: 0.6022\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9559 - accuracy: 0.6012\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9605 - accuracy: 0.6015\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9610 - accuracy: 0.6039\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9647 - accuracy: 0.6053\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9678 - accuracy: 0.6016\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9658 - accuracy: 0.6042\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9612 - accuracy: 0.6028\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9565 - accuracy: 0.6061\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9564 - accuracy: 0.6074\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9608 - accuracy: 0.6053\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9494 - accuracy: 0.6049\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9608 - accuracy: 0.6048\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9623 - accuracy: 0.5989\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9576 - accuracy: 0.6047\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9627 - accuracy: 0.6014\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9572 - accuracy: 0.6067\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9559 - accuracy: 0.6050\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9645 - accuracy: 0.6062\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9592 - accuracy: 0.6031\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9607 - accuracy: 0.6059\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9586 - accuracy: 0.6036\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9582 - accuracy: 0.6055\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9598 - accuracy: 0.6056\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9645 - accuracy: 0.6030\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9548 - accuracy: 0.6070\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9525 - accuracy: 0.6079\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9551 - accuracy: 0.6077\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9537 - accuracy: 0.6073\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9632 - accuracy: 0.6010\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9576 - accuracy: 0.6094\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9572 - accuracy: 0.6053\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9549 - accuracy: 0.6055\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9557 - accuracy: 0.6037\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9539 - accuracy: 0.6042\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9573 - accuracy: 0.6062\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9488 - accuracy: 0.6078\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9549 - accuracy: 0.6066\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9565 - accuracy: 0.6057\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9593 - accuracy: 0.6003\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9571 - accuracy: 0.6069\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9584 - accuracy: 0.6049\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9541 - accuracy: 0.6079\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9592 - accuracy: 0.6027\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9532 - accuracy: 0.6093\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9565 - accuracy: 0.6028\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9557 - accuracy: 0.6072\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9521 - accuracy: 0.6034\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9559 - accuracy: 0.6052\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9552 - accuracy: 0.6067\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9577 - accuracy: 0.6066\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9566 - accuracy: 0.6066\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9527 - accuracy: 0.6083\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9519 - accuracy: 0.6044\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9572 - accuracy: 0.6031\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9529 - accuracy: 0.6053\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9535 - accuracy: 0.6060\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9551 - accuracy: 0.6075\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9523 - accuracy: 0.6034\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9504 - accuracy: 0.6055\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9573 - accuracy: 0.6055\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9524 - accuracy: 0.6037\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9498 - accuracy: 0.6101\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9548 - accuracy: 0.6050\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9434 - accuracy: 0.6087\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9510 - accuracy: 0.6113\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9553 - accuracy: 0.6039\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9524 - accuracy: 0.6107\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9538 - accuracy: 0.6062\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9471 - accuracy: 0.6102\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9469 - accuracy: 0.6095\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9509 - accuracy: 0.6112\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9616 - accuracy: 0.6029\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9539 - accuracy: 0.6056\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9541 - accuracy: 0.6039\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9519 - accuracy: 0.6039\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9572 - accuracy: 0.6049\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9488 - accuracy: 0.6095\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9494 - accuracy: 0.6074\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9478 - accuracy: 0.6107\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9440 - accuracy: 0.6079\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9490 - accuracy: 0.6041\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9477 - accuracy: 0.6063\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9507 - accuracy: 0.6054\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9491 - accuracy: 0.6080\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9523 - accuracy: 0.6081\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9497 - accuracy: 0.6090\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9558 - accuracy: 0.6034\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9482 - accuracy: 0.6060\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9512 - accuracy: 0.6076\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9570 - accuracy: 0.6019\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9483 - accuracy: 0.6088\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9490 - accuracy: 0.6087\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9468 - accuracy: 0.6115\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9508 - accuracy: 0.6046\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9525 - accuracy: 0.6059\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9526 - accuracy: 0.6104\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9506 - accuracy: 0.6104\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9530 - accuracy: 0.6054\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9472 - accuracy: 0.6033\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9457 - accuracy: 0.6088\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9488 - accuracy: 0.6093\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9412 - accuracy: 0.6126\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9462 - accuracy: 0.6142\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9605 - accuracy: 0.6054\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9484 - accuracy: 0.6064\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9401 - accuracy: 0.6088\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9453 - accuracy: 0.6119\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9492 - accuracy: 0.6081\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9508 - accuracy: 0.6102\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9479 - accuracy: 0.6071\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9515 - accuracy: 0.6054\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9454 - accuracy: 0.6101\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9489 - accuracy: 0.6070\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9461 - accuracy: 0.6071\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9456 - accuracy: 0.6126\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9509 - accuracy: 0.6077\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9439 - accuracy: 0.6121\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9438 - accuracy: 0.6079\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9553 - accuracy: 0.6073\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9461 - accuracy: 0.6090\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9467 - accuracy: 0.6086\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9497 - accuracy: 0.6066\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9426 - accuracy: 0.6085\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9482 - accuracy: 0.6072\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9453 - accuracy: 0.6069\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9449 - accuracy: 0.6131\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9448 - accuracy: 0.6080\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9434 - accuracy: 0.6089\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9443 - accuracy: 0.6096\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9481 - accuracy: 0.6101\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9394 - accuracy: 0.6171\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9463 - accuracy: 0.6134\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9433 - accuracy: 0.6104\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9466 - accuracy: 0.6119\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9450 - accuracy: 0.6109\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9461 - accuracy: 0.6086\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9462 - accuracy: 0.6112\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9470 - accuracy: 0.6057\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9419 - accuracy: 0.6112\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9418 - accuracy: 0.6109\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9471 - accuracy: 0.6127\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9429 - accuracy: 0.6109\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9413 - accuracy: 0.6124\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9444 - accuracy: 0.6093\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9426 - accuracy: 0.6114\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9412 - accuracy: 0.6099\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9482 - accuracy: 0.6075\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9437 - accuracy: 0.6120\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9506 - accuracy: 0.6080\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9506 - accuracy: 0.6085\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9438 - accuracy: 0.6133\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9445 - accuracy: 0.6129\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9453 - accuracy: 0.6090\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9428 - accuracy: 0.6090\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9462 - accuracy: 0.6070\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9485 - accuracy: 0.6082\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9477 - accuracy: 0.6073\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9423 - accuracy: 0.6106\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9380 - accuracy: 0.6144\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9470 - accuracy: 0.6080\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9478 - accuracy: 0.6052\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9405 - accuracy: 0.6105\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9440 - accuracy: 0.6132\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9425 - accuracy: 0.6131\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9362 - accuracy: 0.6142\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9407 - accuracy: 0.6096\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9440 - accuracy: 0.6089\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9435 - accuracy: 0.6114\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9397 - accuracy: 0.6134\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9457 - accuracy: 0.6104\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9400 - accuracy: 0.6109\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9352 - accuracy: 0.6158\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9408 - accuracy: 0.6113\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9419 - accuracy: 0.6120\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9402 - accuracy: 0.6118\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9519 - accuracy: 0.6039\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9430 - accuracy: 0.6081\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9379 - accuracy: 0.6122\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9412 - accuracy: 0.6081\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9390 - accuracy: 0.6128\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9311 - accuracy: 0.6159\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9410 - accuracy: 0.6114\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9497 - accuracy: 0.6132\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9352 - accuracy: 0.6127\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9425 - accuracy: 0.6112\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9354 - accuracy: 0.6141\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9456 - accuracy: 0.6143\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9381 - accuracy: 0.6104\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9413 - accuracy: 0.6119\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9411 - accuracy: 0.6130\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9403 - accuracy: 0.6137\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9384 - accuracy: 0.6133\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9450 - accuracy: 0.6100\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9401 - accuracy: 0.6095\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9417 - accuracy: 0.6121\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9402 - accuracy: 0.6135\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9382 - accuracy: 0.6137\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9385 - accuracy: 0.6135\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9419 - accuracy: 0.6128\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9395 - accuracy: 0.6140\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9397 - accuracy: 0.6118\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9401 - accuracy: 0.6109\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9417 - accuracy: 0.6128\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9394 - accuracy: 0.6113\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9343 - accuracy: 0.6154\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9341 - accuracy: 0.6148\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9349 - accuracy: 0.6132\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9357 - accuracy: 0.6122\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9409 - accuracy: 0.6144\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9375 - accuracy: 0.6143\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9425 - accuracy: 0.6127\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9383 - accuracy: 0.6139\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9381 - accuracy: 0.6139\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9428 - accuracy: 0.6116\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9386 - accuracy: 0.6126\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9359 - accuracy: 0.6114\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9367 - accuracy: 0.6111\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9382 - accuracy: 0.6125\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9399 - accuracy: 0.6103\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9390 - accuracy: 0.6130\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9358 - accuracy: 0.6107\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9373 - accuracy: 0.6133\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9418 - accuracy: 0.6105\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9411 - accuracy: 0.6080\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9425 - accuracy: 0.6137\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9429 - accuracy: 0.6095\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9401 - accuracy: 0.6131\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9279 - accuracy: 0.6185\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9347 - accuracy: 0.6136\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9385 - accuracy: 0.6166\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9404 - accuracy: 0.6176\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9318 - accuracy: 0.6153\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9400 - accuracy: 0.6121\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9322 - accuracy: 0.6145\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9395 - accuracy: 0.6098\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9369 - accuracy: 0.6132\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9336 - accuracy: 0.6112\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9404 - accuracy: 0.6097\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9343 - accuracy: 0.6135\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9334 - accuracy: 0.6176\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9365 - accuracy: 0.6119\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9392 - accuracy: 0.6125\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9341 - accuracy: 0.6184\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9418 - accuracy: 0.6117\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9373 - accuracy: 0.6147\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9350 - accuracy: 0.6159\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9352 - accuracy: 0.6127\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9353 - accuracy: 0.6133\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9361 - accuracy: 0.6105\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9333 - accuracy: 0.6158\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9335 - accuracy: 0.6152\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9402 - accuracy: 0.6138\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9282 - accuracy: 0.6192\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9299 - accuracy: 0.6155\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9383 - accuracy: 0.6132\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9345 - accuracy: 0.6137\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9347 - accuracy: 0.6127\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9312 - accuracy: 0.6151\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9302 - accuracy: 0.6168\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9313 - accuracy: 0.6222\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9304 - accuracy: 0.6156\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9371 - accuracy: 0.6154\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9336 - accuracy: 0.6158\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9265 - accuracy: 0.6166\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9286 - accuracy: 0.6165\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9342 - accuracy: 0.6159\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9353 - accuracy: 0.6152\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9350 - accuracy: 0.6136\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9366 - accuracy: 0.6114\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9298 - accuracy: 0.6154\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9323 - accuracy: 0.6158\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9376 - accuracy: 0.6111\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9365 - accuracy: 0.6125\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9354 - accuracy: 0.6138\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9371 - accuracy: 0.6113\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9290 - accuracy: 0.6157\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9351 - accuracy: 0.6117\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9359 - accuracy: 0.6152\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9363 - accuracy: 0.6125\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9322 - accuracy: 0.6111\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9358 - accuracy: 0.6159\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9360 - accuracy: 0.6126\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9318 - accuracy: 0.6163\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9321 - accuracy: 0.6114\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9361 - accuracy: 0.6118\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9376 - accuracy: 0.6125\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9303 - accuracy: 0.6152\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9307 - accuracy: 0.6168\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9314 - accuracy: 0.6180\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9283 - accuracy: 0.6150\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9296 - accuracy: 0.6156\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9301 - accuracy: 0.6180\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9379 - accuracy: 0.6136\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9315 - accuracy: 0.6171\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9353 - accuracy: 0.6191\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9330 - accuracy: 0.6187\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9339 - accuracy: 0.6165\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9321 - accuracy: 0.6186\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9294 - accuracy: 0.6168\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9295 - accuracy: 0.6160\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9314 - accuracy: 0.6181\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9326 - accuracy: 0.6158\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9290 - accuracy: 0.6125\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9326 - accuracy: 0.6159\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9269 - accuracy: 0.6144\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9303 - accuracy: 0.6191\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9312 - accuracy: 0.6140\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9324 - accuracy: 0.6156\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9350 - accuracy: 0.6154\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9277 - accuracy: 0.6195\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9332 - accuracy: 0.6136\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9317 - accuracy: 0.6178\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9304 - accuracy: 0.6163\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9367 - accuracy: 0.6157\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9303 - accuracy: 0.6161\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9285 - accuracy: 0.6145\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9378 - accuracy: 0.6104\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9272 - accuracy: 0.6143\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9250 - accuracy: 0.6152\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9273 - accuracy: 0.6170\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9273 - accuracy: 0.6165\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9284 - accuracy: 0.6174\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9323 - accuracy: 0.6151\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9293 - accuracy: 0.6194\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9262 - accuracy: 0.6156\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9325 - accuracy: 0.6171\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9287 - accuracy: 0.6211\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9315 - accuracy: 0.6183\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9303 - accuracy: 0.6182\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9300 - accuracy: 0.6191\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9297 - accuracy: 0.6190\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9277 - accuracy: 0.6175\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9293 - accuracy: 0.6157\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9296 - accuracy: 0.6138\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9316 - accuracy: 0.6146\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9300 - accuracy: 0.6145\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9256 - accuracy: 0.6198\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9301 - accuracy: 0.6159\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9274 - accuracy: 0.6189\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9248 - accuracy: 0.6174\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9262 - accuracy: 0.6124\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9236 - accuracy: 0.6211\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9263 - accuracy: 0.6192\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9300 - accuracy: 0.6154\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9258 - accuracy: 0.6184\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9302 - accuracy: 0.6160\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9297 - accuracy: 0.6203\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9309 - accuracy: 0.6161\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9295 - accuracy: 0.6164\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9269 - accuracy: 0.6143\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9223 - accuracy: 0.6172\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9286 - accuracy: 0.6152\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9279 - accuracy: 0.6163\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9277 - accuracy: 0.6188\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9285 - accuracy: 0.6161\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9290 - accuracy: 0.6179\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9255 - accuracy: 0.6223\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9317 - accuracy: 0.6190\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9269 - accuracy: 0.6189\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9268 - accuracy: 0.6194\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9304 - accuracy: 0.6182\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9250 - accuracy: 0.6203\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9239 - accuracy: 0.6188\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9234 - accuracy: 0.6190\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9302 - accuracy: 0.6188\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9199 - accuracy: 0.6198\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9265 - accuracy: 0.6168\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9227 - accuracy: 0.6193\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9260 - accuracy: 0.6194\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9264 - accuracy: 0.6192\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9316 - accuracy: 0.6139\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9263 - accuracy: 0.6211\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9220 - accuracy: 0.6211\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9257 - accuracy: 0.6200\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9230 - accuracy: 0.6195\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9281 - accuracy: 0.6200\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9240 - accuracy: 0.6143\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9207 - accuracy: 0.6220\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9280 - accuracy: 0.6176\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9212 - accuracy: 0.6220\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9269 - accuracy: 0.6168\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9263 - accuracy: 0.6191\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9291 - accuracy: 0.6187\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9233 - accuracy: 0.6170\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9238 - accuracy: 0.6221\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9227 - accuracy: 0.6172\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9242 - accuracy: 0.6187\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9246 - accuracy: 0.6194\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9265 - accuracy: 0.6164\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9254 - accuracy: 0.6209\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 1s 3ms/step - loss: 0.9239 - accuracy: 0.6184\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9295 - accuracy: 0.6176\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9233 - accuracy: 0.6204\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9246 - accuracy: 0.6198\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9283 - accuracy: 0.6189\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9224 - accuracy: 0.6232\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9258 - accuracy: 0.6200\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9294 - accuracy: 0.6144\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9292 - accuracy: 0.6173\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9221 - accuracy: 0.6213\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9222 - accuracy: 0.6274\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9209 - accuracy: 0.6219\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9233 - accuracy: 0.6203\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9286 - accuracy: 0.6169\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9176 - accuracy: 0.6217\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9235 - accuracy: 0.6229\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.9257 - accuracy: 0.6183\n",
      "576/576 [==============================] - 2s 1ms/step - loss: 0.7881 - accuracy: 0.6841\n",
      "Train Loss: 0.7881\n",
      "Train Accuracy: 0.6841\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.8689 - accuracy: 0.6500\n",
      "Test Loss: 0.8689\n",
      "Test Accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# DataFrame을 무작위로 섞기\n",
    "df_shuffled = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# 데이터를 입력 특성 (X)과 타겟 변수 (y)로 분할하기\n",
    "X = df_shuffled[['scaled_gx', 'scaled_gy', 'scaled_gz']].values\n",
    "y = df_shuffled['label'].values\n",
    "\n",
    "# 레이블을 인코딩하기 위해 LabelEncoder 사용\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 인코딩된 레이블을 원-핫 인코딩으로 변환하기\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# 입력 특성을 LSTM 모델의 예상 형태로 재구성\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(3, 1), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# LSTM 모델 훈련\n",
    "model.fit(X_train_reshaped, y_train, epochs=1000, batch_size=32)\n",
    "\n",
    "# 훈련 데이터에서 모델 평가\n",
    "train_loss, train_accuracy = model.evaluate(X_train_reshaped, y_train)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# 테스트 데이터에서 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:54:28.443843300Z",
     "start_time": "2023-06-07T06:32:37.542642200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling1d_3\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d_3/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d_3/ExpandDims)' with input shapes: [?,1,1,32].\n\nCall arguments received by layer \"max_pooling1d_3\" (type MaxPooling1D):\n  • inputs=tf.Tensor(shape=(None, 1, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 24\u001B[0m\n\u001B[0;32m     22\u001B[0m model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mReshape((\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m), input_shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m3\u001B[39m,)))\n\u001B[0;32m     23\u001B[0m model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mConv1D(\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m3\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m---> 24\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMaxPooling1D\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpool_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mConv1D(\u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m3\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m     26\u001B[0m model\u001B[38;5;241m.\u001B[39madd(layers\u001B[38;5;241m.\u001B[39mMaxPooling1D(pool_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001B[0m, in \u001B[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_setattr_tracking \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 205\u001B[0m   result \u001B[38;5;241m=\u001B[39m method(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    207\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_setattr_tracking \u001B[38;5;241m=\u001B[39m previous_value  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:6493\u001B[0m, in \u001B[0;36mpool2d\u001B[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001B[0m\n\u001B[0;32m   6490\u001B[0m     pool_size \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m+\u001B[39m pool_size\n\u001B[0;32m   6492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pool_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 6493\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_pool\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   6494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpool_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf_data_format\u001B[49m\n\u001B[0;32m   6495\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6496\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m pool_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavg\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   6497\u001B[0m     x \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mavg_pool(\n\u001B[0;32m   6498\u001B[0m         x, pool_size, strides, padding\u001B[38;5;241m=\u001B[39mpadding, data_format\u001B[38;5;241m=\u001B[39mtf_data_format\n\u001B[0;32m   6499\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Exception encountered when calling layer \"max_pooling1d_3\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d_3/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d_3/ExpandDims)' with input shapes: [?,1,1,32].\n\nCall arguments received by layer \"max_pooling1d_3\" (type MaxPooling1D):\n  • inputs=tf.Tensor(shape=(None, 1, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 데이터 전처리\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# 입력 및 출력 데이터 생성\n",
    "X = df[['scaled_gx', 'scaled_gy', 'scaled_gz']].values\n",
    "y = df['label_encoded'].values\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 생성\n",
    "model = models.Sequential()\n",
    "model.add(layers.Reshape((3, 1), input_shape=(3,)))\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 입력 데이터 형태 조정\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "_, train_accuracy = model.evaluate(X_train, y_train)\n",
    "_, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print('Train Accuracy:', train_accuracy)\n",
    "print('Test Accuracy:', test_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T07:54:41.020592400Z",
     "start_time": "2023-06-07T07:54:40.932636400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3651\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 463166",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 69\u001B[0m\n\u001B[0;32m     65\u001B[0m gz_values\u001B[38;5;241m.\u001B[39mappend(gz_value)\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(gx_values) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m     \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     70\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: user_ID,\n\u001B[0;32m     71\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrial_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: trial_ID,\n\u001B[0;32m     72\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_ID\u001B[39m\u001B[38;5;124m'\u001B[39m: task_ID,\n\u001B[0;32m     73\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgx\u001B[39m\u001B[38;5;124m'\u001B[39m: gx_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m     74\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgy\u001B[39m\u001B[38;5;124m'\u001B[39m: gy_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m     75\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgz\u001B[39m\u001B[38;5;124m'\u001B[39m: gz_values[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m     76\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m: label\n\u001B[0;32m     77\u001B[0m     }\n\u001B[0;32m     78\u001B[0m     record_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     79\u001B[0m     gx_values \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:845\u001B[0m, in \u001B[0;36m_LocationIndexer.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m    843\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    844\u001B[0m     key \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m--> 845\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_setitem_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_valid_setitem_indexer(key)\n\u001B[0;32m    848\u001B[0m iloc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39miloc\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001B[0m, in \u001B[0;36m_LocationIndexer._get_setitem_indexer\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    712\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mrange\u001B[39m):\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;66;03m# GH#45479 test_loc_setitem_range_key\u001B[39;00m\n\u001B[0;32m    714\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m--> 716\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_to_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1397\u001B[0m, in \u001B[0;36m_LocIndexer._convert_to_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_scalar(key) \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(labels, MultiIndex) \u001B[38;5;129;01mand\u001B[39;00m is_hashable(key)):\n\u001B[0;32m   1393\u001B[0m     \u001B[38;5;66;03m# Otherwise get_loc will raise InvalidIndexError\u001B[39;00m\n\u001B[0;32m   1394\u001B[0m \n\u001B[0;32m   1395\u001B[0m     \u001B[38;5;66;03m# if we are a label return me\u001B[39;00m\n\u001B[0;32m   1396\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1397\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlabels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1398\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m:\n\u001B[0;32m   1399\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(labels, MultiIndex):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3650\u001B[0m casted_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_indexer(key)\n\u001B[0;32m   3651\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m   3654\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = \"../data/SisFall_dataset\"\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D03, D05, D07, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D03', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    for line in lines:\n",
    "                        # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                        fields = line.strip().split(',')\n",
    "\n",
    "                        # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                        gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                        gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                        gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                        gx_values.append(gx_value)\n",
    "                        gy_values.append(gy_value)\n",
    "                        gz_values.append(gz_value)\n",
    "\n",
    "                        if len(gx_values) == 1:\n",
    "                            # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                            df.loc[len(df)] = {\n",
    "                                'user_ID': user_ID,\n",
    "                                'trial_ID': trial_ID,\n",
    "                                'task_ID': task_ID,\n",
    "                                'gx': gx_values[0],\n",
    "                                'gy': gy_values[0],\n",
    "                                'gz': gz_values[0],\n",
    "                                'label': label\n",
    "                            }\n",
    "                            record_count += 1\n",
    "                            gx_values = []\n",
    "                            gy_values = []\n",
    "                            gz_values = []\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T00:51:13.521077900Z",
     "start_time": "2023-06-07T23:27:51.720539600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 59\u001B[0m\n\u001B[0;32m     56\u001B[0m fields \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# gx, gy, gz 값 얻기 및 변환 계산\u001B[39;00m\n\u001B[1;32m---> 59\u001B[0m gx_value \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m Range \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m Resolution)) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[43mfields\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[0;32m     60\u001B[0m gy_value \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m Range \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m Resolution)) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mfloat\u001B[39m(fields[\u001B[38;5;241m4\u001B[39m])\n\u001B[0;32m     61\u001B[0m gz_value \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m Range \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m Resolution)) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mfloat\u001B[39m(fields[\u001B[38;5;241m5\u001B[39m])\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = \"../data/SisFall_dataset\"\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D03, D05, D07, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D03', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    # Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    for i, line in enumerate(lines):\n",
    "                        # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                        fields = line.strip().split(',')\n",
    "\n",
    "                        # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                        gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                        gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                        gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                        gx_values.append(gx_value)\n",
    "                        gy_values.append(gy_value)\n",
    "                        gz_values.append(gz_value)\n",
    "\n",
    "                        if i % 10 == 0:  # 1, 11, 21, 31번째 행만 처리\n",
    "                            # 1, 11, 21, 31번째 행의 레코드를 DataFrame에 추가\n",
    "                            df.loc[len(df)] = {\n",
    "                                'user_ID': user_ID,\n",
    "                                'trial_ID': trial_ID,\n",
    "                                'task_ID': task_ID,\n",
    "                                'gx': gx_value,\n",
    "                                'gy': gy_value,\n",
    "                                'gz': gz_value,\n",
    "                                'label': label\n",
    "                            }\n",
    "                            record_count += 1\n",
    "\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T01:06:36.984594800Z",
     "start_time": "2023-06-08T00:51:19.324649200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz'])\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = \"../data/SisFall_dataset\"\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D03, D05, D07, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D03', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 DataFrame에 추가\n",
    "                    for i, line in enumerate(lines):\n",
    "                        if i % 10 == 0:  # 1, 11, 21, 31번째 행만 처리\n",
    "                            # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                            fields = line.strip().split(',')\n",
    "\n",
    "                            if len(fields) >= 6:  # 필드 수 확인\n",
    "                                # gx, gy, gz 값 얻기\n",
    "                                gx = float(fields[3])\n",
    "                                gy = float(fields[4])\n",
    "                                gz = float(fields[5])\n",
    "\n",
    "                                # 1, 11, 21, 31번째 행의 레코드를 DataFrame에 추가\n",
    "                                df.loc[len(df)] = {\n",
    "                                    'user_ID': user_ID,\n",
    "                                    'trial_ID': trial_ID,\n",
    "                                    'task_ID': task_ID,\n",
    "                                    'gx': gx,\n",
    "                                    'gy': gy,\n",
    "                                    'gz': gz\n",
    "                                }\n",
    "                                record_count += 1\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_ID trial_ID task_ID         gx         gy         gz\n",
      "0         SA01      R01     D01  -1.098633 -30.761719 -21.484375\n",
      "1         SA01      R01     D01 -10.864258 -46.752930  -3.173828\n",
      "2         SA01      R01     D01  31.860352 -22.216797   8.056641\n",
      "3         SA01      R01     D01   2.624512 -11.352539  29.052734\n",
      "4         SA01      R01     D01   7.263184  15.869141  26.184082\n",
      "...        ...      ...     ...        ...        ...        ...\n",
      "331797    SE15      R05     D07  -1.281738   3.601074  -0.366211\n",
      "331798    SE15      R05     D07  -1.586914   3.295898  -0.610352\n",
      "331799    SE15      R05     D07  -1.586914   3.173828  -0.915527\n",
      "331800    SE15      R05     D07  -1.525879   2.868652  -0.976562\n",
      "331801    SE15      R05     D07  -1.281738   3.051758  -0.915527\n",
      "\n",
      "[331802 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = \"../data/SisFall_dataset\"\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D03, D05, D07, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D03', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    #Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    # 데이터 파싱 및 DataFrame에 추가\n",
    "                    for i, line in enumerate(lines):\n",
    "                        if i % 10 == 0:  # 1, 11, 21, 31번째 행만 처리\n",
    "                            # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                            fields = line.strip().split(',')\n",
    "\n",
    "                            if len(fields) >= 6:  # 필드 수 확인\n",
    "                                # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                gx_values.append(gx_value)\n",
    "                                gy_values.append(gy_value)\n",
    "                                gz_values.append(gz_value)\n",
    "\n",
    "                                if len(gx_values) == 1:\n",
    "                                    # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                    df.loc[len(df)] = {\n",
    "                                        'user_ID': user_ID,\n",
    "                                        'trial_ID': trial_ID,\n",
    "                                        'task_ID': task_ID,\n",
    "                                        'gx': gx_values[0],\n",
    "                                        'gy': gy_values[0],\n",
    "                                        'gz': gz_values[0],\n",
    "                                        'label': label\n",
    "                                    }\n",
    "                                    record_count += 1\n",
    "                                    gx_values = []\n",
    "                                    gy_values = []\n",
    "                                    gz_values = []\n",
    "\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T03:12:05.923687200Z",
     "start_time": "2023-06-08T02:29:44.255221400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_ID trial_ID task_ID         gx         gy         gz     label\n",
      "0         SA01      R01     D01  -1.098633 -30.761719 -21.484375   walking\n",
      "1         SA01      R01     D01 -10.864258 -46.752930  -3.173828   walking\n",
      "2         SA01      R01     D01  31.860352 -22.216797   8.056641   walking\n",
      "3         SA01      R01     D01   2.624512 -11.352539  29.052734   walking\n",
      "4         SA01      R01     D01   7.263184  15.869141  26.184082   walking\n",
      "...        ...      ...     ...        ...        ...        ...       ...\n",
      "331797    SE15      R05     D07  -1.281738   3.601074  -0.366211  standing\n",
      "331798    SE15      R05     D07  -1.586914   3.295898  -0.610352  standing\n",
      "331799    SE15      R05     D07  -1.586914   3.173828  -0.915527  standing\n",
      "331800    SE15      R05     D07  -1.525879   2.868652  -0.976562  standing\n",
      "331801    SE15      R05     D07  -1.281738   3.051758  -0.915527  standing\n",
      "\n",
      "[331802 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame 초기화\n",
    "df = pd.DataFrame(columns=['user_ID', 'trial_ID', 'task_ID', 'gx', 'gy', 'gz', 'label'])\n",
    "\n",
    "# task_id와 매핑되는 label 정보 생성\n",
    "label_mapping = {\n",
    "    'D01': 'walking',\n",
    "    'D03': 'jogging',\n",
    "    'D05': 'stairs_walking',\n",
    "    'D07': 'standing',\n",
    "    'F06': 'fall'\n",
    "}\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "data_folder = \"../data/SisFall_dataset\"\n",
    "\n",
    "# 폴더 내의 파일들을 확인하고 처리\n",
    "record_count = 0  # 전체 파일에서의 레코드 개수\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        user_ID = dir_name\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # 파일 경로\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "                # 파일 이름에 대한 정보\n",
    "                activity, _, trial_ID_with_extension = file_name.split('_')\n",
    "                trial_ID = trial_ID_with_extension[:-4]  # .txt 제거\n",
    "\n",
    "                # task_id가 D01, D03, D05, D07, F06인 경우에만 처리\n",
    "                if activity in ['D01', 'D03', 'D05', 'D07', 'F06']:\n",
    "                    # task_id에 해당하는 label 정보\n",
    "                    task_ID = activity\n",
    "                    label = label_mapping[task_ID]\n",
    "\n",
    "                    #Angular velocity 변환을 위한 공식에 사용되는 값들\n",
    "                    Range = 2000  # 예시 값을 사용\n",
    "                    Resolution = 16  # 예시 값을 사용\n",
    "\n",
    "                    # 파일에서 데이터를 읽어와서 처리\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                    # 데이터 파싱 및 계산\n",
    "                    gx_values = []\n",
    "                    gy_values = []\n",
    "                    gz_values = []\n",
    "\n",
    "                    # 데이터 파싱 및 DataFrame에 추가\n",
    "                    for i, line in enumerate(lines):\n",
    "                        if i % 10 == 0:  # 1, 11, 21, 31번째 행만 처리\n",
    "                            # 쉼표를 기준으로 줄을 분리하여 필드의 값을 가져오기\n",
    "                            fields = line.strip().split(',')\n",
    "\n",
    "                            if len(fields) >= 6:  # 필드 수 확인\n",
    "                                # gx, gy, gz 값 얻기 및 변환 계산\n",
    "                                gx_value = (2 * Range / (2 ** Resolution)) * float(fields[3])\n",
    "                                gy_value = (2 * Range / (2 ** Resolution)) * float(fields[4])\n",
    "                                gz_value = (2 * Range / (2 ** Resolution)) * float(fields[5])\n",
    "\n",
    "                                gx_values.append(gx_value)\n",
    "                                gy_values.append(gy_value)\n",
    "                                gz_values.append(gz_value)\n",
    "\n",
    "                                if len(gx_values) == 1:\n",
    "                                    # 한 줄의 레코드 처리가 완료되었으므로 DataFrame에 추가\n",
    "                                    df.loc[len(df)] = {\n",
    "                                        'user_ID': user_ID,\n",
    "                                        'trial_ID': trial_ID,\n",
    "                                        'task_ID': task_ID,\n",
    "                                        'gx': gx_values[0],\n",
    "                                        'gy': gy_values[0],\n",
    "                                        'gz': gz_values[0],\n",
    "                                        'label': label\n",
    "                                    }\n",
    "                                    record_count += 1\n",
    "                                    gx_values = []\n",
    "                                    gy_values = []\n",
    "                                    gz_values = []\n",
    "\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T04:12:40.914000700Z",
     "start_time": "2023-06-08T03:25:48.651322900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_df_re.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = \"../data/SisFall_df_re.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"CSV 파일이 저장되었습니다:\", csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T05:55:04.005336300Z",
     "start_time": "2023-06-08T05:55:02.374276100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_ID trial_ID task_ID         gx         gy         gz    label   \n",
      "0    SA01      R01     D01  -1.098633 -30.761719 -21.484375  walking  \\\n",
      "1    SA01      R01     D01 -10.864258 -46.752930  -3.173828  walking   \n",
      "2    SA01      R01     D01  31.860352 -22.216797   8.056641  walking   \n",
      "3    SA01      R01     D01   2.624512 -11.352539  29.052734  walking   \n",
      "4    SA01      R01     D01   7.263184  15.869141  26.184082  walking   \n",
      "\n",
      "   scaled_gx  scaled_gy  scaled_gz  \n",
      "0   0.015592   0.010843   0.042287  \n",
      "1   0.001771  -0.010123   0.066825  \n",
      "2   0.062238   0.022046   0.081875  \n",
      "3   0.020861   0.036290   0.110011  \n",
      "4   0.027426   0.071980   0.106167  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 인스턴스 생성\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# 'gx', 'gy', 'gz' 열의 데이터 추출\n",
    "data = df[['gx', 'gy', 'gz']].values\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 스케일링된 값을 새로운 열에 저장\n",
    "df['scaled_gx'] = scaled_data[:, 0]\n",
    "df['scaled_gy'] = scaled_data[:, 1]\n",
    "df['scaled_gz'] = scaled_data[:, 2]\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T07:48:54.251299300Z",
     "start_time": "2023-06-08T07:48:54.206742500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 저장되었습니다: ../data/SisFall_df_sc.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_path = \"../data/SisFall_df_sc.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"CSV 파일이 저장되었습니다:\", csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T07:49:12.987227100Z",
     "start_time": "2023-06-08T07:49:10.849799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Danu\\TensorFlow\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.8476 - accuracy: 0.6595\n",
      "Epoch 2/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7481 - accuracy: 0.6978\n",
      "Epoch 3/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7174 - accuracy: 0.7094\n",
      "Epoch 4/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6953 - accuracy: 0.7182\n",
      "Epoch 5/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6763 - accuracy: 0.7250\n",
      "Epoch 6/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6600 - accuracy: 0.7317\n",
      "Epoch 7/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6445 - accuracy: 0.7373\n",
      "Epoch 8/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6307 - accuracy: 0.7426\n",
      "Epoch 9/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6169 - accuracy: 0.7481\n",
      "Epoch 10/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6044 - accuracy: 0.7545\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x254ae128d00>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:35:48.227653500Z",
     "start_time": "2023-06-08T06:34:36.371733300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Danu\\TensorFlow\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.8456 - accuracy: 0.6605\n",
      "Epoch 2/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7501 - accuracy: 0.6962\n",
      "Epoch 3/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7180 - accuracy: 0.7098\n",
      "Epoch 4/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6968 - accuracy: 0.7163\n",
      "Epoch 5/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6786 - accuracy: 0.7248\n",
      "Epoch 6/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6623 - accuracy: 0.7308\n",
      "Epoch 7/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6464 - accuracy: 0.7364\n",
      "Epoch 8/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6319 - accuracy: 0.7424\n",
      "Epoch 9/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6200 - accuracy: 0.7477\n",
      "Epoch 10/10\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6054 - accuracy: 0.7540\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x254cb7d4100>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:41:50.433713400Z",
     "start_time": "2023-06-08T06:40:39.674987500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Danu\\TensorFlow\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.8447 - accuracy: 0.6600\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7475 - accuracy: 0.6986\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7184 - accuracy: 0.7079\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6969 - accuracy: 0.7169\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6784 - accuracy: 0.7246\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6601 - accuracy: 0.7323\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6467 - accuracy: 0.7368\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6318 - accuracy: 0.7430\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6183 - accuracy: 0.7484\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6050 - accuracy: 0.7548\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5924 - accuracy: 0.7588\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5813 - accuracy: 0.7638\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5686 - accuracy: 0.7702\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5570 - accuracy: 0.7750\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5461 - accuracy: 0.7800\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5342 - accuracy: 0.7833\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5240 - accuracy: 0.7880\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5128 - accuracy: 0.7935\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5019 - accuracy: 0.7972\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4922 - accuracy: 0.8005\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4807 - accuracy: 0.8048\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4728 - accuracy: 0.8091\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4624 - accuracy: 0.8135\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4521 - accuracy: 0.8185\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4442 - accuracy: 0.8220\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4337 - accuracy: 0.8258\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4253 - accuracy: 0.8300\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4174 - accuracy: 0.8346\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4080 - accuracy: 0.8378\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4000 - accuracy: 0.8408\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3914 - accuracy: 0.8446\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3839 - accuracy: 0.8477\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3775 - accuracy: 0.8498\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3684 - accuracy: 0.8544\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3641 - accuracy: 0.8550\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3567 - accuracy: 0.8594\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3520 - accuracy: 0.8610\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3441 - accuracy: 0.8646\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3370 - accuracy: 0.8666\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3331 - accuracy: 0.8674\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3265 - accuracy: 0.8711\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3196 - accuracy: 0.8752\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3130 - accuracy: 0.8778\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3089 - accuracy: 0.8780\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3033 - accuracy: 0.8819\n",
      "Epoch 46/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2976 - accuracy: 0.8837\n",
      "Epoch 47/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2948 - accuracy: 0.8850\n",
      "Epoch 48/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2868 - accuracy: 0.8874\n",
      "Epoch 49/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2854 - accuracy: 0.8881\n",
      "Epoch 50/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2801 - accuracy: 0.8908\n",
      "Epoch 51/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2765 - accuracy: 0.8917\n",
      "Epoch 52/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2727 - accuracy: 0.8938\n",
      "Epoch 53/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2688 - accuracy: 0.8947\n",
      "Epoch 54/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2623 - accuracy: 0.8975\n",
      "Epoch 55/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2616 - accuracy: 0.8982\n",
      "Epoch 56/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2559 - accuracy: 0.9005\n",
      "Epoch 57/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2520 - accuracy: 0.9017\n",
      "Epoch 58/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2494 - accuracy: 0.9033\n",
      "Epoch 59/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2456 - accuracy: 0.9049\n",
      "Epoch 60/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2444 - accuracy: 0.9045\n",
      "Epoch 61/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2403 - accuracy: 0.9065\n",
      "Epoch 62/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2378 - accuracy: 0.9084\n",
      "Epoch 63/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2349 - accuracy: 0.9073\n",
      "Epoch 64/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2318 - accuracy: 0.9096\n",
      "Epoch 65/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2313 - accuracy: 0.9102\n",
      "Epoch 66/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2254 - accuracy: 0.9122\n",
      "Epoch 67/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2255 - accuracy: 0.9119\n",
      "Epoch 68/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2211 - accuracy: 0.9148\n",
      "Epoch 69/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2206 - accuracy: 0.9148\n",
      "Epoch 70/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2189 - accuracy: 0.9155\n",
      "Epoch 71/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2135 - accuracy: 0.9178\n",
      "Epoch 72/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2123 - accuracy: 0.9174\n",
      "Epoch 73/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2113 - accuracy: 0.9178\n",
      "Epoch 74/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2079 - accuracy: 0.9190\n",
      "Epoch 75/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2050 - accuracy: 0.9204\n",
      "Epoch 76/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2055 - accuracy: 0.9202\n",
      "Epoch 77/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2028 - accuracy: 0.9215\n",
      "Epoch 78/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2010 - accuracy: 0.9224\n",
      "Epoch 79/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2007 - accuracy: 0.9222\n",
      "Epoch 80/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1964 - accuracy: 0.9233\n",
      "Epoch 81/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1971 - accuracy: 0.9243\n",
      "Epoch 82/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1939 - accuracy: 0.9252\n",
      "Epoch 83/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1912 - accuracy: 0.9257\n",
      "Epoch 84/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1919 - accuracy: 0.9261\n",
      "Epoch 85/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1905 - accuracy: 0.9265\n",
      "Epoch 86/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1860 - accuracy: 0.9283\n",
      "Epoch 87/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1880 - accuracy: 0.9266\n",
      "Epoch 88/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1854 - accuracy: 0.9287\n",
      "Epoch 89/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1817 - accuracy: 0.9299\n",
      "Epoch 90/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1827 - accuracy: 0.9301\n",
      "Epoch 91/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1785 - accuracy: 0.9314\n",
      "Epoch 92/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1780 - accuracy: 0.9313\n",
      "Epoch 93/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1749 - accuracy: 0.9328\n",
      "Epoch 94/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1776 - accuracy: 0.9320\n",
      "Epoch 95/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1805 - accuracy: 0.9307\n",
      "Epoch 96/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1735 - accuracy: 0.9338\n",
      "Epoch 97/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1731 - accuracy: 0.9334\n",
      "Epoch 98/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1695 - accuracy: 0.9351\n",
      "Epoch 99/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1719 - accuracy: 0.9345\n",
      "Epoch 100/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1668 - accuracy: 0.9358\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x254d0a0ff40>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=100, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:50:42.698278100Z",
     "start_time": "2023-06-08T06:41:56.676863500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2072/2072 [==============================] - 7s 2ms/step - loss: 1.5363 - accuracy: 0.3052 - val_loss: 1.3873 - val_accuracy: 0.3980\n",
      "Epoch 2/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 1.2636 - accuracy: 0.4559 - val_loss: 1.2174 - val_accuracy: 0.4922\n",
      "Epoch 3/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 1.1875 - accuracy: 0.4858 - val_loss: 1.1634 - val_accuracy: 0.5111\n",
      "Epoch 4/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 1.1385 - accuracy: 0.5104 - val_loss: 1.0999 - val_accuracy: 0.5325\n",
      "Epoch 5/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 1.0690 - accuracy: 0.5444 - val_loss: 1.0422 - val_accuracy: 0.5645\n",
      "Epoch 6/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 1.0224 - accuracy: 0.5676 - val_loss: 1.0390 - val_accuracy: 0.5488\n",
      "Epoch 7/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.9948 - accuracy: 0.5790 - val_loss: 0.9900 - val_accuracy: 0.5861\n",
      "Epoch 8/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.9722 - accuracy: 0.5925 - val_loss: 0.9628 - val_accuracy: 0.5978\n",
      "Epoch 9/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.9511 - accuracy: 0.6003 - val_loss: 0.9562 - val_accuracy: 0.6003\n",
      "Epoch 10/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.9387 - accuracy: 0.6078 - val_loss: 0.9404 - val_accuracy: 0.6047\n",
      "Epoch 11/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.9313 - accuracy: 0.6090 - val_loss: 0.9374 - val_accuracy: 0.6085\n",
      "Epoch 12/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.9248 - accuracy: 0.6126 - val_loss: 0.9389 - val_accuracy: 0.6079\n",
      "Epoch 13/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.9185 - accuracy: 0.6151 - val_loss: 0.9322 - val_accuracy: 0.6112\n",
      "Epoch 14/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.9120 - accuracy: 0.6194 - val_loss: 0.9322 - val_accuracy: 0.6146\n",
      "Epoch 15/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.9075 - accuracy: 0.6211 - val_loss: 0.9344 - val_accuracy: 0.6010\n",
      "Epoch 16/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.9001 - accuracy: 0.6228 - val_loss: 0.9167 - val_accuracy: 0.6207\n",
      "Epoch 17/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8950 - accuracy: 0.6259 - val_loss: 0.9325 - val_accuracy: 0.6120\n",
      "Epoch 18/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8900 - accuracy: 0.6280 - val_loss: 0.9121 - val_accuracy: 0.6209\n",
      "Epoch 19/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8848 - accuracy: 0.6304 - val_loss: 0.9176 - val_accuracy: 0.6158\n",
      "Epoch 20/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8800 - accuracy: 0.6317 - val_loss: 0.9198 - val_accuracy: 0.6084\n",
      "Epoch 21/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8750 - accuracy: 0.6348 - val_loss: 0.9135 - val_accuracy: 0.6152\n",
      "Epoch 22/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8698 - accuracy: 0.6356 - val_loss: 0.8971 - val_accuracy: 0.6284\n",
      "Epoch 23/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8658 - accuracy: 0.6381 - val_loss: 0.9009 - val_accuracy: 0.6311\n",
      "Epoch 24/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8613 - accuracy: 0.6385 - val_loss: 0.9003 - val_accuracy: 0.6190\n",
      "Epoch 25/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8568 - accuracy: 0.6393 - val_loss: 0.8864 - val_accuracy: 0.6282\n",
      "Epoch 26/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8520 - accuracy: 0.6428 - val_loss: 0.8906 - val_accuracy: 0.6269\n",
      "Epoch 27/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8475 - accuracy: 0.6438 - val_loss: 0.8827 - val_accuracy: 0.6322\n",
      "Epoch 28/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8443 - accuracy: 0.6450 - val_loss: 0.8789 - val_accuracy: 0.6357\n",
      "Epoch 29/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.8390 - accuracy: 0.6479 - val_loss: 0.8784 - val_accuracy: 0.6345\n",
      "Epoch 30/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8359 - accuracy: 0.6499 - val_loss: 0.8746 - val_accuracy: 0.6362\n",
      "Epoch 31/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8312 - accuracy: 0.6504 - val_loss: 0.8772 - val_accuracy: 0.6371\n",
      "Epoch 32/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8260 - accuracy: 0.6535 - val_loss: 0.8721 - val_accuracy: 0.6400\n",
      "Epoch 33/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8234 - accuracy: 0.6543 - val_loss: 0.8759 - val_accuracy: 0.6390\n",
      "Epoch 34/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8184 - accuracy: 0.6554 - val_loss: 0.8658 - val_accuracy: 0.6407\n",
      "Epoch 35/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8151 - accuracy: 0.6571 - val_loss: 0.8652 - val_accuracy: 0.6441\n",
      "Epoch 36/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8107 - accuracy: 0.6589 - val_loss: 0.8673 - val_accuracy: 0.6450\n",
      "Epoch 37/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8070 - accuracy: 0.6613 - val_loss: 0.8602 - val_accuracy: 0.6432\n",
      "Epoch 38/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.8028 - accuracy: 0.6620 - val_loss: 0.8640 - val_accuracy: 0.6410\n",
      "Epoch 39/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.7998 - accuracy: 0.6646 - val_loss: 0.8727 - val_accuracy: 0.6419\n",
      "Epoch 40/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.7975 - accuracy: 0.6647 - val_loss: 0.8580 - val_accuracy: 0.6465\n",
      "Epoch 41/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.7927 - accuracy: 0.6654 - val_loss: 0.8606 - val_accuracy: 0.6422\n",
      "Epoch 42/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7902 - accuracy: 0.6667 - val_loss: 0.8562 - val_accuracy: 0.6465\n",
      "Epoch 43/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7869 - accuracy: 0.6686 - val_loss: 0.8622 - val_accuracy: 0.6437\n",
      "Epoch 44/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7845 - accuracy: 0.6693 - val_loss: 0.8534 - val_accuracy: 0.6478\n",
      "Epoch 45/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7799 - accuracy: 0.6715 - val_loss: 0.8647 - val_accuracy: 0.6397\n",
      "Epoch 46/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7784 - accuracy: 0.6712 - val_loss: 0.8529 - val_accuracy: 0.6469\n",
      "Epoch 47/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.7756 - accuracy: 0.6730 - val_loss: 0.8538 - val_accuracy: 0.6431\n",
      "Epoch 48/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.7723 - accuracy: 0.6745 - val_loss: 0.8544 - val_accuracy: 0.6473\n",
      "Epoch 49/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.7706 - accuracy: 0.6763 - val_loss: 0.8539 - val_accuracy: 0.6509\n",
      "Epoch 50/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.7672 - accuracy: 0.6760 - val_loss: 0.8542 - val_accuracy: 0.6482\n",
      "Epoch 51/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7648 - accuracy: 0.6782 - val_loss: 0.8564 - val_accuracy: 0.6489\n",
      "Epoch 52/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7611 - accuracy: 0.6795 - val_loss: 0.8607 - val_accuracy: 0.6516\n",
      "Epoch 53/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7588 - accuracy: 0.6821 - val_loss: 0.8489 - val_accuracy: 0.6523\n",
      "Epoch 54/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7557 - accuracy: 0.6821 - val_loss: 0.8529 - val_accuracy: 0.6476\n",
      "Epoch 55/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7525 - accuracy: 0.6824 - val_loss: 0.8547 - val_accuracy: 0.6477\n",
      "Epoch 56/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7505 - accuracy: 0.6825 - val_loss: 0.8531 - val_accuracy: 0.6521\n",
      "Epoch 57/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7476 - accuracy: 0.6837 - val_loss: 0.8498 - val_accuracy: 0.6535\n",
      "Epoch 58/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7453 - accuracy: 0.6857 - val_loss: 0.8495 - val_accuracy: 0.6554\n",
      "Epoch 59/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7425 - accuracy: 0.6874 - val_loss: 0.8557 - val_accuracy: 0.6508\n",
      "Epoch 60/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7402 - accuracy: 0.6874 - val_loss: 0.8538 - val_accuracy: 0.6534\n",
      "Epoch 61/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7372 - accuracy: 0.6884 - val_loss: 0.8657 - val_accuracy: 0.6500\n",
      "Epoch 62/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7351 - accuracy: 0.6891 - val_loss: 0.8518 - val_accuracy: 0.6529\n",
      "Epoch 63/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7312 - accuracy: 0.6910 - val_loss: 0.8619 - val_accuracy: 0.6502\n",
      "Epoch 64/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7290 - accuracy: 0.6931 - val_loss: 0.8601 - val_accuracy: 0.6508\n",
      "Epoch 65/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7270 - accuracy: 0.6929 - val_loss: 0.8567 - val_accuracy: 0.6546\n",
      "Epoch 66/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7242 - accuracy: 0.6937 - val_loss: 0.8652 - val_accuracy: 0.6524\n",
      "Epoch 67/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7210 - accuracy: 0.6939 - val_loss: 0.8567 - val_accuracy: 0.6545\n",
      "Epoch 68/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7193 - accuracy: 0.6968 - val_loss: 0.8598 - val_accuracy: 0.6505\n",
      "Epoch 69/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7161 - accuracy: 0.6976 - val_loss: 0.8666 - val_accuracy: 0.6532\n",
      "Epoch 70/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7133 - accuracy: 0.6997 - val_loss: 0.8635 - val_accuracy: 0.6492\n",
      "Epoch 71/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.7108 - accuracy: 0.7007 - val_loss: 0.8575 - val_accuracy: 0.6547\n",
      "Epoch 72/100\n",
      "2072/2072 [==============================] - 6s 3ms/step - loss: 0.7089 - accuracy: 0.7005 - val_loss: 0.8602 - val_accuracy: 0.6539\n",
      "Epoch 73/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.7058 - accuracy: 0.7034 - val_loss: 0.8585 - val_accuracy: 0.6576\n",
      "Epoch 74/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.7034 - accuracy: 0.7039 - val_loss: 0.8623 - val_accuracy: 0.6538\n",
      "Epoch 75/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.7012 - accuracy: 0.7026 - val_loss: 0.8642 - val_accuracy: 0.6500\n",
      "Epoch 76/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.6983 - accuracy: 0.7045 - val_loss: 0.8663 - val_accuracy: 0.6499\n",
      "Epoch 77/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.6962 - accuracy: 0.7064 - val_loss: 0.8697 - val_accuracy: 0.6550\n",
      "Epoch 78/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6933 - accuracy: 0.7087 - val_loss: 0.8696 - val_accuracy: 0.6544\n",
      "Epoch 79/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6906 - accuracy: 0.7103 - val_loss: 0.8712 - val_accuracy: 0.6546\n",
      "Epoch 80/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6881 - accuracy: 0.7101 - val_loss: 0.8703 - val_accuracy: 0.6570\n",
      "Epoch 81/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6867 - accuracy: 0.7109 - val_loss: 0.8721 - val_accuracy: 0.6582\n",
      "Epoch 82/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6834 - accuracy: 0.7132 - val_loss: 0.8690 - val_accuracy: 0.6561\n",
      "Epoch 83/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6820 - accuracy: 0.7125 - val_loss: 0.8706 - val_accuracy: 0.6555\n",
      "Epoch 84/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6792 - accuracy: 0.7136 - val_loss: 0.8726 - val_accuracy: 0.6571\n",
      "Epoch 85/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6762 - accuracy: 0.7147 - val_loss: 0.8856 - val_accuracy: 0.6504\n",
      "Epoch 86/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6743 - accuracy: 0.7164 - val_loss: 0.8768 - val_accuracy: 0.6558\n",
      "Epoch 87/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.6713 - accuracy: 0.7168 - val_loss: 0.8830 - val_accuracy: 0.6534\n",
      "Epoch 88/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.6701 - accuracy: 0.7181 - val_loss: 0.8842 - val_accuracy: 0.6531\n",
      "Epoch 89/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6678 - accuracy: 0.7184 - val_loss: 0.8862 - val_accuracy: 0.6554\n",
      "Epoch 90/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6645 - accuracy: 0.7211 - val_loss: 0.8827 - val_accuracy: 0.6552\n",
      "Epoch 91/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6628 - accuracy: 0.7212 - val_loss: 0.8851 - val_accuracy: 0.6599\n",
      "Epoch 92/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6606 - accuracy: 0.7217 - val_loss: 0.8891 - val_accuracy: 0.6613\n",
      "Epoch 93/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6580 - accuracy: 0.7221 - val_loss: 0.8873 - val_accuracy: 0.6595\n",
      "Epoch 94/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6566 - accuracy: 0.7228 - val_loss: 0.8983 - val_accuracy: 0.6485\n",
      "Epoch 95/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6530 - accuracy: 0.7258 - val_loss: 0.9051 - val_accuracy: 0.6477\n",
      "Epoch 96/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6507 - accuracy: 0.7268 - val_loss: 0.8971 - val_accuracy: 0.6556\n",
      "Epoch 97/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6487 - accuracy: 0.7274 - val_loss: 0.9015 - val_accuracy: 0.6493\n",
      "Epoch 98/100\n",
      "2072/2072 [==============================] - 5s 3ms/step - loss: 0.6464 - accuracy: 0.7295 - val_loss: 0.8928 - val_accuracy: 0.6557\n",
      "Epoch 99/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6451 - accuracy: 0.7282 - val_loss: 0.8990 - val_accuracy: 0.6575\n",
      "Epoch 100/100\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 0.6423 - accuracy: 0.7297 - val_loss: 0.9041 - val_accuracy: 0.6568\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2549669c6d0>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# 데이터를 학습용과 테스트용으로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 설정된 시드를 사용하여 TensorFlow의 재현성 확보\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T08:02:11.490172700Z",
     "start_time": "2023-06-08T07:53:27.188152700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_ID trial_ID task_ID         gx         gy         gz     label   \n",
      "0         SA01      R01     D01  -1.098633 -30.761719 -21.484375   walking  \\\n",
      "1         SA01      R01     D01 -10.864258 -46.752930  -3.173828   walking   \n",
      "2         SA01      R01     D01  31.860352 -22.216797   8.056641   walking   \n",
      "3         SA01      R01     D01   2.624512 -11.352539  29.052734   walking   \n",
      "4         SA01      R01     D01   7.263184  15.869141  26.184082   walking   \n",
      "...        ...      ...     ...        ...        ...        ...       ...   \n",
      "331797    SE15      R05     D07  -1.281738   3.601074  -0.366211  standing   \n",
      "331798    SE15      R05     D07  -1.586914   3.295898  -0.610352  standing   \n",
      "331799    SE15      R05     D07  -1.586914   3.173828  -0.915527  standing   \n",
      "331800    SE15      R05     D07  -1.525879   2.868652  -0.976562  standing   \n",
      "331801    SE15      R05     D07  -1.281738   3.051758  -0.915527  standing   \n",
      "\n",
      "        scaled_gx  scaled_gy  scaled_gz  \n",
      "0        0.015592   0.010843   0.042287  \n",
      "1        0.001771  -0.010123   0.066825  \n",
      "2        0.062238   0.022046   0.081875  \n",
      "3        0.020861   0.036290   0.110011  \n",
      "4        0.027426   0.071980   0.106167  \n",
      "...           ...        ...        ...  \n",
      "331797   0.015333   0.055896   0.070587  \n",
      "331798   0.014901   0.055496   0.070260  \n",
      "331799   0.014901   0.055335   0.069851  \n",
      "331800   0.014987   0.054935   0.069769  \n",
      "331801   0.015333   0.055175   0.069851  \n",
      "\n",
      "[331802 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/SisFall_df_sc.csv\")\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T08:34:15.527158300Z",
     "start_time": "2023-06-08T08:34:14.833423900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1036/1036 [==============================] - 5s 3ms/step - loss: 1.5518 - accuracy: 0.2892 - val_loss: 1.5486 - val_accuracy: 0.2877\n",
      "Epoch 2/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.3602 - accuracy: 0.4109 - val_loss: 1.2887 - val_accuracy: 0.4293\n",
      "Epoch 3/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.2494 - accuracy: 0.4556 - val_loss: 1.2233 - val_accuracy: 0.4604\n",
      "Epoch 4/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.1873 - accuracy: 0.4862 - val_loss: 1.1833 - val_accuracy: 0.4967\n",
      "Epoch 5/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.1649 - accuracy: 0.4979 - val_loss: 1.1632 - val_accuracy: 0.5056\n",
      "Epoch 6/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.1531 - accuracy: 0.5030 - val_loss: 1.1589 - val_accuracy: 0.4871\n",
      "Epoch 7/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.1198 - accuracy: 0.5168 - val_loss: 1.0919 - val_accuracy: 0.5386\n",
      "Epoch 8/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.0679 - accuracy: 0.5389 - val_loss: 1.0494 - val_accuracy: 0.5544\n",
      "Epoch 9/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.0351 - accuracy: 0.5561 - val_loss: 1.0126 - val_accuracy: 0.5741\n",
      "Epoch 10/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 1.0013 - accuracy: 0.5766 - val_loss: 0.9861 - val_accuracy: 0.5832\n",
      "Epoch 11/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9777 - accuracy: 0.5906 - val_loss: 0.9733 - val_accuracy: 0.5922\n",
      "Epoch 12/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9673 - accuracy: 0.5921 - val_loss: 0.9693 - val_accuracy: 0.5934\n",
      "Epoch 13/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9591 - accuracy: 0.5956 - val_loss: 0.9621 - val_accuracy: 0.5975\n",
      "Epoch 14/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9524 - accuracy: 0.6004 - val_loss: 0.9503 - val_accuracy: 0.6080\n",
      "Epoch 15/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9476 - accuracy: 0.6025 - val_loss: 0.9639 - val_accuracy: 0.5942\n",
      "Epoch 16/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9403 - accuracy: 0.6056 - val_loss: 0.9427 - val_accuracy: 0.6092\n",
      "Epoch 17/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9347 - accuracy: 0.6089 - val_loss: 0.9547 - val_accuracy: 0.6066\n",
      "Epoch 18/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9286 - accuracy: 0.6143 - val_loss: 0.9360 - val_accuracy: 0.6118\n",
      "Epoch 19/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9223 - accuracy: 0.6151 - val_loss: 0.9381 - val_accuracy: 0.6092\n",
      "Epoch 20/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9182 - accuracy: 0.6165 - val_loss: 0.9293 - val_accuracy: 0.6127\n",
      "Epoch 21/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9121 - accuracy: 0.6203 - val_loss: 0.9276 - val_accuracy: 0.6128\n",
      "Epoch 22/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9074 - accuracy: 0.6205 - val_loss: 0.9224 - val_accuracy: 0.6189\n",
      "Epoch 23/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.9029 - accuracy: 0.6234 - val_loss: 0.9174 - val_accuracy: 0.6208\n",
      "Epoch 24/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8993 - accuracy: 0.6249 - val_loss: 0.9145 - val_accuracy: 0.6194\n",
      "Epoch 25/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8951 - accuracy: 0.6258 - val_loss: 0.9072 - val_accuracy: 0.6235\n",
      "Epoch 26/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8898 - accuracy: 0.6287 - val_loss: 0.9105 - val_accuracy: 0.6164\n",
      "Epoch 27/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8861 - accuracy: 0.6303 - val_loss: 0.9044 - val_accuracy: 0.6228\n",
      "Epoch 28/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8835 - accuracy: 0.6313 - val_loss: 0.8996 - val_accuracy: 0.6311\n",
      "Epoch 29/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8794 - accuracy: 0.6340 - val_loss: 0.9012 - val_accuracy: 0.6286\n",
      "Epoch 30/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8760 - accuracy: 0.6359 - val_loss: 0.8938 - val_accuracy: 0.6304\n",
      "Epoch 31/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8722 - accuracy: 0.6351 - val_loss: 0.9022 - val_accuracy: 0.6259\n",
      "Epoch 32/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8675 - accuracy: 0.6387 - val_loss: 0.8933 - val_accuracy: 0.6304\n",
      "Epoch 33/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8654 - accuracy: 0.6380 - val_loss: 0.8917 - val_accuracy: 0.6309\n",
      "Epoch 34/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8603 - accuracy: 0.6407 - val_loss: 0.8864 - val_accuracy: 0.6335\n",
      "Epoch 35/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8581 - accuracy: 0.6417 - val_loss: 0.8863 - val_accuracy: 0.6347\n",
      "Epoch 36/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8543 - accuracy: 0.6432 - val_loss: 0.8837 - val_accuracy: 0.6365\n",
      "Epoch 37/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8509 - accuracy: 0.6449 - val_loss: 0.8817 - val_accuracy: 0.6343\n",
      "Epoch 38/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8482 - accuracy: 0.6450 - val_loss: 0.8796 - val_accuracy: 0.6327\n",
      "Epoch 39/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8445 - accuracy: 0.6461 - val_loss: 0.8993 - val_accuracy: 0.6316\n",
      "Epoch 40/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8412 - accuracy: 0.6475 - val_loss: 0.8762 - val_accuracy: 0.6368\n",
      "Epoch 41/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8381 - accuracy: 0.6492 - val_loss: 0.8722 - val_accuracy: 0.6387\n",
      "Epoch 42/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8347 - accuracy: 0.6488 - val_loss: 0.8726 - val_accuracy: 0.6381\n",
      "Epoch 43/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8319 - accuracy: 0.6518 - val_loss: 0.8723 - val_accuracy: 0.6375\n",
      "Epoch 44/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8290 - accuracy: 0.6529 - val_loss: 0.8662 - val_accuracy: 0.6392\n",
      "Epoch 45/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8245 - accuracy: 0.6549 - val_loss: 0.8763 - val_accuracy: 0.6347\n",
      "Epoch 46/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8230 - accuracy: 0.6534 - val_loss: 0.8694 - val_accuracy: 0.6364\n",
      "Epoch 47/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8201 - accuracy: 0.6555 - val_loss: 0.8643 - val_accuracy: 0.6431\n",
      "Epoch 48/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8173 - accuracy: 0.6563 - val_loss: 0.8621 - val_accuracy: 0.6416\n",
      "Epoch 49/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8151 - accuracy: 0.6581 - val_loss: 0.8628 - val_accuracy: 0.6417\n",
      "Epoch 50/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8110 - accuracy: 0.6585 - val_loss: 0.8653 - val_accuracy: 0.6422\n",
      "Epoch 51/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8092 - accuracy: 0.6608 - val_loss: 0.8603 - val_accuracy: 0.6418\n",
      "Epoch 52/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8067 - accuracy: 0.6613 - val_loss: 0.8644 - val_accuracy: 0.6413\n",
      "Epoch 53/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8040 - accuracy: 0.6632 - val_loss: 0.8564 - val_accuracy: 0.6467\n",
      "Epoch 54/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.8025 - accuracy: 0.6643 - val_loss: 0.8542 - val_accuracy: 0.6448\n",
      "Epoch 55/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7985 - accuracy: 0.6655 - val_loss: 0.8552 - val_accuracy: 0.6442\n",
      "Epoch 56/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7960 - accuracy: 0.6640 - val_loss: 0.8611 - val_accuracy: 0.6453\n",
      "Epoch 57/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7944 - accuracy: 0.6653 - val_loss: 0.8500 - val_accuracy: 0.6491\n",
      "Epoch 58/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7920 - accuracy: 0.6658 - val_loss: 0.8502 - val_accuracy: 0.6488\n",
      "Epoch 59/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7899 - accuracy: 0.6675 - val_loss: 0.8595 - val_accuracy: 0.6441\n",
      "Epoch 60/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7872 - accuracy: 0.6694 - val_loss: 0.8500 - val_accuracy: 0.6502\n",
      "Epoch 61/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7858 - accuracy: 0.6688 - val_loss: 0.8540 - val_accuracy: 0.6473\n",
      "Epoch 62/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7824 - accuracy: 0.6702 - val_loss: 0.8480 - val_accuracy: 0.6518\n",
      "Epoch 63/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7793 - accuracy: 0.6720 - val_loss: 0.8510 - val_accuracy: 0.6489\n",
      "Epoch 64/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7780 - accuracy: 0.6728 - val_loss: 0.8578 - val_accuracy: 0.6409\n",
      "Epoch 65/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7762 - accuracy: 0.6728 - val_loss: 0.8457 - val_accuracy: 0.6506\n",
      "Epoch 66/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7734 - accuracy: 0.6739 - val_loss: 0.8585 - val_accuracy: 0.6409\n",
      "Epoch 67/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7709 - accuracy: 0.6757 - val_loss: 0.8447 - val_accuracy: 0.6537\n",
      "Epoch 68/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7699 - accuracy: 0.6742 - val_loss: 0.8542 - val_accuracy: 0.6489\n",
      "Epoch 69/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7663 - accuracy: 0.6764 - val_loss: 0.8566 - val_accuracy: 0.6477\n",
      "Epoch 70/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7655 - accuracy: 0.6765 - val_loss: 0.8460 - val_accuracy: 0.6523\n",
      "Epoch 71/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7634 - accuracy: 0.6778 - val_loss: 0.8465 - val_accuracy: 0.6521\n",
      "Epoch 72/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7614 - accuracy: 0.6785 - val_loss: 0.8435 - val_accuracy: 0.6509\n",
      "Epoch 73/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7592 - accuracy: 0.6800 - val_loss: 0.8506 - val_accuracy: 0.6515\n",
      "Epoch 74/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7571 - accuracy: 0.6813 - val_loss: 0.8483 - val_accuracy: 0.6486\n",
      "Epoch 75/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7543 - accuracy: 0.6834 - val_loss: 0.8488 - val_accuracy: 0.6509\n",
      "Epoch 76/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7529 - accuracy: 0.6808 - val_loss: 0.8479 - val_accuracy: 0.6499\n",
      "Epoch 77/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7510 - accuracy: 0.6820 - val_loss: 0.8503 - val_accuracy: 0.6531\n",
      "Epoch 78/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7489 - accuracy: 0.6834 - val_loss: 0.8482 - val_accuracy: 0.6541\n",
      "Epoch 79/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7458 - accuracy: 0.6856 - val_loss: 0.8461 - val_accuracy: 0.6555\n",
      "Epoch 80/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7450 - accuracy: 0.6851 - val_loss: 0.8513 - val_accuracy: 0.6541\n",
      "Epoch 81/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7427 - accuracy: 0.6864 - val_loss: 0.8464 - val_accuracy: 0.6558\n",
      "Epoch 82/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7402 - accuracy: 0.6872 - val_loss: 0.8472 - val_accuracy: 0.6510\n",
      "Epoch 83/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7391 - accuracy: 0.6882 - val_loss: 0.8483 - val_accuracy: 0.6509\n",
      "Epoch 84/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7369 - accuracy: 0.6891 - val_loss: 0.8441 - val_accuracy: 0.6527\n",
      "Epoch 85/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7345 - accuracy: 0.6893 - val_loss: 0.8509 - val_accuracy: 0.6526\n",
      "Epoch 86/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7327 - accuracy: 0.6905 - val_loss: 0.8501 - val_accuracy: 0.6553\n",
      "Epoch 87/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7305 - accuracy: 0.6923 - val_loss: 0.8483 - val_accuracy: 0.6546\n",
      "Epoch 88/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7294 - accuracy: 0.6925 - val_loss: 0.8456 - val_accuracy: 0.6570\n",
      "Epoch 89/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7273 - accuracy: 0.6922 - val_loss: 0.8484 - val_accuracy: 0.6547\n",
      "Epoch 90/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7249 - accuracy: 0.6948 - val_loss: 0.8494 - val_accuracy: 0.6540\n",
      "Epoch 91/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7232 - accuracy: 0.6956 - val_loss: 0.8506 - val_accuracy: 0.6550\n",
      "Epoch 92/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7220 - accuracy: 0.6952 - val_loss: 0.8528 - val_accuracy: 0.6571\n",
      "Epoch 93/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7194 - accuracy: 0.6960 - val_loss: 0.8478 - val_accuracy: 0.6581\n",
      "Epoch 94/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7182 - accuracy: 0.6969 - val_loss: 0.8590 - val_accuracy: 0.6496\n",
      "Epoch 95/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7156 - accuracy: 0.6988 - val_loss: 0.8649 - val_accuracy: 0.6461\n",
      "Epoch 96/1000\n",
      "1036/1036 [==============================] - 4s 3ms/step - loss: 0.7149 - accuracy: 0.6986 - val_loss: 0.8589 - val_accuracy: 0.6534\n",
      "Epoch 97/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7121 - accuracy: 0.6992 - val_loss: 0.8547 - val_accuracy: 0.6526\n",
      "Epoch 98/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7097 - accuracy: 0.7003 - val_loss: 0.8506 - val_accuracy: 0.6573\n",
      "Epoch 99/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7080 - accuracy: 0.7021 - val_loss: 0.8544 - val_accuracy: 0.6561\n",
      "Epoch 100/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7072 - accuracy: 0.7023 - val_loss: 0.8521 - val_accuracy: 0.6573\n",
      "Epoch 101/1000\n",
      "1036/1036 [==============================] - 4s 3ms/step - loss: 0.7048 - accuracy: 0.7028 - val_loss: 0.8544 - val_accuracy: 0.6582\n",
      "Epoch 102/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7029 - accuracy: 0.7038 - val_loss: 0.8535 - val_accuracy: 0.6576\n",
      "Epoch 103/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.7011 - accuracy: 0.7051 - val_loss: 0.8518 - val_accuracy: 0.6576\n",
      "Epoch 104/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6994 - accuracy: 0.7068 - val_loss: 0.8567 - val_accuracy: 0.6540\n",
      "Epoch 105/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6986 - accuracy: 0.7065 - val_loss: 0.8569 - val_accuracy: 0.6533\n",
      "Epoch 106/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6971 - accuracy: 0.7064 - val_loss: 0.8597 - val_accuracy: 0.6532\n",
      "Epoch 107/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6947 - accuracy: 0.7073 - val_loss: 0.8554 - val_accuracy: 0.6567\n",
      "Epoch 108/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6923 - accuracy: 0.7091 - val_loss: 0.8589 - val_accuracy: 0.6546\n",
      "Epoch 109/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6906 - accuracy: 0.7095 - val_loss: 0.8574 - val_accuracy: 0.6570\n",
      "Epoch 110/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6898 - accuracy: 0.7091 - val_loss: 0.8589 - val_accuracy: 0.6535\n",
      "Epoch 111/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6878 - accuracy: 0.7112 - val_loss: 0.8618 - val_accuracy: 0.6572\n",
      "Epoch 112/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6861 - accuracy: 0.7121 - val_loss: 0.8601 - val_accuracy: 0.6553\n",
      "Epoch 113/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6849 - accuracy: 0.7127 - val_loss: 0.8617 - val_accuracy: 0.6553\n",
      "Epoch 114/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6824 - accuracy: 0.7140 - val_loss: 0.8683 - val_accuracy: 0.6568\n",
      "Epoch 115/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.7136 - val_loss: 0.8680 - val_accuracy: 0.6577\n",
      "Epoch 116/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.7147 - val_loss: 0.8649 - val_accuracy: 0.6531\n",
      "Epoch 117/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6774 - accuracy: 0.7167 - val_loss: 0.8673 - val_accuracy: 0.6547\n",
      "Epoch 118/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6764 - accuracy: 0.7162 - val_loss: 0.8699 - val_accuracy: 0.6544\n",
      "Epoch 119/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6747 - accuracy: 0.7170 - val_loss: 0.8697 - val_accuracy: 0.6562\n",
      "Epoch 120/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6733 - accuracy: 0.7167 - val_loss: 0.8671 - val_accuracy: 0.6567\n",
      "Epoch 121/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6705 - accuracy: 0.7182 - val_loss: 0.8665 - val_accuracy: 0.6599\n",
      "Epoch 122/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6696 - accuracy: 0.7198 - val_loss: 0.8724 - val_accuracy: 0.6518\n",
      "Epoch 123/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6673 - accuracy: 0.7204 - val_loss: 0.8711 - val_accuracy: 0.6553\n",
      "Epoch 124/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6653 - accuracy: 0.7217 - val_loss: 0.8697 - val_accuracy: 0.6593\n",
      "Epoch 125/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6654 - accuracy: 0.7208 - val_loss: 0.8774 - val_accuracy: 0.6559\n",
      "Epoch 126/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6640 - accuracy: 0.7233 - val_loss: 0.8768 - val_accuracy: 0.6564\n",
      "Epoch 127/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6606 - accuracy: 0.7236 - val_loss: 0.8788 - val_accuracy: 0.6545\n",
      "Epoch 128/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6589 - accuracy: 0.7250 - val_loss: 0.8772 - val_accuracy: 0.6547\n",
      "Epoch 129/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6568 - accuracy: 0.7244 - val_loss: 0.8829 - val_accuracy: 0.6535\n",
      "Epoch 130/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6566 - accuracy: 0.7236 - val_loss: 0.8802 - val_accuracy: 0.6549\n",
      "Epoch 131/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6551 - accuracy: 0.7279 - val_loss: 0.8808 - val_accuracy: 0.6594\n",
      "Epoch 132/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6535 - accuracy: 0.7260 - val_loss: 0.8874 - val_accuracy: 0.6492\n",
      "Epoch 133/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6500 - accuracy: 0.7274 - val_loss: 0.8850 - val_accuracy: 0.6512\n",
      "Epoch 134/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6503 - accuracy: 0.7281 - val_loss: 0.8894 - val_accuracy: 0.6569\n",
      "Epoch 135/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6481 - accuracy: 0.7293 - val_loss: 0.8850 - val_accuracy: 0.6576\n",
      "Epoch 136/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6461 - accuracy: 0.7308 - val_loss: 0.8847 - val_accuracy: 0.6534\n",
      "Epoch 137/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6457 - accuracy: 0.7297 - val_loss: 0.8873 - val_accuracy: 0.6561\n",
      "Epoch 138/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6432 - accuracy: 0.7314 - val_loss: 0.8916 - val_accuracy: 0.6550\n",
      "Epoch 139/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6426 - accuracy: 0.7314 - val_loss: 0.8926 - val_accuracy: 0.6554\n",
      "Epoch 140/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6404 - accuracy: 0.7320 - val_loss: 0.8883 - val_accuracy: 0.6579\n",
      "Epoch 141/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6384 - accuracy: 0.7325 - val_loss: 0.8915 - val_accuracy: 0.6556\n",
      "Epoch 142/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6370 - accuracy: 0.7333 - val_loss: 0.8974 - val_accuracy: 0.6568\n",
      "Epoch 143/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6370 - accuracy: 0.7337 - val_loss: 0.9004 - val_accuracy: 0.6547\n",
      "Epoch 144/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6342 - accuracy: 0.7345 - val_loss: 0.8954 - val_accuracy: 0.6517\n",
      "Epoch 145/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6328 - accuracy: 0.7350 - val_loss: 0.9048 - val_accuracy: 0.6538\n",
      "Epoch 146/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6317 - accuracy: 0.7358 - val_loss: 0.8995 - val_accuracy: 0.6533\n",
      "Epoch 147/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6302 - accuracy: 0.7363 - val_loss: 0.9026 - val_accuracy: 0.6567\n",
      "Epoch 148/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6283 - accuracy: 0.7377 - val_loss: 0.9039 - val_accuracy: 0.6574\n",
      "Epoch 149/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6271 - accuracy: 0.7375 - val_loss: 0.9001 - val_accuracy: 0.6562\n",
      "Epoch 150/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6258 - accuracy: 0.7380 - val_loss: 0.9040 - val_accuracy: 0.6558\n",
      "Epoch 151/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6245 - accuracy: 0.7390 - val_loss: 0.9058 - val_accuracy: 0.6549\n",
      "Epoch 152/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6234 - accuracy: 0.7397 - val_loss: 0.9109 - val_accuracy: 0.6548\n",
      "Epoch 153/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6203 - accuracy: 0.7418 - val_loss: 0.9110 - val_accuracy: 0.6517\n",
      "Epoch 154/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6197 - accuracy: 0.7421 - val_loss: 0.9079 - val_accuracy: 0.6591\n",
      "Epoch 155/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6187 - accuracy: 0.7418 - val_loss: 0.9151 - val_accuracy: 0.6551\n",
      "Epoch 156/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6177 - accuracy: 0.7415 - val_loss: 0.9180 - val_accuracy: 0.6551\n",
      "Epoch 157/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6155 - accuracy: 0.7428 - val_loss: 0.9162 - val_accuracy: 0.6541\n",
      "Epoch 158/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6135 - accuracy: 0.7445 - val_loss: 0.9193 - val_accuracy: 0.6579\n",
      "Epoch 159/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6129 - accuracy: 0.7459 - val_loss: 0.9205 - val_accuracy: 0.6568\n",
      "Epoch 160/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6114 - accuracy: 0.7444 - val_loss: 0.9272 - val_accuracy: 0.6525\n",
      "Epoch 161/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6097 - accuracy: 0.7448 - val_loss: 0.9244 - val_accuracy: 0.6540\n",
      "Epoch 162/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6089 - accuracy: 0.7467 - val_loss: 0.9250 - val_accuracy: 0.6585\n",
      "Epoch 163/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6069 - accuracy: 0.7469 - val_loss: 0.9299 - val_accuracy: 0.6507\n",
      "Epoch 164/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6050 - accuracy: 0.7489 - val_loss: 0.9305 - val_accuracy: 0.6546\n",
      "Epoch 165/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6030 - accuracy: 0.7483 - val_loss: 0.9313 - val_accuracy: 0.6544\n",
      "Epoch 166/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.6032 - accuracy: 0.7475 - val_loss: 0.9331 - val_accuracy: 0.6529\n",
      "Epoch 167/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5994 - accuracy: 0.7496 - val_loss: 0.9381 - val_accuracy: 0.6509\n",
      "Epoch 168/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5990 - accuracy: 0.7500 - val_loss: 0.9344 - val_accuracy: 0.6546\n",
      "Epoch 169/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5971 - accuracy: 0.7509 - val_loss: 0.9337 - val_accuracy: 0.6512\n",
      "Epoch 170/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5972 - accuracy: 0.7499 - val_loss: 0.9495 - val_accuracy: 0.6482\n",
      "Epoch 171/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5957 - accuracy: 0.7523 - val_loss: 0.9497 - val_accuracy: 0.6493\n",
      "Epoch 172/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5941 - accuracy: 0.7530 - val_loss: 0.9445 - val_accuracy: 0.6535\n",
      "Epoch 173/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5924 - accuracy: 0.7537 - val_loss: 0.9394 - val_accuracy: 0.6551\n",
      "Epoch 174/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5898 - accuracy: 0.7537 - val_loss: 0.9436 - val_accuracy: 0.6503\n",
      "Epoch 175/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5899 - accuracy: 0.7564 - val_loss: 0.9497 - val_accuracy: 0.6526\n",
      "Epoch 176/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5892 - accuracy: 0.7534 - val_loss: 0.9431 - val_accuracy: 0.6537\n",
      "Epoch 177/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5869 - accuracy: 0.7570 - val_loss: 0.9567 - val_accuracy: 0.6485\n",
      "Epoch 178/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5866 - accuracy: 0.7562 - val_loss: 0.9572 - val_accuracy: 0.6512\n",
      "Epoch 179/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5848 - accuracy: 0.7563 - val_loss: 0.9566 - val_accuracy: 0.6515\n",
      "Epoch 180/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5836 - accuracy: 0.7577 - val_loss: 0.9604 - val_accuracy: 0.6479\n",
      "Epoch 181/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5814 - accuracy: 0.7577 - val_loss: 0.9547 - val_accuracy: 0.6530\n",
      "Epoch 182/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5802 - accuracy: 0.7589 - val_loss: 0.9588 - val_accuracy: 0.6547\n",
      "Epoch 183/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5789 - accuracy: 0.7588 - val_loss: 0.9617 - val_accuracy: 0.6535\n",
      "Epoch 184/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5778 - accuracy: 0.7595 - val_loss: 0.9630 - val_accuracy: 0.6538\n",
      "Epoch 185/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5762 - accuracy: 0.7606 - val_loss: 0.9644 - val_accuracy: 0.6544\n",
      "Epoch 186/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5745 - accuracy: 0.7609 - val_loss: 0.9707 - val_accuracy: 0.6498\n",
      "Epoch 187/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5734 - accuracy: 0.7609 - val_loss: 0.9751 - val_accuracy: 0.6490\n",
      "Epoch 188/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5722 - accuracy: 0.7620 - val_loss: 0.9728 - val_accuracy: 0.6518\n",
      "Epoch 189/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5707 - accuracy: 0.7640 - val_loss: 0.9744 - val_accuracy: 0.6500\n",
      "Epoch 190/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5697 - accuracy: 0.7637 - val_loss: 0.9803 - val_accuracy: 0.6513\n",
      "Epoch 191/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5693 - accuracy: 0.7636 - val_loss: 0.9815 - val_accuracy: 0.6523\n",
      "Epoch 192/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5682 - accuracy: 0.7642 - val_loss: 0.9853 - val_accuracy: 0.6549\n",
      "Epoch 193/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5653 - accuracy: 0.7658 - val_loss: 0.9824 - val_accuracy: 0.6526\n",
      "Epoch 194/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5643 - accuracy: 0.7652 - val_loss: 0.9816 - val_accuracy: 0.6531\n",
      "Epoch 195/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5637 - accuracy: 0.7659 - val_loss: 0.9911 - val_accuracy: 0.6540\n",
      "Epoch 196/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5624 - accuracy: 0.7676 - val_loss: 0.9886 - val_accuracy: 0.6488\n",
      "Epoch 197/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5599 - accuracy: 0.7678 - val_loss: 0.9983 - val_accuracy: 0.6510\n",
      "Epoch 198/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5591 - accuracy: 0.7679 - val_loss: 0.9962 - val_accuracy: 0.6529\n",
      "Epoch 199/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5581 - accuracy: 0.7683 - val_loss: 0.9979 - val_accuracy: 0.6482\n",
      "Epoch 200/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5557 - accuracy: 0.7702 - val_loss: 0.9956 - val_accuracy: 0.6479\n",
      "Epoch 201/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5560 - accuracy: 0.7692 - val_loss: 1.0043 - val_accuracy: 0.6484\n",
      "Epoch 202/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5551 - accuracy: 0.7707 - val_loss: 1.0086 - val_accuracy: 0.6445\n",
      "Epoch 203/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5523 - accuracy: 0.7710 - val_loss: 1.0092 - val_accuracy: 0.6474\n",
      "Epoch 204/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5523 - accuracy: 0.7713 - val_loss: 1.0154 - val_accuracy: 0.6503\n",
      "Epoch 205/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5512 - accuracy: 0.7712 - val_loss: 1.0097 - val_accuracy: 0.6503\n",
      "Epoch 206/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5495 - accuracy: 0.7727 - val_loss: 1.0163 - val_accuracy: 0.6490\n",
      "Epoch 207/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5481 - accuracy: 0.7731 - val_loss: 1.0139 - val_accuracy: 0.6439\n",
      "Epoch 208/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5484 - accuracy: 0.7727 - val_loss: 1.0263 - val_accuracy: 0.6491\n",
      "Epoch 209/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5467 - accuracy: 0.7730 - val_loss: 1.0214 - val_accuracy: 0.6480\n",
      "Epoch 210/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7750 - val_loss: 1.0281 - val_accuracy: 0.6476\n",
      "Epoch 211/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5431 - accuracy: 0.7761 - val_loss: 1.0235 - val_accuracy: 0.6495\n",
      "Epoch 212/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5429 - accuracy: 0.7749 - val_loss: 1.0258 - val_accuracy: 0.6480\n",
      "Epoch 213/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5418 - accuracy: 0.7752 - val_loss: 1.0322 - val_accuracy: 0.6529\n",
      "Epoch 214/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5399 - accuracy: 0.7783 - val_loss: 1.0323 - val_accuracy: 0.6505\n",
      "Epoch 215/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5385 - accuracy: 0.7770 - val_loss: 1.0352 - val_accuracy: 0.6521\n",
      "Epoch 216/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5365 - accuracy: 0.7781 - val_loss: 1.0340 - val_accuracy: 0.6489\n",
      "Epoch 217/1000\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.5358 - accuracy: 0.7785 - val_loss: 1.0391 - val_accuracy: 0.6418\n",
      "Epoch 218/1000\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.5349 - accuracy: 0.7792 - val_loss: 1.0484 - val_accuracy: 0.6459\n",
      "Epoch 219/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5345 - accuracy: 0.7795 - val_loss: 1.0468 - val_accuracy: 0.6514\n",
      "Epoch 220/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5329 - accuracy: 0.7805 - val_loss: 1.0398 - val_accuracy: 0.6480\n",
      "Epoch 221/1000\n",
      "1036/1036 [==============================] - 4s 3ms/step - loss: 0.5313 - accuracy: 0.7806 - val_loss: 1.0468 - val_accuracy: 0.6475\n",
      "Epoch 222/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5314 - accuracy: 0.7798 - val_loss: 1.0623 - val_accuracy: 0.6495\n",
      "Epoch 223/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5300 - accuracy: 0.7809 - val_loss: 1.0540 - val_accuracy: 0.6467\n",
      "Epoch 224/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5269 - accuracy: 0.7834 - val_loss: 1.0591 - val_accuracy: 0.6432\n",
      "Epoch 225/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5264 - accuracy: 0.7809 - val_loss: 1.0557 - val_accuracy: 0.6461\n",
      "Epoch 226/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5254 - accuracy: 0.7828 - val_loss: 1.0656 - val_accuracy: 0.6442\n",
      "Epoch 227/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5244 - accuracy: 0.7837 - val_loss: 1.0734 - val_accuracy: 0.6421\n",
      "Epoch 228/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5220 - accuracy: 0.7844 - val_loss: 1.0649 - val_accuracy: 0.6432\n",
      "Epoch 229/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5218 - accuracy: 0.7853 - val_loss: 1.0754 - val_accuracy: 0.6446\n",
      "Epoch 230/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5208 - accuracy: 0.7856 - val_loss: 1.0742 - val_accuracy: 0.6442\n",
      "Epoch 231/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5183 - accuracy: 0.7859 - val_loss: 1.0762 - val_accuracy: 0.6459\n",
      "Epoch 232/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5186 - accuracy: 0.7859 - val_loss: 1.0803 - val_accuracy: 0.6464\n",
      "Epoch 233/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5169 - accuracy: 0.7868 - val_loss: 1.0866 - val_accuracy: 0.6431\n",
      "Epoch 234/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5155 - accuracy: 0.7872 - val_loss: 1.0846 - val_accuracy: 0.6433\n",
      "Epoch 235/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5146 - accuracy: 0.7888 - val_loss: 1.0797 - val_accuracy: 0.6450\n",
      "Epoch 236/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5136 - accuracy: 0.7880 - val_loss: 1.0928 - val_accuracy: 0.6483\n",
      "Epoch 237/1000\n",
      "1036/1036 [==============================] - 3s 3ms/step - loss: 0.5125 - accuracy: 0.7892 - val_loss: 1.0963 - val_accuracy: 0.6424\n",
      "Epoch 238/1000\n",
      " 326/1036 [========>.....................] - ETA: 1s - loss: 0.5117 - accuracy: 0.7870"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 55\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# 모델 컴파일 및 학습\u001B[39;00m\n\u001B[0;32m     54\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 55\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# 최상의 적합 모델을 피클 파일로 저장\u001B[39;00m\n\u001B[0;32m     58\u001B[0m best_model \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mmodel\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# 데이터를 학습용과 테스트용으로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 설정된 시드를 사용하여 TensorFlow의 재현성 확보\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델을 피클 파일로 저장\n",
    "best_model = history.model\n",
    "pickle.dump(best_model, open('best_model.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T08:46:44.781200300Z",
     "start_time": "2023-06-08T08:34:19.830242700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 4, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4, 3), dtype=tf.float32, name='lstm_1_input'), name='lstm_1_input', description=\"created by layer 'lstm_1_input'\"), but it was called on an input with incompatible shape (None, 4, 3, 4).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"lstm_1\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 4, 3, 4)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 4, 3, 4), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 73\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# 모델 컴파일 및 학습\u001B[39;00m\n\u001B[0;32m     72\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 73\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# 최상의 적합 모델을 피클 파일로 저장\u001B[39;00m\n\u001B[0;32m     76\u001B[0m best_model \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mmodel\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filef6ma4xo1.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"lstm_1\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 4, 3, 4)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 4, 3, 4), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../data/SisFall_df_sc.csv')\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# 시퀀스 단위로 데이터를 분할하기 위한 인덱스 계산\n",
    "seq_length = 4\n",
    "split_index = range(seq_length, len(X), seq_length)\n",
    "\n",
    "# 시퀀스 단위로 데이터 분할\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "for i in split_index:\n",
    "    X_seq.append(X[i-seq_length:i])\n",
    "    y_seq.append(y[i-seq_length:i])\n",
    "\n",
    "# 분할된 시퀀스 데이터를 넘파이 배열로 변환\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# 데이터를 학습용과 테스트용으로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# 설정된 시드를 사용하여 TensorFlow의 재현성 확보\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, 3)))  # seq_length개의 시퀀스, 각 시퀀스에 3개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델을 피클 파일로 저장\n",
    "best_model = history.model\n",
    "pickle.dump(best_model, open('best_model.pkl', 'wb'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T08:47:27.086978200Z",
     "start_time": "2023-06-08T08:47:09.093317100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Danu\\TensorFlow\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 4, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4, 3), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 4, 3, 4).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"lstm_2\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 4, 3, 4)\n    \n    Call arguments received by layer \"sequential_2\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 4, 3, 4), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 73\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# 모델 컴파일 및 학습\u001B[39;00m\n\u001B[0;32m     72\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 73\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# 최상의 적합 모델을 피클 파일로 저장\u001B[39;00m\n\u001B[0;32m     76\u001B[0m best_model \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mmodel\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filef6ma4xo1.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\SW402-08\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"lstm_2\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 4, 3, 4)\n    \n    Call arguments received by layer \"sequential_2\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 4, 3, 4), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../data/SisFall_df_sc.csv')\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# 시퀀스 단위로 데이터를 분할하기 위한 인덱스 계산\n",
    "seq_length = 4\n",
    "split_index = range(seq_length, len(X), seq_length)\n",
    "\n",
    "# 시퀀스 단위로 데이터 분할\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "for i in split_index:\n",
    "    X_seq.append(X[i-seq_length:i])\n",
    "    y_seq.append(y[i-seq_length:i])\n",
    "\n",
    "# 분할된 시퀀스 데이터를 넘파이 배열로 변환\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# 데이터를 학습용과 테스트용으로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# 설정된 시드를 사용하여 TensorFlow의 재현성 확보\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, 3)))  # 3개의 시퀀스, 각 시퀀스에 3개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델을 피클 파일로 저장\n",
    "best_model = history.model\n",
    "pickle.dump(best_model, open('best_model.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T08:49:06.613329800Z",
     "start_time": "2023-06-08T08:48:48.685492300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=100, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Danu\\TensorFlow\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 7s 2ms/step - loss: 0.8483 - accuracy: 0.6587\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7500 - accuracy: 0.6974\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.7188 - accuracy: 0.7101\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6958 - accuracy: 0.7168\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.6778 - accuracy: 0.7251\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6616 - accuracy: 0.7293\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.6459 - accuracy: 0.7367\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6302 - accuracy: 0.7439\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6174 - accuracy: 0.7491\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6038 - accuracy: 0.7540\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5918 - accuracy: 0.7603\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5785 - accuracy: 0.7639\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5680 - accuracy: 0.7694\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5547 - accuracy: 0.7747\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5452 - accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5330 - accuracy: 0.7841\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5220 - accuracy: 0.7879\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5109 - accuracy: 0.7928\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.5007 - accuracy: 0.7981\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4897 - accuracy: 0.8023\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4792 - accuracy: 0.8064\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4694 - accuracy: 0.8117\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4584 - accuracy: 0.8155\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4508 - accuracy: 0.8180\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4402 - accuracy: 0.8234\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4324 - accuracy: 0.8267\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4223 - accuracy: 0.8298\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4148 - accuracy: 0.8337\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.4060 - accuracy: 0.8373\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3987 - accuracy: 0.8409\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3920 - accuracy: 0.8435\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3831 - accuracy: 0.8479\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3744 - accuracy: 0.8497\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3682 - accuracy: 0.8542\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3608 - accuracy: 0.8580\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3550 - accuracy: 0.8586\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3482 - accuracy: 0.8614\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3403 - accuracy: 0.8655\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3354 - accuracy: 0.8678\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3291 - accuracy: 0.8692\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3224 - accuracy: 0.8719\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3157 - accuracy: 0.8748\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3116 - accuracy: 0.8761\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3066 - accuracy: 0.8785\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3010 - accuracy: 0.8806\n",
      "Epoch 46/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2964 - accuracy: 0.8833\n",
      "Epoch 47/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2906 - accuracy: 0.8856\n",
      "Epoch 48/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2862 - accuracy: 0.8880\n",
      "Epoch 49/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2823 - accuracy: 0.8894\n",
      "Epoch 50/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2780 - accuracy: 0.8907\n",
      "Epoch 51/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2722 - accuracy: 0.8934\n",
      "Epoch 52/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2691 - accuracy: 0.8950\n",
      "Epoch 53/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2671 - accuracy: 0.8946\n",
      "Epoch 54/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2599 - accuracy: 0.8978\n",
      "Epoch 55/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2596 - accuracy: 0.8982\n",
      "Epoch 56/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2532 - accuracy: 0.8999\n",
      "Epoch 57/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2512 - accuracy: 0.9004\n",
      "Epoch 58/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2472 - accuracy: 0.9036\n",
      "Epoch 59/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2453 - accuracy: 0.9044\n",
      "Epoch 60/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2395 - accuracy: 0.9057\n",
      "Epoch 61/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2391 - accuracy: 0.9060\n",
      "Epoch 62/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2337 - accuracy: 0.9089\n",
      "Epoch 63/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2333 - accuracy: 0.9080\n",
      "Epoch 64/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2269 - accuracy: 0.9105\n",
      "Epoch 65/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2283 - accuracy: 0.9106\n",
      "Epoch 66/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2258 - accuracy: 0.9104\n",
      "Epoch 67/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2213 - accuracy: 0.9133\n",
      "Epoch 68/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2203 - accuracy: 0.9125\n",
      "Epoch 69/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2157 - accuracy: 0.9157\n",
      "Epoch 70/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2153 - accuracy: 0.9149\n",
      "Epoch 71/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2124 - accuracy: 0.9164\n",
      "Epoch 72/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2093 - accuracy: 0.9181\n",
      "Epoch 73/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2058 - accuracy: 0.9193\n",
      "Epoch 74/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2071 - accuracy: 0.9190\n",
      "Epoch 75/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2072 - accuracy: 0.9186\n",
      "Epoch 76/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2013 - accuracy: 0.9212\n",
      "Epoch 77/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2026 - accuracy: 0.9197\n",
      "Epoch 78/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1977 - accuracy: 0.9226\n",
      "Epoch 79/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1980 - accuracy: 0.9223\n",
      "Epoch 80/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1958 - accuracy: 0.9238\n",
      "Epoch 81/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1939 - accuracy: 0.9235\n",
      "Epoch 82/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1937 - accuracy: 0.9233\n",
      "Epoch 83/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1909 - accuracy: 0.9257\n",
      "Epoch 84/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1910 - accuracy: 0.9247\n",
      "Epoch 85/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1863 - accuracy: 0.9260\n",
      "Epoch 86/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1864 - accuracy: 0.9264\n",
      "Epoch 87/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1864 - accuracy: 0.9269\n",
      "Epoch 88/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1831 - accuracy: 0.9280\n",
      "Epoch 89/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1821 - accuracy: 0.9280\n",
      "Epoch 90/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1835 - accuracy: 0.9287\n",
      "Epoch 91/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1794 - accuracy: 0.9290\n",
      "Epoch 92/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1783 - accuracy: 0.9296\n",
      "Epoch 93/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1768 - accuracy: 0.9306\n",
      "Epoch 94/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1758 - accuracy: 0.9306\n",
      "Epoch 95/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1767 - accuracy: 0.9309\n",
      "Epoch 96/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1718 - accuracy: 0.9331\n",
      "Epoch 97/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1736 - accuracy: 0.9324\n",
      "Epoch 98/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1727 - accuracy: 0.9319\n",
      "Epoch 99/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1689 - accuracy: 0.9335\n",
      "Epoch 100/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1705 - accuracy: 0.9328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d960d710-78d4-4e80-9b1c-f1d46209e812/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d960d710-78d4-4e80-9b1c-f1d46209e812/assets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=100, batch_size=32)\n",
    "\n",
    "# 최상의 적합 모델을 피클 파일로 저장\n",
    "best_model = history.model\n",
    "pickle.dump(best_model, open('../model/best_model.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T09:00:29.213430500Z",
     "start_time": "2023-06-08T08:51:24.218273500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'label_encoder_classes.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 29\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# 예측 결과 디코딩\u001B[39;00m\n\u001B[0;32m     28\u001B[0m label_encoder \u001B[38;5;241m=\u001B[39m LabelEncoder()\n\u001B[1;32m---> 29\u001B[0m label_encoder\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel_encoder_classes.npy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m decoded_predictions \u001B[38;5;241m=\u001B[39m label_encoder\u001B[38;5;241m.\u001B[39minverse_transform(np\u001B[38;5;241m.\u001B[39margmax(predictions, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# 예측 결과를 CSV 파일로 저장\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[0;32m    403\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 405\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    406\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    408\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'label_encoder_classes.npy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# 예측할 데이터 불러오기\n",
    "pred_df = pd.read_csv('../data/Arduino/fall_sc.csv')\n",
    "\n",
    "# 입력 데이터 준비\n",
    "X_pred = []  # 입력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(pred_df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = pred_df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = pred_df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = pred_df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "    X_pred.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "# 입력 데이터를 넘파이 배열로 변환\n",
    "X_pred = np.array(X_pred)\n",
    "\n",
    "# 모델을 사용하여 예측\n",
    "predictions = best_model.predict(X_pred)\n",
    "\n",
    "# 예측 결과 디코딩\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('label_encoder_classes.npy')\n",
    "decoded_predictions = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "pred_df['predicted_label'] = decoded_predictions\n",
    "pred_df.to_csv('../data/prediction_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T09:01:03.062025100Z",
     "start_time": "2023-06-08T09:01:02.522029400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
