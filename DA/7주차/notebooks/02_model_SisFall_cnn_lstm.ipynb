{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "214/214 [==============================] - 5s 14ms/step - loss: 0.7662 - accuracy: 0.6746 - val_loss: 0.7295 - val_accuracy: 0.7095\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5488 - accuracy: 0.7718 - val_loss: 0.6731 - val_accuracy: 0.7399\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.4601 - accuracy: 0.8117 - val_loss: 0.6465 - val_accuracy: 0.7580\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.4055 - accuracy: 0.8327 - val_loss: 0.5859 - val_accuracy: 0.7615\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.3652 - accuracy: 0.8510 - val_loss: 0.6465 - val_accuracy: 0.7434\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.3275 - accuracy: 0.8684 - val_loss: 0.5771 - val_accuracy: 0.7697\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.3029 - accuracy: 0.8755 - val_loss: 0.6217 - val_accuracy: 0.7592\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.2805 - accuracy: 0.8835 - val_loss: 0.6052 - val_accuracy: 0.7726\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.2554 - accuracy: 0.8937 - val_loss: 0.6606 - val_accuracy: 0.7697\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.2424 - accuracy: 0.8995 - val_loss: 0.6556 - val_accuracy: 0.7686\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.2287 - accuracy: 0.9009 - val_loss: 0.7699 - val_accuracy: 0.7680\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.2097 - accuracy: 0.9107 - val_loss: 0.6577 - val_accuracy: 0.7773\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1940 - accuracy: 0.9184 - val_loss: 0.6230 - val_accuracy: 0.7802\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1919 - accuracy: 0.9190 - val_loss: 0.7137 - val_accuracy: 0.7586\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1800 - accuracy: 0.9238 - val_loss: 0.7440 - val_accuracy: 0.7762\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1693 - accuracy: 0.9289 - val_loss: 0.7149 - val_accuracy: 0.7767\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1754 - accuracy: 0.9259 - val_loss: 0.7420 - val_accuracy: 0.7726\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1597 - accuracy: 0.9307 - val_loss: 0.7625 - val_accuracy: 0.7820\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1681 - accuracy: 0.9303 - val_loss: 0.6993 - val_accuracy: 0.7978\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1815 - accuracy: 0.9214 - val_loss: 0.8867 - val_accuracy: 0.7534\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1721 - accuracy: 0.9270 - val_loss: 0.8003 - val_accuracy: 0.7791\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1521 - accuracy: 0.9370 - val_loss: 0.8271 - val_accuracy: 0.7773\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1524 - accuracy: 0.9343 - val_loss: 0.8347 - val_accuracy: 0.7756\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1404 - accuracy: 0.9390 - val_loss: 0.8808 - val_accuracy: 0.7767\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1295 - accuracy: 0.9453 - val_loss: 0.8836 - val_accuracy: 0.7750\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1292 - accuracy: 0.9449 - val_loss: 0.9544 - val_accuracy: 0.7709\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1191 - accuracy: 0.9479 - val_loss: 0.8791 - val_accuracy: 0.7855\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.1156 - accuracy: 0.9512 - val_loss: 1.0704 - val_accuracy: 0.7703\n",
      "Epoch 29/30\n",
      "111/214 [==============>...............] - ETA: 1s - loss: 0.1089 - accuracy: 0.9527"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 87\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;66;03m# 모델 컴파일 및 학습\u001B[39;00m\n\u001B[0;32m     86\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 87\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;66;03m# 최상의 적합 모델의 가중치를 피클 파일로 저장\u001B[39;00m\n\u001B[0;32m     90\u001B[0m best_model_weights \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mget_weights()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.python.estimator import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df = pd.read_csv('../data/SisFall_train_L.csv')  # 훈련 파일\n",
    "test_df = pd.read_csv('../data/SisFall_val_L.csv')  # 테스트 파일\n",
    "\n",
    "X_train = []  # 훈련 입력 데이터\n",
    "y_train = []  # 훈련 출력 데이터\n",
    "\n",
    "X_test = []  # 테스트 입력 데이터\n",
    "y_test = []  # 테스트 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(train_df) - 39, 40):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = train_df.loc[i:i+39, 'gx'].values\n",
    "    gy_values = train_df.loc[i:i+39, 'gy'].values\n",
    "    gz_values = train_df.loc[i:i+39, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = train_df.loc[i:i+39, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_train.append(np.transpose([gx_values, gy_values, gz_values]))\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_train.append(labels[0])\n",
    "\n",
    "for i in range(0, len(test_df) - 39, 40):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = test_df.loc[i:i+39, 'gx'].values\n",
    "    gy_values = test_df.loc[i:i+39, 'gy'].values\n",
    "    gz_values = test_df.loc[i:i+39, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = test_df.loc[i:i+39, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_test.append(np.transpose([gx_values, gy_values, gz_values]))\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_test.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "onehot_encoder_train = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder_train.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = label_encoder.transform(y_test)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "onehot_encoder_test = OneHotEncoder(sparse_output=False)\n",
    "y_test = onehot_encoder_test.fit_transform(integer_encoded_test)\n",
    "\n",
    "# CNN-LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(40, 3)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = history.model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_cnn_lstm.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_cnn_lstm.npy', label_encoder.classes_)\n",
    "\n",
    "# 가중치를 로드하기 위해 모델 구성\n",
    "loaded_model = keras.models.Sequential()\n",
    "loaded_model.add(keras.layers.LSTM(128, input_shape=(3, 40)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "loaded_model.add(keras.layers.Dense(7, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 피클 파일에서 가중치 로드\n",
    "loaded_model_weights = pickle.load(open('../model/best_model_weights_cnn_lstm.pkl', 'rb'))\n",
    "\n",
    "# 모델에 로드된 가중치 설정\n",
    "loaded_model.set_weights(loaded_model_weights)\n",
    "\n",
    "# 모델 컴파일\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장\n",
    "loaded_model.save('../model/loaded_model_cnn_lstm.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T08:53:42.937204800Z",
     "start_time": "2023-06-13T08:52:17.545837300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Get the training history\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mhistory\u001B[49m\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      5\u001B[0m train_acc \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      6\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the training history\n",
    "train_loss = history.history['loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T05:22:21.469963700Z",
     "start_time": "2023-06-12T05:22:21.173002500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "214/214 [==============================] - 4s 12ms/step - loss: 0.8720 - accuracy: 0.6423 - val_loss: 0.7253 - val_accuracy: 0.7130\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.6764 - accuracy: 0.7246 - val_loss: 0.6628 - val_accuracy: 0.7300\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.6167 - accuracy: 0.7488 - val_loss: 0.6908 - val_accuracy: 0.7113\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.5786 - accuracy: 0.7635 - val_loss: 0.6763 - val_accuracy: 0.7376\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5500 - accuracy: 0.7767 - val_loss: 0.6553 - val_accuracy: 0.7434\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5246 - accuracy: 0.7919 - val_loss: 0.7048 - val_accuracy: 0.7434\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5046 - accuracy: 0.7977 - val_loss: 0.5991 - val_accuracy: 0.7592\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4768 - accuracy: 0.8061 - val_loss: 0.6482 - val_accuracy: 0.7516\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4696 - accuracy: 0.8081 - val_loss: 0.6339 - val_accuracy: 0.7499\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.4544 - accuracy: 0.8157 - val_loss: 0.6324 - val_accuracy: 0.7598\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.4403 - accuracy: 0.8227 - val_loss: 0.5670 - val_accuracy: 0.7779\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.4258 - accuracy: 0.8297 - val_loss: 0.6183 - val_accuracy: 0.7621\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.4153 - accuracy: 0.8334 - val_loss: 0.6353 - val_accuracy: 0.7522\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3993 - accuracy: 0.8382 - val_loss: 0.6073 - val_accuracy: 0.7715\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3886 - accuracy: 0.8430 - val_loss: 0.6573 - val_accuracy: 0.7499\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3837 - accuracy: 0.8450 - val_loss: 0.6789 - val_accuracy: 0.7423\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3693 - accuracy: 0.8480 - val_loss: 0.6409 - val_accuracy: 0.7575\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3719 - accuracy: 0.8483 - val_loss: 0.6229 - val_accuracy: 0.7674\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3654 - accuracy: 0.8488 - val_loss: 0.6461 - val_accuracy: 0.7557\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3513 - accuracy: 0.8554 - val_loss: 0.5850 - val_accuracy: 0.7802\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3455 - accuracy: 0.8562 - val_loss: 0.6034 - val_accuracy: 0.7849\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3394 - accuracy: 0.8624 - val_loss: 0.6060 - val_accuracy: 0.7715\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3320 - accuracy: 0.8634 - val_loss: 0.7011 - val_accuracy: 0.7551\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3246 - accuracy: 0.8651 - val_loss: 0.6556 - val_accuracy: 0.7691\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3195 - accuracy: 0.8681 - val_loss: 0.6679 - val_accuracy: 0.7732\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3158 - accuracy: 0.8715 - val_loss: 0.7218 - val_accuracy: 0.7645\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3102 - accuracy: 0.8730 - val_loss: 0.6557 - val_accuracy: 0.7791\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3006 - accuracy: 0.8785 - val_loss: 0.6631 - val_accuracy: 0.7703\n",
      "Epoch 29/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.3042 - accuracy: 0.8747 - val_loss: 0.7198 - val_accuracy: 0.7604\n",
      "Epoch 30/30\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 0.2890 - accuracy: 0.8831 - val_loss: 0.6880 - val_accuracy: 0.7621\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df = pd.read_csv('../data/SisFall_train_L_20.csv')  # 훈련 파일\n",
    "test_df = pd.read_csv('../data/SisFall_val_L_20.csv')  # 테스트 파일\n",
    "\n",
    "X_train = []  # 훈련 입력 데이터\n",
    "y_train = []  # 훈련 출력 데이터\n",
    "\n",
    "X_test = []  # 테스트 입력 데이터\n",
    "y_test = []  # 테스트 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(train_df) - 19, 20):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = train_df.loc[i:i+19, 'gx'].values\n",
    "    gy_values = train_df.loc[i:i+19, 'gy'].values\n",
    "    gz_values = train_df.loc[i:i+19, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = train_df.loc[i:i+19, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_train.append(np.transpose([gx_values, gy_values, gz_values]))\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_train.append(labels[0])\n",
    "\n",
    "for i in range(0, len(test_df) - 19, 20):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = test_df.loc[i:i+19, 'gx'].values\n",
    "    gy_values = test_df.loc[i:i+19, 'gy'].values\n",
    "    gz_values = test_df.loc[i:i+19, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = test_df.loc[i:i+19, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_test.append(np.transpose([gx_values, gy_values, gz_values]))\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_test.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "onehot_encoder_train = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder_train.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = label_encoder.transform(y_test)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "onehot_encoder_test = OneHotEncoder(sparse_output=False)\n",
    "y_test = onehot_encoder_test.fit_transform(integer_encoded_test)\n",
    "\n",
    "# CNN-LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(20, 3)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_cnn_lstm.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_cnn_lstm.npy', label_encoder.classes_)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('../model/loaded_model_cnn_lstm.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T02:08:46.092336500Z",
     "start_time": "2023-06-14T02:07:45.127554100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "214/214 [==============================] - 5s 11ms/step - loss: 0.8817 - accuracy: 0.6232 - val_loss: 0.7833 - val_accuracy: 0.7043\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.6770 - accuracy: 0.7037 - val_loss: 0.6217 - val_accuracy: 0.7148\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.6218 - accuracy: 0.7237 - val_loss: 0.6478 - val_accuracy: 0.7236\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5872 - accuracy: 0.7355 - val_loss: 0.6316 - val_accuracy: 0.7019\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5559 - accuracy: 0.7465 - val_loss: 0.6731 - val_accuracy: 0.7276\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5347 - accuracy: 0.7611 - val_loss: 0.6422 - val_accuracy: 0.7119\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5151 - accuracy: 0.7678 - val_loss: 0.6851 - val_accuracy: 0.6926\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4962 - accuracy: 0.7725 - val_loss: 0.6703 - val_accuracy: 0.7171\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4762 - accuracy: 0.7856 - val_loss: 0.6854 - val_accuracy: 0.7142\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4549 - accuracy: 0.7940 - val_loss: 0.6647 - val_accuracy: 0.7183\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4404 - accuracy: 0.8016 - val_loss: 0.6363 - val_accuracy: 0.7364\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4618 - accuracy: 0.7905 - val_loss: 0.6844 - val_accuracy: 0.7352\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4295 - accuracy: 0.8039 - val_loss: 0.7234 - val_accuracy: 0.7189\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4157 - accuracy: 0.8103 - val_loss: 0.6540 - val_accuracy: 0.7376\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4092 - accuracy: 0.8122 - val_loss: 0.6661 - val_accuracy: 0.7124\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4047 - accuracy: 0.8146 - val_loss: 0.7204 - val_accuracy: 0.7428\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3877 - accuracy: 0.8199 - val_loss: 0.6536 - val_accuracy: 0.7522\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3898 - accuracy: 0.8217 - val_loss: 0.6865 - val_accuracy: 0.7323\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3872 - accuracy: 0.8224 - val_loss: 0.7411 - val_accuracy: 0.7300\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3619 - accuracy: 0.8343 - val_loss: 0.6799 - val_accuracy: 0.7376\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3704 - accuracy: 0.8302 - val_loss: 0.7390 - val_accuracy: 0.7539\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3506 - accuracy: 0.8388 - val_loss: 0.6778 - val_accuracy: 0.7563\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3455 - accuracy: 0.8427 - val_loss: 0.7021 - val_accuracy: 0.7580\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3402 - accuracy: 0.8450 - val_loss: 0.7815 - val_accuracy: 0.7247\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3293 - accuracy: 0.8476 - val_loss: 0.7664 - val_accuracy: 0.7364\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3405 - accuracy: 0.8420 - val_loss: 0.7484 - val_accuracy: 0.7405\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3226 - accuracy: 0.8515 - val_loss: 0.7571 - val_accuracy: 0.7499\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3280 - accuracy: 0.8493 - val_loss: 0.7551 - val_accuracy: 0.7557\n",
      "Epoch 29/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3153 - accuracy: 0.8544 - val_loss: 0.7748 - val_accuracy: 0.7499\n",
      "Epoch 30/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3135 - accuracy: 0.8532 - val_loss: 0.7242 - val_accuracy: 0.7364\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df = pd.read_csv('../data/SisFall_train_L_20.csv')  # 훈련 파일\n",
    "test_df = pd.read_csv('../data/SisFall_val_L_20.csv')  # 테스트 파일\n",
    "\n",
    "X_train = []  # 훈련 입력 데이터\n",
    "y_train = []  # 훈련 출력 데이터\n",
    "\n",
    "X_test = []  # 테스트 입력 데이터\n",
    "y_test = []  # 테스트 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(train_df) - 19, 20):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = train_df.loc[i:i+19, 'gx'].values\n",
    "    gy_values = train_df.loc[i:i+19, 'gy'].values\n",
    "    gz_values = train_df.loc[i:i+19, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = train_df.loc[i:i+19, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_train.append(np.transpose([gx_values, gy_values, gz_values]))\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_train.append(labels[0])\n",
    "\n",
    "for i in range(0, len(test_df) - 19, 20):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = test_df.loc[i:i+19, 'gx'].values\n",
    "    gy_values = test_df.loc[i:i+19, 'gy'].values\n",
    "    gz_values = test_df.loc[i:i+19, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = test_df.loc[i:i+19, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_test.append(np.transpose([gx_values, gy_values, gz_values]))\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_test.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "onehot_encoder_train = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder_train.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = label_encoder.transform(y_test)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "onehot_encoder_test = OneHotEncoder(sparse_output=False)\n",
    "y_test = onehot_encoder_test.fit_transform(integer_encoded_test)\n",
    "\n",
    "# CNN-LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(20, 3)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))  # Dropout layer with 20% dropout rate\n",
    "model.add(BatchNormalization())  # Batch normalization layer\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_cnn_lstm.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_cnn_lstm.npy', label_encoder.classes_)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('../model/loaded_model_cnn_lstm.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T02:10:35.123338500Z",
     "start_time": "2023-06-14T02:09:29.626637400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "214/214 [==============================] - 5s 12ms/step - loss: 0.8670 - accuracy: 0.6299 - val_loss: 0.6914 - val_accuracy: 0.7101\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.6705 - accuracy: 0.7047 - val_loss: 0.6365 - val_accuracy: 0.7148\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.6186 - accuracy: 0.7249 - val_loss: 0.6541 - val_accuracy: 0.6990\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5882 - accuracy: 0.7353 - val_loss: 0.6942 - val_accuracy: 0.7013\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.5546 - accuracy: 0.7493 - val_loss: 0.6405 - val_accuracy: 0.7002\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5408 - accuracy: 0.7553 - val_loss: 0.6386 - val_accuracy: 0.7165\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.5181 - accuracy: 0.7638 - val_loss: 0.6432 - val_accuracy: 0.7160\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.5060 - accuracy: 0.7731 - val_loss: 0.6516 - val_accuracy: 0.7160\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4797 - accuracy: 0.7861 - val_loss: 0.6411 - val_accuracy: 0.7358\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.4634 - accuracy: 0.7927 - val_loss: 0.6333 - val_accuracy: 0.7434\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.4399 - accuracy: 0.7985 - val_loss: 0.6264 - val_accuracy: 0.7300\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4316 - accuracy: 0.8079 - val_loss: 0.6478 - val_accuracy: 0.7317\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4268 - accuracy: 0.8032 - val_loss: 0.6965 - val_accuracy: 0.7253\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.4265 - accuracy: 0.8065 - val_loss: 0.7038 - val_accuracy: 0.7183\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.4228 - accuracy: 0.8064 - val_loss: 0.6771 - val_accuracy: 0.7417\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.3951 - accuracy: 0.8162 - val_loss: 0.6834 - val_accuracy: 0.7387\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.3833 - accuracy: 0.8270 - val_loss: 0.7139 - val_accuracy: 0.7282\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.3746 - accuracy: 0.8285 - val_loss: 0.6677 - val_accuracy: 0.7417\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3643 - accuracy: 0.8333 - val_loss: 0.6759 - val_accuracy: 0.7545\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3698 - accuracy: 0.8319 - val_loss: 0.7387 - val_accuracy: 0.7510\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.3531 - accuracy: 0.8387 - val_loss: 0.7277 - val_accuracy: 0.7475\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.3564 - accuracy: 0.8377 - val_loss: 0.6753 - val_accuracy: 0.7335\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.3440 - accuracy: 0.8399 - val_loss: 0.7111 - val_accuracy: 0.7621\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3368 - accuracy: 0.8472 - val_loss: 0.7147 - val_accuracy: 0.7458\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3395 - accuracy: 0.8431 - val_loss: 0.7180 - val_accuracy: 0.7370\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3246 - accuracy: 0.8489 - val_loss: 0.7855 - val_accuracy: 0.7382\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3242 - accuracy: 0.8490 - val_loss: 0.8084 - val_accuracy: 0.7142\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.3199 - accuracy: 0.8536 - val_loss: 0.7795 - val_accuracy: 0.7288\n",
      "Epoch 29/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3223 - accuracy: 0.8495 - val_loss: 0.7832 - val_accuracy: 0.7212\n",
      "Epoch 30/30\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.3279 - accuracy: 0.8503 - val_loss: 0.8323 - val_accuracy: 0.7271\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df = pd.read_csv('../data/SisFall_train_L_20.csv')  # 훈련 파일\n",
    "test_df = pd.read_csv('../data/SisFall_val_L_20.csv')  # 테스트 파일\n",
    "\n",
    "X_train = []  # 훈련 입력 데이터\n",
    "y_train = []  # 훈련 출력 데이터\n",
    "\n",
    "X_test = []  # 테스트 입력 데이터\n",
    "y_test = []  # 테스트 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(train_df) - 19, 20):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = train_df.loc[i:i+19, 'gx'].values\n",
    "    gy_values = train_df.loc[i:i+19, 'gy'].values\n",
    "    gz_values = train_df.loc[i:i+19, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = train_df.loc[i:i+19, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_train.append(np.transpose([gx_values, gy_values, gz_values]))\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_train.append(labels[0])\n",
    "\n",
    "for i in range(0, len(test_df) - 19, 20):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = test_df.loc[i:i+19, 'gx'].values\n",
    "    gy_values = test_df.loc[i:i+19, 'gy'].values\n",
    "    gz_values = test_df.loc[i:i+19, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = test_df.loc[i:i+19, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_test.append(np.transpose([gx_values, gy_values, gz_values]))\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_test.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "onehot_encoder_train = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder_train.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = label_encoder.transform(y_test)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "onehot_encoder_test = OneHotEncoder(sparse_output=False)\n",
    "y_test = onehot_encoder_test.fit_transform(integer_encoded_test)\n",
    "\n",
    "# CNN-LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(20, 3)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))  # Dropout layer with 20% dropout rate\n",
    "model.add(BatchNormalization())  # Batch normalization layer\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_cnn_lstm.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_cnn_lstm.npy', label_encoder.classes_)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('../model/loaded_model_cnn_lstm.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T02:26:36.444569800Z",
     "start_time": "2023-06-14T02:25:28.022475400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
