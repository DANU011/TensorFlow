{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "208/208 [==============================] - 3s 6ms/step - loss: 1.0336 - accuracy: 0.6265 - val_loss: 0.8624 - val_accuracy: 0.6737\n",
      "Epoch 2/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7872 - val_loss: 0.7579 - val_accuracy: 0.7093\n",
      "Epoch 3/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8429 - val_loss: 0.7223 - val_accuracy: 0.7205\n",
      "Epoch 4/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8802 - val_loss: 0.7222 - val_accuracy: 0.7184\n",
      "Epoch 5/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.9126 - val_loss: 0.7134 - val_accuracy: 0.7296\n",
      "Epoch 6/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9374 - val_loss: 0.7192 - val_accuracy: 0.7435\n",
      "Epoch 7/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9496 - val_loss: 0.7531 - val_accuracy: 0.7331\n",
      "Epoch 8/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9616 - val_loss: 0.7499 - val_accuracy: 0.7386\n",
      "Epoch 9/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9707 - val_loss: 0.7905 - val_accuracy: 0.7331\n",
      "Epoch 10/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9744 - val_loss: 0.7876 - val_accuracy: 0.7428\n",
      "Epoch 11/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9756 - val_loss: 0.8352 - val_accuracy: 0.7289\n",
      "Epoch 12/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9806 - val_loss: 0.8514 - val_accuracy: 0.7324\n",
      "Epoch 13/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 0.8559 - val_accuracy: 0.7268\n",
      "Epoch 14/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 0.8725 - val_accuracy: 0.7331\n",
      "Epoch 15/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9844 - val_loss: 0.8853 - val_accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9863 - val_loss: 0.8941 - val_accuracy: 0.7324\n",
      "Epoch 17/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9844 - val_loss: 0.9194 - val_accuracy: 0.7303\n",
      "Epoch 18/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9877 - val_loss: 0.9568 - val_accuracy: 0.7268\n",
      "Epoch 19/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9839 - val_loss: 0.9912 - val_accuracy: 0.7170\n",
      "Epoch 20/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9856 - val_loss: 1.0032 - val_accuracy: 0.7275\n",
      "Epoch 21/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9872 - val_loss: 1.0040 - val_accuracy: 0.7275\n",
      "Epoch 22/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9856 - val_loss: 0.9598 - val_accuracy: 0.7310\n",
      "Epoch 23/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9874 - val_loss: 0.9778 - val_accuracy: 0.7484\n",
      "Epoch 24/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9908 - val_loss: 1.0152 - val_accuracy: 0.7393\n",
      "Epoch 25/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 1.0200 - val_accuracy: 0.7365\n",
      "Epoch 26/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 1.0514 - val_accuracy: 0.7400\n",
      "Epoch 27/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 1.0661 - val_accuracy: 0.7310\n",
      "Epoch 28/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 1.0675 - val_accuracy: 0.7456\n",
      "Epoch 29/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 1.0985 - val_accuracy: 0.7393\n",
      "Epoch 30/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 1.1204 - val_accuracy: 0.7352\n",
      "Epoch 31/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 1.1103 - val_accuracy: 0.7282\n",
      "Epoch 32/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9783 - val_loss: 1.1195 - val_accuracy: 0.7226\n",
      "Epoch 33/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9687 - val_loss: 1.0736 - val_accuracy: 0.7275\n",
      "Epoch 34/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9798 - val_loss: 1.0956 - val_accuracy: 0.7268\n",
      "Epoch 35/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9907 - val_loss: 1.1415 - val_accuracy: 0.7233\n",
      "Epoch 36/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 1.1430 - val_accuracy: 0.7268\n",
      "Epoch 37/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 1.1698 - val_accuracy: 0.7365\n",
      "Epoch 38/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 1.1892 - val_accuracy: 0.7393\n",
      "Epoch 39/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 1.2230 - val_accuracy: 0.7317\n",
      "Epoch 40/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.2184 - val_accuracy: 0.7358\n",
      "Epoch 41/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 1.2577 - val_accuracy: 0.7345\n",
      "Epoch 42/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 1.2465 - val_accuracy: 0.7498\n",
      "Epoch 43/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 1.2788 - val_accuracy: 0.7379\n",
      "Epoch 44/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 1.2785 - val_accuracy: 0.7449\n",
      "Epoch 45/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 1.2826 - val_accuracy: 0.7345\n",
      "Epoch 46/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.0155 - accuracy: 0.9937 - val_loss: 1.3062 - val_accuracy: 0.7247\n",
      "Epoch 47/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 1.3089 - val_accuracy: 0.7275\n",
      "Epoch 48/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 1.3065 - val_accuracy: 0.7358\n",
      "Epoch 49/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 1.3256 - val_accuracy: 0.7331\n",
      "Epoch 50/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.3509 - val_accuracy: 0.7338\n",
      "Epoch 51/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 1.3697 - val_accuracy: 0.7247\n",
      "Epoch 52/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 1.3575 - val_accuracy: 0.7317\n",
      "Epoch 53/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 1.3696 - val_accuracy: 0.7114\n",
      "Epoch 54/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9663 - val_loss: 1.2892 - val_accuracy: 0.7156\n",
      "Epoch 55/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9767 - val_loss: 1.3015 - val_accuracy: 0.7184\n",
      "Epoch 56/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9937 - val_loss: 1.3464 - val_accuracy: 0.7275\n",
      "Epoch 57/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 1.3478 - val_accuracy: 0.7247\n",
      "Epoch 58/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 1.3571 - val_accuracy: 0.7296\n",
      "Epoch 59/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 1.3692 - val_accuracy: 0.7268\n",
      "Epoch 60/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3847 - val_accuracy: 0.7275\n",
      "Epoch 61/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.3918 - val_accuracy: 0.7296\n",
      "Epoch 62/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 1.3937 - val_accuracy: 0.7310\n",
      "Epoch 63/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 1.4015 - val_accuracy: 0.7240\n",
      "Epoch 64/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 1.4167 - val_accuracy: 0.7303\n",
      "Epoch 65/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.4352 - val_accuracy: 0.7310\n",
      "Epoch 66/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.4445 - val_accuracy: 0.7310\n",
      "Epoch 67/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4460 - val_accuracy: 0.7352\n",
      "Epoch 68/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.4524 - val_accuracy: 0.7324\n",
      "Epoch 69/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 7.1104e-04 - accuracy: 1.0000 - val_loss: 1.4645 - val_accuracy: 0.7331\n",
      "Epoch 70/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 6.2851e-04 - accuracy: 1.0000 - val_loss: 1.4720 - val_accuracy: 0.7345\n",
      "Epoch 71/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 6.1653e-04 - accuracy: 1.0000 - val_loss: 1.4796 - val_accuracy: 0.7331\n",
      "Epoch 72/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 5.0705e-04 - accuracy: 1.0000 - val_loss: 1.4878 - val_accuracy: 0.7338\n",
      "Epoch 73/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 4.6179e-04 - accuracy: 1.0000 - val_loss: 1.4953 - val_accuracy: 0.7352\n",
      "Epoch 74/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 4.1664e-04 - accuracy: 1.0000 - val_loss: 1.4988 - val_accuracy: 0.7372\n",
      "Epoch 75/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 3.9124e-04 - accuracy: 1.0000 - val_loss: 1.5133 - val_accuracy: 0.7352\n",
      "Epoch 76/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 1.5478 - val_accuracy: 0.7065\n",
      "Epoch 77/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.2056 - accuracy: 0.9285 - val_loss: 1.2737 - val_accuracy: 0.7023\n",
      "Epoch 78/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.1086 - accuracy: 0.9612 - val_loss: 1.2612 - val_accuracy: 0.7156\n",
      "Epoch 79/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9919 - val_loss: 1.2775 - val_accuracy: 0.7261\n",
      "Epoch 80/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 1.3098 - val_accuracy: 0.7317\n",
      "Epoch 81/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 1.3239 - val_accuracy: 0.7365\n",
      "Epoch 82/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 1.3281 - val_accuracy: 0.7331\n",
      "Epoch 83/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3426 - val_accuracy: 0.7372\n",
      "Epoch 84/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 1.3511 - val_accuracy: 0.7386\n",
      "Epoch 85/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3618 - val_accuracy: 0.7400\n",
      "Epoch 86/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3676 - val_accuracy: 0.7386\n",
      "Epoch 87/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3741 - val_accuracy: 0.7393\n",
      "Epoch 88/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3719 - val_accuracy: 0.7414\n",
      "Epoch 89/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3888 - val_accuracy: 0.7407\n",
      "Epoch 90/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3917 - val_accuracy: 0.7414\n",
      "Epoch 91/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4025 - val_accuracy: 0.7379\n",
      "Epoch 92/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 9.4441e-04 - accuracy: 1.0000 - val_loss: 1.4108 - val_accuracy: 0.7365\n",
      "Epoch 93/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 8.5994e-04 - accuracy: 1.0000 - val_loss: 1.4169 - val_accuracy: 0.7372\n",
      "Epoch 94/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 7.9271e-04 - accuracy: 1.0000 - val_loss: 1.4199 - val_accuracy: 0.7372\n",
      "Epoch 95/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 6.9269e-04 - accuracy: 1.0000 - val_loss: 1.4311 - val_accuracy: 0.7407\n",
      "Epoch 96/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 6.3358e-04 - accuracy: 1.0000 - val_loss: 1.4354 - val_accuracy: 0.7386\n",
      "Epoch 97/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 5.8943e-04 - accuracy: 1.0000 - val_loss: 1.4465 - val_accuracy: 0.7379\n",
      "Epoch 98/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 5.1281e-04 - accuracy: 1.0000 - val_loss: 1.4492 - val_accuracy: 0.7379\n",
      "Epoch 99/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 4.7239e-04 - accuracy: 1.0000 - val_loss: 1.4616 - val_accuracy: 0.7421\n",
      "Epoch 100/100\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 4.2947e-04 - accuracy: 1.0000 - val_loss: 1.4702 - val_accuracy: 0.7386\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df = pd.read_csv('../data/SisFall_train.csv')  # 훈련 파일\n",
    "test_df = pd.read_csv('../data/SisFall_test.csv')  # 테스트 파일\n",
    "\n",
    "X_train = []  # 훈련 입력 데이터\n",
    "y_train = []  # 훈련 출력 데이터\n",
    "\n",
    "X_test = []  # 테스트 입력 데이터\n",
    "y_test = []  # 테스트 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(train_df) - 39, 40):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = train_df.loc[i:i+39, 'gx'].values\n",
    "    gy_values = train_df.loc[i:i+39, 'gy'].values\n",
    "    gz_values = train_df.loc[i:i+39, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = train_df.loc[i:i+39, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_train.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_train.append(labels[0])\n",
    "\n",
    "for i in range(0, len(test_df) - 39, 40):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = test_df.loc[i:i+39, 'gx'].values\n",
    "    gy_values = test_df.loc[i:i+39, 'gy'].values\n",
    "    gz_values = test_df.loc[i:i+39, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = test_df.loc[i:i+39, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_test.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_test.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = label_encoder.transform(y_test)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "y_test = onehot_encoder.transform(integer_encoded_test)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(3, 40)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = history.model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_lstm.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_lstm.npy', label_encoder.classes_)\n",
    "\n",
    "# 가중치를 로드하기 위해 모델 구성\n",
    "loaded_model = keras.models.Sequential()\n",
    "loaded_model.add(keras.layers.LSTM(128, input_shape=(3, 40)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "loaded_model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 피클 파일에서 가중치 로드\n",
    "loaded_model_weights = pickle.load(open('../model/best_model_weights_lstm.pkl', 'rb'))\n",
    "\n",
    "# 모델에 로드된 가중치 설정\n",
    "loaded_model.set_weights(loaded_model_weights)\n",
    "\n",
    "# 모델 컴파일\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장\n",
    "loaded_model.save('../model/loaded_model_lstm.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T07:40:36.994842500Z",
     "start_time": "2023-06-12T07:39:42.848495300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the training history\n",
    "train_loss = history.history['loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
