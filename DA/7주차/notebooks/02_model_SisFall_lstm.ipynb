{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "427/427 [==============================] - 3s 3ms/step - loss: 1.0303 - accuracy: 0.5756 - val_loss: 0.8544 - val_accuracy: 0.6692\n",
      "Epoch 2/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.7200 - val_loss: 0.8169 - val_accuracy: 0.6768\n",
      "Epoch 3/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.5777 - accuracy: 0.7743 - val_loss: 0.8080 - val_accuracy: 0.6873\n",
      "Epoch 4/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.4955 - accuracy: 0.8065 - val_loss: 0.7934 - val_accuracy: 0.7037\n",
      "Epoch 5/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.8359 - val_loss: 0.8235 - val_accuracy: 0.7049\n",
      "Epoch 6/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.3685 - accuracy: 0.8627 - val_loss: 0.8355 - val_accuracy: 0.7066\n",
      "Epoch 7/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8858 - val_loss: 0.9002 - val_accuracy: 0.6920\n",
      "Epoch 8/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9023 - val_loss: 0.9498 - val_accuracy: 0.6920\n",
      "Epoch 9/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9157 - val_loss: 0.9910 - val_accuracy: 0.6821\n",
      "Epoch 10/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2212 - accuracy: 0.9273 - val_loss: 1.0259 - val_accuracy: 0.6826\n",
      "Epoch 11/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1980 - accuracy: 0.9359 - val_loss: 1.0748 - val_accuracy: 0.6750\n",
      "Epoch 12/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1846 - accuracy: 0.9395 - val_loss: 1.0878 - val_accuracy: 0.6780\n",
      "Epoch 13/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1698 - accuracy: 0.9455 - val_loss: 1.1066 - val_accuracy: 0.6897\n",
      "Epoch 14/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9487 - val_loss: 1.1826 - val_accuracy: 0.6739\n",
      "Epoch 15/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1480 - accuracy: 0.9516 - val_loss: 1.2180 - val_accuracy: 0.6815\n",
      "Epoch 16/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1320 - accuracy: 0.9567 - val_loss: 1.2474 - val_accuracy: 0.6791\n",
      "Epoch 17/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1209 - accuracy: 0.9603 - val_loss: 1.2642 - val_accuracy: 0.6879\n",
      "Epoch 18/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1084 - accuracy: 0.9647 - val_loss: 1.3229 - val_accuracy: 0.6826\n",
      "Epoch 19/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9693 - val_loss: 1.3420 - val_accuracy: 0.6797\n",
      "Epoch 20/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9705 - val_loss: 1.3517 - val_accuracy: 0.6914\n",
      "Epoch 21/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9698 - val_loss: 1.3840 - val_accuracy: 0.6809\n",
      "Epoch 22/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1123 - accuracy: 0.9612 - val_loss: 1.4526 - val_accuracy: 0.6786\n",
      "Epoch 23/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.9550 - val_loss: 1.4392 - val_accuracy: 0.6710\n",
      "Epoch 24/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1036 - accuracy: 0.9647 - val_loss: 1.4559 - val_accuracy: 0.6727\n",
      "Epoch 25/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9771 - val_loss: 1.4652 - val_accuracy: 0.6727\n",
      "Epoch 26/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 1.4852 - val_accuracy: 0.6786\n",
      "Epoch 27/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.9843 - val_loss: 1.4904 - val_accuracy: 0.6762\n",
      "Epoch 28/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 1.5364 - val_accuracy: 0.6826\n",
      "Epoch 29/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0412 - accuracy: 0.9889 - val_loss: 1.5850 - val_accuracy: 0.6750\n",
      "Epoch 30/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 1.5639 - val_accuracy: 0.6861\n",
      "Epoch 31/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0439 - accuracy: 0.9863 - val_loss: 1.5870 - val_accuracy: 0.6844\n",
      "Epoch 32/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.9707 - val_loss: 1.6396 - val_accuracy: 0.6657\n",
      "Epoch 33/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9544 - val_loss: 1.6465 - val_accuracy: 0.6651\n",
      "Epoch 34/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9672 - val_loss: 1.6960 - val_accuracy: 0.6739\n",
      "Epoch 35/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9856 - val_loss: 1.6618 - val_accuracy: 0.6733\n",
      "Epoch 36/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0401 - accuracy: 0.9894 - val_loss: 1.6477 - val_accuracy: 0.6797\n",
      "Epoch 37/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9930 - val_loss: 1.6407 - val_accuracy: 0.6908\n",
      "Epoch 38/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9952 - val_loss: 1.6963 - val_accuracy: 0.6850\n",
      "Epoch 39/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 1.7518 - val_accuracy: 0.6780\n",
      "Epoch 40/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 1.7610 - val_accuracy: 0.6803\n",
      "Epoch 41/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 1.7869 - val_accuracy: 0.6786\n",
      "Epoch 42/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 1.8466 - val_accuracy: 0.6768\n",
      "Epoch 43/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.9765 - val_loss: 1.8837 - val_accuracy: 0.6774\n",
      "Epoch 44/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1165 - accuracy: 0.9589 - val_loss: 1.8654 - val_accuracy: 0.6715\n",
      "Epoch 45/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0844 - accuracy: 0.9694 - val_loss: 1.8700 - val_accuracy: 0.6645\n",
      "Epoch 46/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 1.8638 - val_accuracy: 0.6739\n",
      "Epoch 47/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0300 - accuracy: 0.9927 - val_loss: 1.9160 - val_accuracy: 0.6733\n",
      "Epoch 48/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.9970 - val_loss: 1.9568 - val_accuracy: 0.6674\n",
      "Epoch 49/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 1.9259 - val_accuracy: 0.6780\n",
      "Epoch 50/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 1.9693 - val_accuracy: 0.6727\n",
      "Epoch 51/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 1.9755 - val_accuracy: 0.6780\n",
      "Epoch 52/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 1.9849 - val_accuracy: 0.6739\n",
      "Epoch 53/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 2.0355 - val_accuracy: 0.6727\n",
      "Epoch 54/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9685 - val_loss: 2.0027 - val_accuracy: 0.6704\n",
      "Epoch 55/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.9688 - val_loss: 2.0551 - val_accuracy: 0.6628\n",
      "Epoch 56/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0508 - accuracy: 0.9829 - val_loss: 2.0347 - val_accuracy: 0.6745\n",
      "Epoch 57/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 2.0493 - val_accuracy: 0.6786\n",
      "Epoch 58/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 2.0279 - val_accuracy: 0.6809\n",
      "Epoch 59/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 2.1062 - val_accuracy: 0.6739\n",
      "Epoch 60/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 2.0820 - val_accuracy: 0.6774\n",
      "Epoch 61/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 2.1105 - val_accuracy: 0.6791\n",
      "Epoch 62/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 2.0820 - val_accuracy: 0.6745\n",
      "Epoch 63/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9888 - val_loss: 2.0587 - val_accuracy: 0.6721\n",
      "Epoch 64/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9677 - val_loss: 2.0400 - val_accuracy: 0.6610\n",
      "Epoch 65/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9735 - val_loss: 2.0700 - val_accuracy: 0.6791\n",
      "Epoch 66/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0398 - accuracy: 0.9888 - val_loss: 2.0525 - val_accuracy: 0.6774\n",
      "Epoch 67/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 2.0505 - val_accuracy: 0.6750\n",
      "Epoch 68/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 2.0625 - val_accuracy: 0.6745\n",
      "Epoch 69/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 2.1145 - val_accuracy: 0.6750\n",
      "Epoch 70/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 2.1335 - val_accuracy: 0.6745\n",
      "Epoch 71/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 2.0967 - val_accuracy: 0.6780\n",
      "Epoch 72/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 2.1415 - val_accuracy: 0.6844\n",
      "Epoch 73/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 2.1751 - val_accuracy: 0.6838\n",
      "Epoch 74/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.9654 - val_loss: 2.0792 - val_accuracy: 0.6686\n",
      "Epoch 75/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9671 - val_loss: 2.0582 - val_accuracy: 0.6821\n",
      "Epoch 76/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9797 - val_loss: 2.0973 - val_accuracy: 0.6774\n",
      "Epoch 77/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 2.1085 - val_accuracy: 0.6844\n",
      "Epoch 78/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 2.1297 - val_accuracy: 0.6821\n",
      "Epoch 79/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 2.1282 - val_accuracy: 0.6832\n",
      "Epoch 80/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1415 - val_accuracy: 0.6809\n",
      "Epoch 81/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.1417 - val_accuracy: 0.6838\n",
      "Epoch 82/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1533 - val_accuracy: 0.6791\n",
      "Epoch 83/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1668 - val_accuracy: 0.6780\n",
      "Epoch 84/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1705 - val_accuracy: 0.6815\n",
      "Epoch 85/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 9.7761e-04 - accuracy: 1.0000 - val_loss: 2.1786 - val_accuracy: 0.6821\n",
      "Epoch 86/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 7.8717e-04 - accuracy: 1.0000 - val_loss: 2.2052 - val_accuracy: 0.6803\n",
      "Epoch 87/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 6.7338e-04 - accuracy: 1.0000 - val_loss: 2.2138 - val_accuracy: 0.6803\n",
      "Epoch 88/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 5.9347e-04 - accuracy: 1.0000 - val_loss: 2.2254 - val_accuracy: 0.6832\n",
      "Epoch 89/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9953 - val_loss: 2.2264 - val_accuracy: 0.6698\n",
      "Epoch 90/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8861 - val_loss: 2.0001 - val_accuracy: 0.6710\n",
      "Epoch 91/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.1394 - accuracy: 0.9515 - val_loss: 1.9946 - val_accuracy: 0.6780\n",
      "Epoch 92/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 2.0341 - val_accuracy: 0.6774\n",
      "Epoch 93/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0290 - accuracy: 0.9940 - val_loss: 2.0328 - val_accuracy: 0.6721\n",
      "Epoch 94/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0152 - accuracy: 0.9985 - val_loss: 2.0491 - val_accuracy: 0.6745\n",
      "Epoch 95/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 2.0791 - val_accuracy: 0.6692\n",
      "Epoch 96/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9999 - val_loss: 2.1078 - val_accuracy: 0.6721\n",
      "Epoch 97/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 2.1177 - val_accuracy: 0.6680\n",
      "Epoch 98/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1188 - val_accuracy: 0.6686\n",
      "Epoch 99/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 2.1501 - val_accuracy: 0.6680\n",
      "Epoch 100/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 2.1900 - val_accuracy: 0.6704\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df = pd.read_csv('../data/SisFall_train_L.csv')  # 훈련 파일\n",
    "test_df = pd.read_csv('../data/SisFall_val_L.csv')  # 테스트 파일\n",
    "\n",
    "X_train = []  # 훈련 입력 데이터\n",
    "y_train = []  # 훈련 출력 데이터\n",
    "\n",
    "X_test = []  # 테스트 입력 데이터\n",
    "y_test = []  # 테스트 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(train_df) - 39, 40):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = train_df.loc[i:i+39, 'gx'].values\n",
    "    gy_values = train_df.loc[i:i+39, 'gy'].values\n",
    "    gz_values = train_df.loc[i:i+39, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = train_df.loc[i:i+39, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_train.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_train.append(labels[0])\n",
    "\n",
    "for i in range(0, len(test_df) - 39, 40):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = test_df.loc[i:i+39, 'gx'].values\n",
    "    gy_values = test_df.loc[i:i+39, 'gy'].values\n",
    "    gz_values = test_df.loc[i:i+39, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = test_df.loc[i:i+39, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_test.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_test.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = label_encoder.transform(y_test)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "y_test = onehot_encoder.transform(integer_encoded_test)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(3, 40)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = history.model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_lstm.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_lstm.npy', label_encoder.classes_)\n",
    "\n",
    "# 가중치를 로드하기 위해 모델 구성\n",
    "loaded_model = keras.models.Sequential()\n",
    "loaded_model.add(keras.layers.LSTM(128, input_shape=(3, 40)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "loaded_model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 피클 파일에서 가중치 로드\n",
    "loaded_model_weights = pickle.load(open('../model/best_model_weights_lstm.pkl', 'rb'))\n",
    "\n",
    "# 모델에 로드된 가중치 설정\n",
    "loaded_model.set_weights(loaded_model_weights)\n",
    "\n",
    "# 모델 컴파일\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장\n",
    "loaded_model.save('../model/loaded_model_lstm.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T08:49:45.865602Z",
     "start_time": "2023-06-13T08:48:05.072634100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the training history\n",
    "train_loss = history.history['loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "427/427 [==============================] - 3s 4ms/step - loss: 1.0523 - accuracy: 0.5757 - val_loss: 0.8567 - val_accuracy: 0.6669\n",
      "Epoch 2/100\n",
      "427/427 [==============================] - 1s 3ms/step - loss: 0.7163 - accuracy: 0.7119 - val_loss: 0.8137 - val_accuracy: 0.6809\n",
      "Epoch 3/100\n",
      "427/427 [==============================] - 1s 3ms/step - loss: 0.6036 - accuracy: 0.7594 - val_loss: 0.8248 - val_accuracy: 0.6838\n",
      "Epoch 4/100\n",
      "427/427 [==============================] - 1s 3ms/step - loss: 0.5250 - accuracy: 0.7938 - val_loss: 0.8306 - val_accuracy: 0.6797\n",
      "Epoch 5/100\n",
      "427/427 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8200 - val_loss: 0.9033 - val_accuracy: 0.6657\n",
      "Epoch 6/100\n",
      "427/427 [==============================] - 1s 3ms/step - loss: 0.4104 - accuracy: 0.8468 - val_loss: 0.8909 - val_accuracy: 0.6721\n",
      "Epoch 7/100\n",
      "427/427 [==============================] - 1s 3ms/step - loss: 0.3647 - accuracy: 0.8673 - val_loss: 0.9021 - val_accuracy: 0.6832\n",
      "Epoch 8/100\n",
      "427/427 [==============================] - 1s 3ms/step - loss: 0.3253 - accuracy: 0.8827 - val_loss: 0.9861 - val_accuracy: 0.6669\n",
      "Epoch 9/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2915 - accuracy: 0.8976 - val_loss: 1.0375 - val_accuracy: 0.6669\n",
      "Epoch 10/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.9100 - val_loss: 1.0094 - val_accuracy: 0.6680\n",
      "Epoch 11/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.9160 - val_loss: 1.0603 - val_accuracy: 0.6710\n",
      "Epoch 12/100\n",
      "427/427 [==============================] - 1s 2ms/step - loss: 0.2157 - accuracy: 0.9260 - val_loss: 1.1481 - val_accuracy: 0.6651\n",
      "Epoch 13/100\n",
      "427/427 [==============================] - 1s 3ms/step - loss: 0.2022 - accuracy: 0.9301 - val_loss: 1.1888 - val_accuracy: 0.6353\n",
      "Epoch 14/100\n",
      "272/427 [==================>...........] - ETA: 0s - loss: 0.1774 - accuracy: 0.9383"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 77\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# 모델 컴파일 및 학습\u001B[39;00m\n\u001B[0;32m     76\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 77\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;66;03m# 최상의 적합 모델의 가중치를 피클 파일로 저장\u001B[39;00m\n\u001B[0;32m     80\u001B[0m best_model_weights \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mget_weights()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df = pd.read_csv('../data/SisFall_train_L_20.csv')  # 훈련 파일\n",
    "test_df = pd.read_csv('../data/SisFall_val_L_20.csv')  # 테스트 파일\n",
    "\n",
    "X_train = []  # 훈련 입력 데이터\n",
    "y_train = []  # 훈련 출력 데이터\n",
    "\n",
    "X_test = []  # 테스트 입력 데이터\n",
    "y_test = []  # 테스트 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(train_df) - 19, 20):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = train_df.loc[i:i+19, 'gx'].values\n",
    "    gy_values = train_df.loc[i:i+19, 'gy'].values\n",
    "    gz_values = train_df.loc[i:i+19, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = train_df.loc[i:i+19, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_train.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_train.append(labels[0])\n",
    "\n",
    "for i in range(0, len(test_df) - 19, 20):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = test_df.loc[i:i+19, 'gx'].values\n",
    "    gy_values = test_df.loc[i:i+19, 'gy'].values\n",
    "    gz_values = test_df.loc[i:i+19, 'gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = test_df.loc[i:i+19, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X_test.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y_test.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = onehot_encoder.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = label_encoder.transform(y_test)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "y_test = onehot_encoder.transform(integer_encoded_test)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(3, 20)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = history.model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_lstm.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_lstm.npy', label_encoder.classes_)\n",
    "\n",
    "# 가중치를 로드하기 위해 모델 구성\n",
    "loaded_model = keras.models.Sequential()\n",
    "loaded_model.add(keras.layers.LSTM(128, input_shape=(3, 20)))  # 3개의 시퀀스, 각 시퀀스에 40개의 피처\n",
    "loaded_model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 피클 파일에서 가중치 로드\n",
    "loaded_model_weights = pickle.load(open('../model/best_model_weights_lstm.pkl', 'rb'))\n",
    "\n",
    "# 모델에 로드된 가중치 설정\n",
    "loaded_model.set_weights(loaded_model_weights)\n",
    "\n",
    "# 모델 컴파일\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장\n",
    "loaded_model.save('../model/loaded_model_lstm.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T01:00:59.905496800Z",
     "start_time": "2023-06-14T01:00:33.598681600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
