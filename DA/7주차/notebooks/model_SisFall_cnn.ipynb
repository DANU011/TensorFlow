{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_ID trial_ID task_ID         gx         gy         gz     label   \n",
      "0         SA01      R01     D01  -1.098633 -30.761719 -21.484375   walking  \\\n",
      "1         SA01      R01     D01 -10.864258 -46.752930  -3.173828   walking   \n",
      "2         SA01      R01     D01  31.860352 -22.216797   8.056641   walking   \n",
      "3         SA01      R01     D01   2.624512 -11.352539  29.052734   walking   \n",
      "4         SA01      R01     D01   7.263184  15.869141  26.184082   walking   \n",
      "...        ...      ...     ...        ...        ...        ...       ...   \n",
      "331797    SE15      R05     D07  -1.281738   3.601074  -0.366211  standing   \n",
      "331798    SE15      R05     D07  -1.586914   3.295898  -0.610352  standing   \n",
      "331799    SE15      R05     D07  -1.586914   3.173828  -0.915527  standing   \n",
      "331800    SE15      R05     D07  -1.525879   2.868652  -0.976562  standing   \n",
      "331801    SE15      R05     D07  -1.281738   3.051758  -0.915527  standing   \n",
      "\n",
      "        scaled_gx  scaled_gy  scaled_gz  \n",
      "0        0.015592   0.010843   0.042287  \n",
      "1        0.001771  -0.010123   0.066825  \n",
      "2        0.062238   0.022046   0.081875  \n",
      "3        0.020861   0.036290   0.110011  \n",
      "4        0.027426   0.071980   0.106167  \n",
      "...           ...        ...        ...  \n",
      "331797   0.015333   0.055896   0.070587  \n",
      "331798   0.014901   0.055496   0.070260  \n",
      "331799   0.014901   0.055335   0.069851  \n",
      "331800   0.014987   0.054935   0.069769  \n",
      "331801   0.015333   0.055175   0.069851  \n",
      "\n",
      "[331802 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/SisFall_df_sc.csv\")\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T02:42:26.289761300Z",
     "start_time": "2023-06-09T02:42:25.837267900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 7s 2ms/step - loss: 1.4584 - accuracy: 0.3500\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 1.2018 - accuracy: 0.4780\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 1.1664 - accuracy: 0.4956\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 1.1092 - accuracy: 0.5207\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 1.0512 - accuracy: 0.5505\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 1.0113 - accuracy: 0.5694\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9722 - accuracy: 0.5918\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9518 - accuracy: 0.6021\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9383 - accuracy: 0.6086\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9268 - accuracy: 0.6149\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9177 - accuracy: 0.6188\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9094 - accuracy: 0.6227\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9000 - accuracy: 0.6261\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8917 - accuracy: 0.6284\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8848 - accuracy: 0.6320\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8786 - accuracy: 0.6339\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8723 - accuracy: 0.6383\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8672 - accuracy: 0.6389\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8609 - accuracy: 0.6415\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8564 - accuracy: 0.6429\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8501 - accuracy: 0.6461\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8455 - accuracy: 0.6476\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8399 - accuracy: 0.6500\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8351 - accuracy: 0.6516\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8310 - accuracy: 0.6538\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8258 - accuracy: 0.6536\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8221 - accuracy: 0.6581\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8182 - accuracy: 0.6575\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8137 - accuracy: 0.6604\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8110 - accuracy: 0.6622\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8073 - accuracy: 0.6631\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8035 - accuracy: 0.6651\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7998 - accuracy: 0.6654\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7975 - accuracy: 0.6663\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7925 - accuracy: 0.6692\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7892 - accuracy: 0.6715\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7865 - accuracy: 0.6706\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7827 - accuracy: 0.6722\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7796 - accuracy: 0.6742\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7766 - accuracy: 0.6741\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7725 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7695 - accuracy: 0.6783\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7667 - accuracy: 0.6793\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7639 - accuracy: 0.6796\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7598 - accuracy: 0.6826\n",
      "Epoch 46/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7571 - accuracy: 0.6820\n",
      "Epoch 47/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7529 - accuracy: 0.6846\n",
      "Epoch 48/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7502 - accuracy: 0.6854\n",
      "Epoch 49/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7487 - accuracy: 0.6877\n",
      "Epoch 50/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7446 - accuracy: 0.6881\n",
      "Epoch 51/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7420 - accuracy: 0.6893\n",
      "Epoch 52/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7388 - accuracy: 0.6906\n",
      "Epoch 53/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7359 - accuracy: 0.6922\n",
      "Epoch 54/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7326 - accuracy: 0.6929\n",
      "Epoch 55/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7293 - accuracy: 0.6950\n",
      "Epoch 56/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7272 - accuracy: 0.6950\n",
      "Epoch 57/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7234 - accuracy: 0.6975\n",
      "Epoch 58/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7207 - accuracy: 0.6970\n",
      "Epoch 59/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7185 - accuracy: 0.6981\n",
      "Epoch 60/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7153 - accuracy: 0.6989\n",
      "Epoch 61/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7136 - accuracy: 0.7024\n",
      "Epoch 62/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7113 - accuracy: 0.7012\n",
      "Epoch 63/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7084 - accuracy: 0.7022\n",
      "Epoch 64/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7045 - accuracy: 0.7052\n",
      "Epoch 65/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7031 - accuracy: 0.7050\n",
      "Epoch 66/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7000 - accuracy: 0.7069\n",
      "Epoch 67/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6973 - accuracy: 0.7086\n",
      "Epoch 68/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6955 - accuracy: 0.7085\n",
      "Epoch 69/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6925 - accuracy: 0.7087\n",
      "Epoch 70/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6908 - accuracy: 0.7108\n",
      "Epoch 71/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6867 - accuracy: 0.7126\n",
      "Epoch 72/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6863 - accuracy: 0.7129\n",
      "Epoch 73/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6825 - accuracy: 0.7138\n",
      "Epoch 74/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6810 - accuracy: 0.7150\n",
      "Epoch 75/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6786 - accuracy: 0.7165\n",
      "Epoch 76/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6756 - accuracy: 0.7166\n",
      "Epoch 77/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6744 - accuracy: 0.7179\n",
      "Epoch 78/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6708 - accuracy: 0.7198\n",
      "Epoch 79/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6689 - accuracy: 0.7199\n",
      "Epoch 80/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6663 - accuracy: 0.7218\n",
      "Epoch 81/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6643 - accuracy: 0.7224\n",
      "Epoch 82/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6631 - accuracy: 0.7238\n",
      "Epoch 83/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6605 - accuracy: 0.7243\n",
      "Epoch 84/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6579 - accuracy: 0.7244\n",
      "Epoch 85/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6555 - accuracy: 0.7245\n",
      "Epoch 86/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6539 - accuracy: 0.7262\n",
      "Epoch 87/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6519 - accuracy: 0.7288\n",
      "Epoch 88/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6490 - accuracy: 0.7294\n",
      "Epoch 89/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6477 - accuracy: 0.7296\n",
      "Epoch 90/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6451 - accuracy: 0.7289\n",
      "Epoch 91/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6435 - accuracy: 0.7316\n",
      "Epoch 92/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6410 - accuracy: 0.7331\n",
      "Epoch 93/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6403 - accuracy: 0.7338\n",
      "Epoch 94/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6371 - accuracy: 0.7343\n",
      "Epoch 95/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6353 - accuracy: 0.7348\n",
      "Epoch 96/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6337 - accuracy: 0.7354\n",
      "Epoch 97/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6310 - accuracy: 0.7366\n",
      "Epoch 98/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6295 - accuracy: 0.7373\n",
      "Epoch 99/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6274 - accuracy: 0.7379\n",
      "Epoch 100/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6253 - accuracy: 0.7388\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Arduino/fall_sc_cnn.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 74\u001B[0m\n\u001B[0;32m     71\u001B[0m loaded_model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../model/loaded_model_cnn.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;66;03m# 예측할 데이터 불러오기\u001B[39;00m\n\u001B[1;32m---> 74\u001B[0m pred_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../data/Arduino/fall_sc_cnn.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;66;03m# 입력 데이터 준비\u001B[39;00m\n\u001B[0;32m     77\u001B[0m X_pred \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# 입력 데이터\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1664\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1670\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    863\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/Arduino/fall_sc_cnn.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=100, batch_size=32)\n",
    "\n",
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = history.model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights_cnn.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes_cnn.npy', label_encoder.classes_)\n",
    "\n",
    "# 가중치를 로드하기 위해 모델 구성\n",
    "loaded_model = keras.models.Sequential()\n",
    "loaded_model.add(keras.layers.LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "loaded_model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 피클 파일에서 가중치 로드\n",
    "loaded_model_weights = pickle.load(open('../model/best_model_weights_cnn.pkl', 'rb'))\n",
    "\n",
    "# 모델에 로드된 가중치 설정\n",
    "loaded_model.set_weights(loaded_model_weights)\n",
    "\n",
    "# 모델 컴파일\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장\n",
    "loaded_model.save('../model/loaded_model_cnn.h5')\n",
    "\n",
    "# 예측할 데이터 불러오기\n",
    "pred_df = pd.read_csv('../data/Arduino/fall_sc_cnn.csv')\n",
    "\n",
    "# 입력 데이터 준비\n",
    "X_pred = []  # 입력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(pred_df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = pred_df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = pred_df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = pred_df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 데이터 형상 조정\n",
    "    gx_values = np.transpose(gx_values)\n",
    "    gy_values = np.transpose(gy_values)\n",
    "    gz_values = np.transpose(gz_values)\n",
    "\n",
    "    # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "    X_pred.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "# 입력 데이터를 넘파이 배열로 변환\n",
    "X_pred = np.array(X_pred)\n",
    "\n",
    "# 모델 로드\n",
    "try:\n",
    "    best_model = keras.models.load_model('../model/loaded_model_cnn.h5')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"모델 파일을 찾을 수 없습니다: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 모델을 사용하여 예측\n",
    "predictions = best_model.predict(X_pred)\n",
    "\n",
    "# 예측 결과 디코딩\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('../model/label_encoder_classes_cnn.npy')\n",
    "decoded_predictions = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "# 예측 결과를 데이터프레임에 추가\n",
    "pred_df['predicted_label_cnn'] = np.repeat(decoded_predictions, 4)\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "pred_df.to_csv('../data/prediction_results_cnn.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T03:17:51.228019400Z",
     "start_time": "2023-06-09T03:09:12.474409800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# 예측할 데이터 불러오기\n",
    "pred_df = pd.read_csv('../data/Arduino/fall_sc.csv')\n",
    "\n",
    "# 입력 데이터 준비\n",
    "X_pred = []  # 입력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(pred_df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = pred_df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = pred_df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = pred_df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 데이터 형상 조정\n",
    "    gx_values = np.transpose(gx_values)\n",
    "    gy_values = np.transpose(gy_values)\n",
    "    gz_values = np.transpose(gz_values)\n",
    "\n",
    "    # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "    X_pred.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "# 입력 데이터를 넘파이 배열로 변환\n",
    "X_pred = np.array(X_pred)\n",
    "\n",
    "# 모델 로드\n",
    "try:\n",
    "    best_model = keras.models.load_model('../model/loaded_model_cnn.h5')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"모델 파일을 찾을 수 없습니다: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 모델을 사용하여 예측\n",
    "predictions = best_model.predict(X_pred)\n",
    "\n",
    "# 예측 결과 디코딩\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('../model/label_encoder_classes_cnn.npy')\n",
    "decoded_predictions = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "# 예측 결과를 데이터프레임에 추가\n",
    "pred_df['predicted_label_cnn'] = np.repeat(decoded_predictions, 4)\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "pred_df.to_csv('../data/prediction_results_cnn.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T03:21:29.811809500Z",
     "start_time": "2023-06-09T03:21:28.817832700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# 데이터셋 준비\n",
    "X = []  # 입력 데이터\n",
    "y = []  # 출력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 레이블 값 가져오기\n",
    "    labels = df.loc[i:i+3, 'label'].values\n",
    "\n",
    "    # 서로 다른 레이블이 포함된 경우 해당 시퀀스는 분석에서 제외\n",
    "    if len(set(labels)) == 1:\n",
    "        # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "        X.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "        # 레이블 값 중복 제거하여 출력 데이터에 추가\n",
    "        y.append(labels[0])\n",
    "\n",
    "# 입력 데이터와 출력 데이터를 넘파이 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 출력 데이터를 One-Hot 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T03:31:31.164647200Z",
     "start_time": "2023-06-09T03:31:14.070384300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 7s 2ms/step - loss: 1.5233 - accuracy: 0.3102\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 1.2342 - accuracy: 0.4656\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 1.1547 - accuracy: 0.5015\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 1.0542 - accuracy: 0.5506\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9962 - accuracy: 0.5817\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9684 - accuracy: 0.5953\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.9537 - accuracy: 0.6011\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9451 - accuracy: 0.6066\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9372 - accuracy: 0.6092\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9307 - accuracy: 0.6107\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.9243 - accuracy: 0.6144\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.9194 - accuracy: 0.6170\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.9142 - accuracy: 0.6196\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.9083 - accuracy: 0.6217\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.9034 - accuracy: 0.6232\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8985 - accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8929 - accuracy: 0.6282\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8871 - accuracy: 0.6291\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8820 - accuracy: 0.6314\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8767 - accuracy: 0.6340\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8720 - accuracy: 0.6360\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8676 - accuracy: 0.6373\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8608 - accuracy: 0.6400\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8550 - accuracy: 0.6420\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8500 - accuracy: 0.6448\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8441 - accuracy: 0.6457\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8398 - accuracy: 0.6481\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8337 - accuracy: 0.6522\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8300 - accuracy: 0.6520\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8271 - accuracy: 0.6534\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8221 - accuracy: 0.6561\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8176 - accuracy: 0.6578\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8142 - accuracy: 0.6596\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8112 - accuracy: 0.6616\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8064 - accuracy: 0.6621\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8035 - accuracy: 0.6638\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.8004 - accuracy: 0.6643\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7966 - accuracy: 0.6663\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7944 - accuracy: 0.6668\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7906 - accuracy: 0.6664\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7872 - accuracy: 0.6684\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7833 - accuracy: 0.6701\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7809 - accuracy: 0.6716\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7780 - accuracy: 0.6729\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7745 - accuracy: 0.6738\n",
      "Epoch 46/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7718 - accuracy: 0.6760\n",
      "Epoch 47/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.7683 - accuracy: 0.6779\n",
      "Epoch 48/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.7658 - accuracy: 0.6777\n",
      "Epoch 49/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.7618 - accuracy: 0.6791\n",
      "Epoch 50/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7602 - accuracy: 0.6798\n",
      "Epoch 51/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7569 - accuracy: 0.6799\n",
      "Epoch 52/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7537 - accuracy: 0.6835\n",
      "Epoch 53/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7505 - accuracy: 0.6845\n",
      "Epoch 54/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7483 - accuracy: 0.6860\n",
      "Epoch 55/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7449 - accuracy: 0.6870\n",
      "Epoch 56/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7424 - accuracy: 0.6878\n",
      "Epoch 57/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7398 - accuracy: 0.6887\n",
      "Epoch 58/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7370 - accuracy: 0.6894\n",
      "Epoch 59/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7338 - accuracy: 0.6911\n",
      "Epoch 60/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7314 - accuracy: 0.6927\n",
      "Epoch 61/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7288 - accuracy: 0.6938\n",
      "Epoch 62/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.7262 - accuracy: 0.6945\n",
      "Epoch 63/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.7241 - accuracy: 0.6934\n",
      "Epoch 64/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.7211 - accuracy: 0.6956\n",
      "Epoch 65/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.7189 - accuracy: 0.6980\n",
      "Epoch 66/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7167 - accuracy: 0.6996\n",
      "Epoch 67/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7144 - accuracy: 0.6997\n",
      "Epoch 68/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7108 - accuracy: 0.6996\n",
      "Epoch 69/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7084 - accuracy: 0.7030\n",
      "Epoch 70/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7063 - accuracy: 0.7034\n",
      "Epoch 71/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7042 - accuracy: 0.7034\n",
      "Epoch 72/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7012 - accuracy: 0.7054\n",
      "Epoch 73/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.7002 - accuracy: 0.7055\n",
      "Epoch 74/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6970 - accuracy: 0.7070\n",
      "Epoch 75/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6951 - accuracy: 0.7081\n",
      "Epoch 76/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6926 - accuracy: 0.7090\n",
      "Epoch 77/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6903 - accuracy: 0.7092\n",
      "Epoch 78/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6874 - accuracy: 0.7116\n",
      "Epoch 79/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6849 - accuracy: 0.7115\n",
      "Epoch 80/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6841 - accuracy: 0.7118\n",
      "Epoch 81/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6818 - accuracy: 0.7132\n",
      "Epoch 82/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6786 - accuracy: 0.7145\n",
      "Epoch 83/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6764 - accuracy: 0.7162\n",
      "Epoch 84/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6757 - accuracy: 0.7161\n",
      "Epoch 85/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6723 - accuracy: 0.7171\n",
      "Epoch 86/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6707 - accuracy: 0.7173\n",
      "Epoch 87/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6684 - accuracy: 0.7198\n",
      "Epoch 88/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6651 - accuracy: 0.7203\n",
      "Epoch 89/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6635 - accuracy: 0.7207\n",
      "Epoch 90/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6624 - accuracy: 0.7230\n",
      "Epoch 91/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6604 - accuracy: 0.7223\n",
      "Epoch 92/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6572 - accuracy: 0.7252\n",
      "Epoch 93/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6560 - accuracy: 0.7238\n",
      "Epoch 94/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6543 - accuracy: 0.7256\n",
      "Epoch 95/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6514 - accuracy: 0.7264\n",
      "Epoch 96/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6498 - accuracy: 0.7279\n",
      "Epoch 97/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6474 - accuracy: 0.7297\n",
      "Epoch 98/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6460 - accuracy: 0.7290\n",
      "Epoch 99/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6443 - accuracy: 0.7301\n",
      "Epoch 100/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.6417 - accuracy: 0.7309\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 정의\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=100, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T03:40:25.245956400Z",
     "start_time": "2023-06-09T03:31:34.655313300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# 최상의 적합 모델의 가중치를 피클 파일로 저장\n",
    "best_model_weights = history.model.get_weights()\n",
    "pickle.dump(best_model_weights, open('../model/best_model_weights.pkl', 'wb'))\n",
    "\n",
    "# 레이블 인코더의 클래스 정보를 저장\n",
    "np.save('../model/label_encoder_classes.npy', label_encoder.classes_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T03:41:22.183439Z",
     "start_time": "2023-06-09T03:41:22.167798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n",
      "['fall' 'fall' 'stairs_walking' 'stairs_walking' 'stairs_walking' 'fall'\n",
      " 'jogging' 'fall' 'stairs_walking' 'fall' 'jogging' 'stairs_walking'\n",
      " 'stairs_walking' 'fall' 'fall' 'fall' 'stairs_walking' 'stairs_walking'\n",
      " 'fall' 'stairs_walking' 'fall' 'fall' 'stairs_walking' 'fall' 'fall'\n",
      " 'fall' 'fall' 'fall' 'stairs_walking' 'stairs_walking' 'stairs_walking'\n",
      " 'fall' 'stairs_walking' 'fall' 'jogging' 'jogging' 'fall'\n",
      " 'stairs_walking' 'stairs_walking' 'jogging' 'stairs_walking' 'fall'\n",
      " 'fall' 'fall' 'fall' 'stairs_walking' 'fall' 'jogging' 'fall'\n",
      " 'stairs_walking']\n"
     ]
    }
   ],
   "source": [
    "# 가중치를 로드하기 위해 모델 구성\n",
    "loaded_model = keras.models.Sequential()\n",
    "loaded_model.add(keras.layers.LSTM(128, input_shape=(3, 4)))  # 3개의 시퀀스, 각 시퀀스에 4개의 피처\n",
    "loaded_model.add(keras.layers.Dense(5, activation='softmax'))  # 분류할 클래스 수에 맞게 조정\n",
    "\n",
    "# 피클 파일에서 가중치 로드\n",
    "loaded_model_weights = pickle.load(open('../model/best_model_weights.pkl', 'rb'))\n",
    "\n",
    "# 모델에 로드된 가중치 설정\n",
    "loaded_model.set_weights(loaded_model_weights)\n",
    "\n",
    "# 모델 컴파일\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장\n",
    "loaded_model.save('../model/loaded_model_cnn.h5')\n",
    "\n",
    "# 예측할 데이터 불러오기\n",
    "pred_df = pd.read_csv('../data/Arduino/fall_sc.csv')\n",
    "\n",
    "# 입력 데이터 준비\n",
    "X_pred = []  # 입력 데이터\n",
    "\n",
    "# 4개의 레코드씩 묶어서 처리\n",
    "for i in range(0, len(pred_df) - 3, 4):\n",
    "    # gx, gy, gz 값 가져오기\n",
    "    gx_values = pred_df.loc[i:i+3, 'scaled_gx'].values\n",
    "    gy_values = pred_df.loc[i:i+3, 'scaled_gy'].values\n",
    "    gz_values = pred_df.loc[i:i+3, 'scaled_gz'].values\n",
    "\n",
    "    # 데이터 형상 조정\n",
    "    gx_values = np.transpose(gx_values)\n",
    "    gy_values = np.transpose(gy_values)\n",
    "    gz_values = np.transpose(gz_values)\n",
    "\n",
    "    # 시퀀스로 변환하여 입력 데이터에 추가\n",
    "    X_pred.append([gx_values, gy_values, gz_values])\n",
    "\n",
    "# 입력 데이터를 넘파이 배열로 변환\n",
    "X_pred = np.array(X_pred)\n",
    "\n",
    "# 예측\n",
    "predictions = loaded_model.predict(X_pred)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_classes = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(predicted_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T03:51:46.039572400Z",
     "start_time": "2023-06-09T03:51:44.832661500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
